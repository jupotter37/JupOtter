{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0604b13596a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score, recall_score, precision_score, classification_report, precision_recall_fscore_support\n",
    "import itertools\n",
    "from string import punctuation\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import ensemble\n",
    "from sklearn import neural_network\n",
    "from sklearn import linear_model\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# file used to write preserve the results of the classfier\n",
    "# confusion matrix and precision recall fscore matrix\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    \n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.tight_layout()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##saving the classification report\n",
    "def pandas_classification_report(y_true, y_pred):\n",
    "    metrics_summary = precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    \n",
    "    avg = list(precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred,\n",
    "            average='macro'))\n",
    "    avg.append(accuracy_score(y_true, y_pred, normalize=True))\n",
    "    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support','accuracy']\n",
    "    list_all=list(metrics_summary)\n",
    "    list_all.append(cm.diagonal())\n",
    "    class_report_df = pd.DataFrame(\n",
    "        list_all,\n",
    "        index=metrics_sum_index)\n",
    "\n",
    "    support = class_report_df.loc['support']\n",
    "    total = support.sum() \n",
    "    avg[-2] = total\n",
    "\n",
    "    class_report_df['avg / total'] = avg\n",
    "\n",
    "    return class_report_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....start....cleaning\n"
     ]
    }
   ],
   "source": [
    "from commen_preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_train_dataset = pd.read_csv('../AMI_data/en_training.tsv', sep='\\t')\n",
    "eng_test_dataset = pd.read_csv('../AMI_data/en_testing.tsv', sep='\\t')\n",
    "eng_gold_test_dataset = pd.read_csv('../AMI_data/en_testing_gold.tsv', sep='\\t')\n",
    "\n",
    "#eng_train_dataset = pd.read_csv('../AMI@EVALITA2018/my_pd_train.tsv', sep='\\t')\n",
    "#eng_test_dataset = pd.read_csv('../AMI@EVALITA2018/my_pd_test.tsv', sep='\\t')\n",
    "\n",
    "eng_train_dataset = eng_train_dataset.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>misogynous</th>\n",
       "      <th>misogyny_category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2813</td>\n",
       "      <td>I don't need anyone on my dick, I stay on my o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2193</td>\n",
       "      <td>NBC Rachel Maddcow not concerned about Rape &amp;;...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>899</td>\n",
       "      <td>Stop sayin you have resting bitch face... Bitc...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1941</td>\n",
       "      <td>@AnYaMemories @juthee_alam @TheSomyaSeth How d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2666</td>\n",
       "      <td>People- how long before your heart and liver g...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1246</td>\n",
       "      <td>slut - derogatory term for a female who will f...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2707</td>\n",
       "      <td>Deleted again. Working to get it back again ht...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1849</td>\n",
       "      <td>Sometimes you gotta beat ya dick like it stole...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2520</td>\n",
       "      <td>When you're chillin and the Taco Bell hits you...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2963</td>\n",
       "      <td>RT @taxo__: When it's Friday &amp;; you're feeling...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3957</td>\n",
       "      <td>@alexmvnon Also sad that you fucked your tooth...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>554</td>\n",
       "      <td>If you've ever mentioned me to your therapist,...</td>\n",
       "      <td>1</td>\n",
       "      <td>sexual_harassment</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3973</td>\n",
       "      <td>@louise__izzy @hxrrynicholson @fchamberlain31 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1511</td>\n",
       "      <td>@Cobratate God I hate that dumb cunt with her ...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2935</td>\n",
       "      <td>When you realize tomorrow is Monday https://t....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>998</td>\n",
       "      <td>#WeAlmostDatedBut FRIEND ZONED #WomenSuckk</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2474</td>\n",
       "      <td>#StopChildAbuse The next social movement will ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2438</td>\n",
       "      <td>Because running the world is harder than you'd...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1321</td>\n",
       "      <td>@ekhatami Die in a fire you fucking skank.</td>\n",
       "      <td>1</td>\n",
       "      <td>sexual_harassment</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>610</td>\n",
       "      <td>@bruhkari Why do you think that hoe is in the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2631</td>\n",
       "      <td>This is the kind of Easter egg hunt I need htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>819</td>\n",
       "      <td>sometimes your girlfriend gets kidnapped by a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3723</td>\n",
       "      <td>@bIueperiod That’s annoying. Not all men are t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>307</td>\n",
       "      <td>Told “that tight dress is what makes you a who...</td>\n",
       "      <td>1</td>\n",
       "      <td>derailing</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>879</td>\n",
       "      <td>If she's over 18 and owns anything Hello Kitty...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3123</td>\n",
       "      <td>When she says she only dates black guys https:...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2668</td>\n",
       "      <td>This is why I hate people https://t.co/19E4rarP5j</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3680</td>\n",
       "      <td>@steelebabe10 is a whore for any medical show ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1806</td>\n",
       "      <td>@realDonaldTrump Dont you mean killing America...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>149</td>\n",
       "      <td>@Its_Diaamondd Bitch fuck you too then 😭‼️that...</td>\n",
       "      <td>1</td>\n",
       "      <td>sexual_harassment</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>714</td>\n",
       "      <td>@GhostofGigi Are you calling me a Twitter Whor...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>2887</td>\n",
       "      <td>Her- don't I give the best head? Me- https://t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>3638</td>\n",
       "      <td>Oh go and beat up another woman you boring cun...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>1997</td>\n",
       "      <td>@mattkeogh Shame you won't protect children fr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>2603</td>\n",
       "      <td>When you see what you posted online when you w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3975</th>\n",
       "      <td>3969</td>\n",
       "      <td>@faceless you made it kunt https://t.co/0IR8x2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3976</th>\n",
       "      <td>16</td>\n",
       "      <td>like damn bitch if youre hungry shut the fuck ...</td>\n",
       "      <td>1</td>\n",
       "      <td>dominance</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>386</td>\n",
       "      <td>@BasicMormon So do we! Check out our account f...</td>\n",
       "      <td>1</td>\n",
       "      <td>dominance</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>1667</td>\n",
       "      <td>Don't fix yo mouth to say whatchu gone do, I t...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>3248</td>\n",
       "      <td>@allengbrown @Alyssa_Milano A police officer c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>3278</td>\n",
       "      <td>@MrAndyNgo Please don’t stop being kind. There...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>1873</td>\n",
       "      <td>Cuffing is not DEAD If everybody stop being a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3982</th>\n",
       "      <td>2285</td>\n",
       "      <td>#NYC housing projects &amp;; #PanAfrica men employ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>189</td>\n",
       "      <td>Its a good thing I always wear a glove on my l...</td>\n",
       "      <td>1</td>\n",
       "      <td>stereotype</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>150</td>\n",
       "      <td>@jezzellll then why tho?? u damn stupid hoe 😂</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3985</th>\n",
       "      <td>1567</td>\n",
       "      <td>@grxmd I dont think this fat whore could even ...</td>\n",
       "      <td>1</td>\n",
       "      <td>stereotype</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3986</th>\n",
       "      <td>2461</td>\n",
       "      <td>http://t.co/6n4V9kBtya See the monthly post, t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3987</th>\n",
       "      <td>1124</td>\n",
       "      <td>Only places my wife can drive are to restauran...</td>\n",
       "      <td>1</td>\n",
       "      <td>stereotype</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3988</th>\n",
       "      <td>2868</td>\n",
       "      <td>I feel like post birth abortion should be a th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3989</th>\n",
       "      <td>841</td>\n",
       "      <td>They've made it almost impossible for Men to b...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3990</th>\n",
       "      <td>3993</td>\n",
       "      <td>But anyway my point is - men don't lose sleep ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3991</th>\n",
       "      <td>2317</td>\n",
       "      <td>Constructing a Mental Hospital Prior To Ram Te...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992</th>\n",
       "      <td>2368</td>\n",
       "      <td>The poor kid wanted a fuck and got a bitch pre...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3993</th>\n",
       "      <td>420</td>\n",
       "      <td>Hoes in the city so recycled you just a rerock...</td>\n",
       "      <td>1</td>\n",
       "      <td>sexual_harassment</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>1139</td>\n",
       "      <td>Stop tweeting about your boyfriend. No one giv...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>3911</td>\n",
       "      <td>i said i was a whore, bro i can be a real bitc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>2509</td>\n",
       "      <td>I'm so anti social that I avoid people in my p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>520</td>\n",
       "      <td>Good girls send nudes</td>\n",
       "      <td>1</td>\n",
       "      <td>sexual_harassment</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>3066</td>\n",
       "      <td>@taxo__ @Scouse_ma 😂😂😂😂</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>2788</td>\n",
       "      <td>No one gives less fucks than a grown man using...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  misogynous  \\\n",
       "0     2813  I don't need anyone on my dick, I stay on my o...           0   \n",
       "1     2193  NBC Rachel Maddcow not concerned about Rape &;...           0   \n",
       "2      899  Stop sayin you have resting bitch face... Bitc...           1   \n",
       "3     1941  @AnYaMemories @juthee_alam @TheSomyaSeth How d...           0   \n",
       "4     2666  People- how long before your heart and liver g...           0   \n",
       "5     1246  slut - derogatory term for a female who will f...           1   \n",
       "6     2707  Deleted again. Working to get it back again ht...           0   \n",
       "7     1849  Sometimes you gotta beat ya dick like it stole...           0   \n",
       "8     2520  When you're chillin and the Taco Bell hits you...           0   \n",
       "9     2963  RT @taxo__: When it's Friday &; you're feeling...           0   \n",
       "10    3957  @alexmvnon Also sad that you fucked your tooth...           0   \n",
       "11     554  If you've ever mentioned me to your therapist,...           1   \n",
       "12    3973  @louise__izzy @hxrrynicholson @fchamberlain31 ...           0   \n",
       "13    1511  @Cobratate God I hate that dumb cunt with her ...           1   \n",
       "14    2935  When you realize tomorrow is Monday https://t....           0   \n",
       "15     998         #WeAlmostDatedBut FRIEND ZONED #WomenSuckk           1   \n",
       "16    2474  #StopChildAbuse The next social movement will ...           0   \n",
       "17    2438  Because running the world is harder than you'd...           0   \n",
       "18    1321         @ekhatami Die in a fire you fucking skank.           1   \n",
       "19     610  @bruhkari Why do you think that hoe is in the ...           1   \n",
       "20    2631  This is the kind of Easter egg hunt I need htt...           0   \n",
       "21     819  sometimes your girlfriend gets kidnapped by a ...           1   \n",
       "22    3723  @bIueperiod That’s annoying. Not all men are t...           0   \n",
       "23     307  Told “that tight dress is what makes you a who...           1   \n",
       "24     879  If she's over 18 and owns anything Hello Kitty...           1   \n",
       "25    3123  When she says she only dates black guys https:...           0   \n",
       "26    2668  This is why I hate people https://t.co/19E4rarP5j           0   \n",
       "27    3680  @steelebabe10 is a whore for any medical show ...           0   \n",
       "28    1806  @realDonaldTrump Dont you mean killing America...           0   \n",
       "29     149  @Its_Diaamondd Bitch fuck you too then 😭‼️that...           1   \n",
       "...    ...                                                ...         ...   \n",
       "3970   714  @GhostofGigi Are you calling me a Twitter Whor...           1   \n",
       "3971  2887  Her- don't I give the best head? Me- https://t...           0   \n",
       "3972  3638  Oh go and beat up another woman you boring cun...           0   \n",
       "3973  1997  @mattkeogh Shame you won't protect children fr...           0   \n",
       "3974  2603  When you see what you posted online when you w...           0   \n",
       "3975  3969  @faceless you made it kunt https://t.co/0IR8x2...           0   \n",
       "3976    16  like damn bitch if youre hungry shut the fuck ...           1   \n",
       "3977   386  @BasicMormon So do we! Check out our account f...           1   \n",
       "3978  1667  Don't fix yo mouth to say whatchu gone do, I t...           1   \n",
       "3979  3248  @allengbrown @Alyssa_Milano A police officer c...           0   \n",
       "3980  3278  @MrAndyNgo Please don’t stop being kind. There...           0   \n",
       "3981  1873  Cuffing is not DEAD If everybody stop being a ...           0   \n",
       "3982  2285  #NYC housing projects &; #PanAfrica men employ...           0   \n",
       "3983   189  Its a good thing I always wear a glove on my l...           1   \n",
       "3984   150      @jezzellll then why tho?? u damn stupid hoe 😂           1   \n",
       "3985  1567  @grxmd I dont think this fat whore could even ...           1   \n",
       "3986  2461  http://t.co/6n4V9kBtya See the monthly post, t...           0   \n",
       "3987  1124  Only places my wife can drive are to restauran...           1   \n",
       "3988  2868  I feel like post birth abortion should be a th...           0   \n",
       "3989   841  They've made it almost impossible for Men to b...           1   \n",
       "3990  3993  But anyway my point is - men don't lose sleep ...           0   \n",
       "3991  2317  Constructing a Mental Hospital Prior To Ram Te...           0   \n",
       "3992  2368  The poor kid wanted a fuck and got a bitch pre...           0   \n",
       "3993   420  Hoes in the city so recycled you just a rerock...           1   \n",
       "3994  1139  Stop tweeting about your boyfriend. No one giv...           1   \n",
       "3995  3911  i said i was a whore, bro i can be a real bitc...           0   \n",
       "3996  2509  I'm so anti social that I avoid people in my p...           0   \n",
       "3997   520                              Good girls send nudes           1   \n",
       "3998  3066                            @taxo__ @Scouse_ma 😂😂😂😂           0   \n",
       "3999  2788  No one gives less fucks than a grown man using...           0   \n",
       "\n",
       "      misogyny_category   target  \n",
       "0                     0        0  \n",
       "1                     0        0  \n",
       "2             discredit   active  \n",
       "3                     0        0  \n",
       "4                     0        0  \n",
       "5             discredit  passive  \n",
       "6                     0        0  \n",
       "7                     0        0  \n",
       "8                     0        0  \n",
       "9                     0        0  \n",
       "10                    0        0  \n",
       "11    sexual_harassment   active  \n",
       "12                    0        0  \n",
       "13            discredit   active  \n",
       "14                    0        0  \n",
       "15            discredit  passive  \n",
       "16                    0        0  \n",
       "17                    0        0  \n",
       "18    sexual_harassment   active  \n",
       "19            discredit   active  \n",
       "20                    0        0  \n",
       "21            discredit   active  \n",
       "22                    0        0  \n",
       "23            derailing  passive  \n",
       "24            discredit  passive  \n",
       "25                    0        0  \n",
       "26                    0        0  \n",
       "27                    0        0  \n",
       "28                    0        0  \n",
       "29    sexual_harassment   active  \n",
       "...                 ...      ...  \n",
       "3970          discredit   active  \n",
       "3971                  0        0  \n",
       "3972                  0        0  \n",
       "3973                  0        0  \n",
       "3974                  0        0  \n",
       "3975                  0        0  \n",
       "3976          dominance   active  \n",
       "3977          dominance  passive  \n",
       "3978          discredit   active  \n",
       "3979                  0        0  \n",
       "3980                  0        0  \n",
       "3981                  0        0  \n",
       "3982                  0        0  \n",
       "3983         stereotype  passive  \n",
       "3984          discredit   active  \n",
       "3985         stereotype   active  \n",
       "3986                  0        0  \n",
       "3987         stereotype   active  \n",
       "3988                  0        0  \n",
       "3989          discredit  passive  \n",
       "3990                  0        0  \n",
       "3991                  0        0  \n",
       "3992                  0        0  \n",
       "3993  sexual_harassment   active  \n",
       "3994          discredit   active  \n",
       "3995                  0        0  \n",
       "3996                  0        0  \n",
       "3997  sexual_harassment  passive  \n",
       "3998                  0        0  \n",
       "3999                  0        0  \n",
       "\n",
       "[4000 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    2215\n",
       "discredit            1014\n",
       "sexual_harassment     352\n",
       "stereotype            179\n",
       "dominance             148\n",
       "derailing              92\n",
       "Name: misogyny_category, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_train_dataset['misogyny_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Loading Glove Model\n",
      "count10000\n",
      "count20000\n",
      "count30000\n",
      "count40000\n",
      "count50000\n",
      "count60000\n",
      "count70000\n",
      "count80000\n",
      "count90000\n",
      "count100000\n",
      "count110000\n",
      "count120000\n",
      "count130000\n",
      "count140000\n",
      "count150000\n",
      "count160000\n",
      "count170000\n",
      "count180000\n",
      "count190000\n",
      "count200000\n",
      "count210000\n",
      "count220000\n",
      "count230000\n",
      "count240000\n",
      "count250000\n",
      "count260000\n",
      "count270000\n",
      "count280000\n",
      "count290000\n",
      "count300000\n",
      "count310000\n",
      "count320000\n",
      "count330000\n",
      "count340000\n",
      "count350000\n",
      "count360000\n",
      "count370000\n",
      "count380000\n",
      "count390000\n",
      "count400000\n",
      "count410000\n",
      "count420000\n",
      "count430000\n",
      "count440000\n",
      "count450000\n",
      "count460000\n",
      "count470000\n",
      "count480000\n",
      "count490000\n",
      "count500000\n",
      "count510000\n",
      "count520000\n",
      "count530000\n",
      "count540000\n",
      "count550000\n",
      "count560000\n",
      "count570000\n",
      "count580000\n",
      "count590000\n",
      "count600000\n",
      "count610000\n",
      "count620000\n",
      "count630000\n",
      "count640000\n",
      "count650000\n",
      "count660000\n",
      "count670000\n",
      "count680000\n",
      "count690000\n",
      "count700000\n",
      "count710000\n",
      "count720000\n",
      "count730000\n",
      "count740000\n",
      "count750000\n",
      "count760000\n",
      "count770000\n",
      "count780000\n",
      "count790000\n",
      "count800000\n",
      "count810000\n",
      "count820000\n",
      "count830000\n",
      "count840000\n",
      "count850000\n",
      "count860000\n",
      "count870000\n",
      "count880000\n",
      "count890000\n",
      "count900000\n",
      "count910000\n",
      "count920000\n",
      "count930000\n",
      "count940000\n",
      "count950000\n",
      "count960000\n",
      "count970000\n",
      "count980000\n",
      "count990000\n",
      "count1000000\n",
      "count1010000\n",
      "count1020000\n",
      "count1030000\n",
      "count1040000\n",
      "count1050000\n",
      "count1060000\n",
      "count1070000\n",
      "count1080000\n",
      "count1090000\n",
      "count1100000\n",
      "count1110000\n",
      "count1120000\n",
      "count1130000\n",
      "count1140000\n",
      "count1150000\n",
      "count1160000\n",
      "count1170000\n",
      "count1180000\n",
      "count1190000\n",
      "Done. 1193515  words loaded!\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "import os\n",
    "#### give the path to the glove model \n",
    "#### NOTE: this is\n",
    "GLOVE_MODEL_FILE = \"../../LEAM-master/glove.twitter.27B/glove.twitter.27B.200d.txt\"\n",
    "print(os.path.isfile(GLOVE_MODEL_FILE))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "##function for loading Glove Model\n",
    "def loadGloveModel(gloveFile):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r', encoding='utf8')\n",
    "    model = {}\n",
    "    i=0\n",
    "    for line in f:\n",
    "        i=i+1\n",
    "        splitLine = line.split(' ')\n",
    "        word = splitLine[0]\n",
    "        embedding = np.asarray(splitLine[1:], dtype='float32')\n",
    "        model[word] = embedding\n",
    "        if(i%10000==0):\n",
    "            print(\"count\"+str(i))\n",
    "    print(\"Done.\",len(model),\" words loaded!\")\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "EMBEDDING_DIM = 200\n",
    "word2vec_model = loadGloveModel(GLOVE_MODEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### stopwords and punctuations are not removed but text is cleaned and stemmed more details in the commen_preprocess.py file\n",
    "def glove_tokenize_norem(text):\n",
    "    #text = tokenizer(text)\n",
    "    text=clean(text, remove_stopwords=False, remove_punctuations=False)\n",
    "    words = text.split()\n",
    "    words =[ps.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "####stopwords and punctuations are removed along with that text is cleaned ans stemmed\n",
    "def glove_tokenize(text):\n",
    "    #text = tokenizer(text)\n",
    "    text=clean(text, remove_stopwords=False, remove_punctuations=False)\n",
    "    text = ''.join([c for c in text if c not in punctuation])\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in STOPWORDS]\n",
    "    words =[ps.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "def glove_tokenize_embed(text):\n",
    "    #text = tokenizer(text)\n",
    "    text=clean(text, remove_stopwords=False, remove_punctuations=False)\n",
    "    text = ''.join([c for c in text if c not in punctuation])\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in STOPWORDS]\n",
    "    return words\n",
    "\n",
    "def glove_tokenize_vocab(text):\n",
    "    #text = tokenizer(text)\n",
    "    text=clean(text, remove_stopwords=False, remove_punctuations=False)\n",
    "    words = text.split()\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def convert_class_label(input_text):\n",
    "    if input_text==1:\n",
    "        return 'misogyny'\n",
    "    elif input_text==0:\n",
    "        return 'non-misogyny'\n",
    "    else:\n",
    "        print('Wrong Input', input_text)\n",
    "        sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Loading Completed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binny/anaconda3/envs/punyajoy-nogpu/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# pd_train = pd.DataFrame(columns=['id','misogynous','text'])\n",
    "eng_train_dataset[\"text\"].replace('', np.nan, inplace=True)\n",
    "eng_train_dataset.dropna(subset=['text'], inplace=True)\n",
    "\n",
    "pd_train_binary = eng_train_dataset[['id','misogynous','text','misogyny_category','target']]\n",
    "pd_train_category = eng_train_dataset[['id','misogynous','text','misogyny_category']]\n",
    "pd_train_target = eng_train_dataset[['id','misogynous','text','target']]\n",
    "pd_test = eng_test_dataset[['id','text']]\n",
    "\n",
    "pd_train_category = pd_train_category.loc[pd_train_category['misogynous'] == 1]\n",
    "pd_train_target = pd_train_target.loc[pd_train_target['misogynous'] == 1]\n",
    "pd_train_target.drop(['misogynous'], axis=1)                                      \n",
    "pd_train_category.drop(['misogynous'], axis=1)                                      \n",
    "\n",
    "# pd_train['class'] =pd_train.apply(lambda row: convert_class_label(row['misogynous']), axis=1)\n",
    "\n",
    "pd_train_binary['class'] = pd_train_binary['misogynous']\n",
    "pd_train_category['class'] = pd_train_category['misogyny_category']\n",
    "pd_train_target['class'] = pd_train_target['target']\n",
    "\n",
    "# for count, each in enumerate(train_data):\n",
    "#     try:\n",
    "#         pd_train.loc[count]  = [each['id'], convert_class_label(each['CounterSpeech']), each['Community'],each['Category'],each['commentText']]\n",
    "#     except:\n",
    "#         pass\n",
    "print('Training Data Loading Completed...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(pd_train):\n",
    "    comments=pd_train['text'].values\n",
    "    labels=pd_train['class'].values\n",
    "    \n",
    "    list_comment=[]\n",
    "    for comment,label in zip(comments,labels):\n",
    "        temp={}\n",
    "        temp['text']=comment\n",
    "        temp['label']=label\n",
    "        list_comment.append(temp)\n",
    "    return list_comment \n",
    "\n",
    "def get_data_test(pd_test):\n",
    "    comments=pd_test['text'].values\n",
    "    list_comment=[]\n",
    "    for comment in comments:\n",
    "        temp={}\n",
    "        temp['text']=comment\n",
    "        list_comment.append(temp)\n",
    "    return list_comment \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab={}\n",
    "def create_vocab(data):\n",
    "    comments = get_data(data)\n",
    "    for comment in comments:\n",
    "        words=glove_tokenize_vocab(comment['text'])\n",
    "        for word in words:\n",
    "            if word in vocab.keys():\n",
    "                vocab[word]=vocab[word]+1 \n",
    "            else:\n",
    "                vocab[word]=1\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Universal Sentence Encoder configuration\n",
    "###### prerequisite: tensorflow version >=1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binny/anaconda3/envs/punyajoy-nogpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Downloading TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder/2'.\n",
      "INFO:tensorflow:Downloaded TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder/2'.\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_0:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_0\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_1:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_1\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_10:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_10\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_11:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_11\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_12:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_12\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_13:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_13\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_14:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_14\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_15:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_15\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_16:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_16\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_2:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_2\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_3:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_3\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_4:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_4\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_5:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_5\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_6:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_6\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_7:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_7\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_8:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_8\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_9:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_9\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_0/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Encoder_en/DNN/ResidualHidden_0/weights\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_1/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Encoder_en/DNN/ResidualHidden_1/weights\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_2/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Encoder_en/DNN/ResidualHidden_2/weights\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_3/projection:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Encoder_en/DNN/ResidualHidden_3/projection\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_3/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Encoder_en/DNN/ResidualHidden_3/weights\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_0/bias:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_0/bias\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_0/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_0/weights\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_1/bias:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_1/bias\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_1/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_1/weights\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_2/bias:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_2/bias\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_2/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_2/weights\n",
      "INFO:tensorflow:Initialize variable module/SNLI/Classifier/LinearLayer/bias:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SNLI/Classifier/LinearLayer/bias\n",
      "INFO:tensorflow:Initialize variable module/SNLI/Classifier/LinearLayer/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SNLI/Classifier/LinearLayer/weights\n",
      "INFO:tensorflow:Initialize variable module/SNLI/Classifier/tanh_layer_0/bias:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SNLI/Classifier/tanh_layer_0/bias\n",
      "INFO:tensorflow:Initialize variable module/SNLI/Classifier/tanh_layer_0/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SNLI/Classifier/tanh_layer_0/weights\n",
      "INFO:tensorflow:Initialize variable module/global_step:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with global_step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]\n",
    "embed = hub.Module(module_url)\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=12,\n",
    "                       allow_soft_placement=True, device_count = {'CPU': 12})\n",
    "\n",
    "def get_embeddings(messages):\n",
    "      \n",
    "    with tf.Session(config=config) as session:\n",
    "            session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "            message_emb = session.run(embed(messages))\n",
    "            \n",
    "    print(\"ending\")\n",
    "    return np.array(message_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "TOKENIZER = glove_tokenize\n",
    "#google encoding used where text is cleaned  \n",
    "def gen_data_google(data):\n",
    "    comments = get_data(data)\n",
    "    X, y = [], []\n",
    "    for comment in comments:\n",
    "        y.append(comment['label'])\n",
    "        #X.append(tokenizer(comment['text']))\n",
    "        X.append(clean(comment['text'], remove_stopwords=True, remove_punctuations=True))\n",
    "    #TFIDF_feature = 'bpe_text'\n",
    "\n",
    "    #Word Level Features\n",
    "    X =get_embeddings(X)\n",
    "    # print y\n",
    "    #y = MultiLabelBinarizer(classes = (1,2,3,4,5,6,7,8,9,10)).fit_transform(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "#google encoding used where text is not cleaned \n",
    "def gen_data_google2(data):\n",
    "    comments = get_data(data)\n",
    "    X, y = [],[]\n",
    "    for comment in comments:\n",
    "        y.append(comment['label'])\n",
    "        X.append(clean(comment['text'], remove_stopwords=False, remove_punctuations=False))\n",
    "    #Word Level Features\n",
    "    X =get_embeddings(X)\n",
    "    #y = MultiLabelBinarizer(classes = (1,2,3,4,5,6,7,8,9,10)).fit_transform(y)\n",
    "    return X,y\n",
    "\n",
    "###get data male,female\n",
    "def male_female(data):\n",
    "    comments = get_data(data)\n",
    "    X = []\n",
    "    for comment in comments:\n",
    "        X.append(np.array([comment['male'],comment['female']]))\n",
    "    #Word Level Features\n",
    "    \n",
    "    #y = MultiLabelBinarizer(classes = (1,2,3,4,5,6,7,8,9,10)).fit_transform(y)\n",
    "    return np.array(X)\n",
    "\n",
    "\n",
    "\n",
    "### tfidf feature generation was used here where stopwords and punctuations are removed \n",
    "def gen_data_new_tfidf(data):\n",
    "    comments = get_data(data)\n",
    "    comments_test=get_data_test(pd_test)\n",
    "    X, y = [], []\n",
    "    for comment in comments:\n",
    "        y.append(comment['label'])\n",
    "        X.append(comment['text'])\n",
    "\n",
    "    X1=[]\n",
    "    for comment in comments_test:\n",
    "        X1.append(comment['text'])\n",
    "\n",
    "\n",
    "    #Word Level Features\n",
    "    word_vectorizer = TfidfVectorizer(sublinear_tf=True, ngram_range=(1,3),\n",
    "                min_df=1, \n",
    "                strip_accents='unicode',\n",
    "                #smooth_idf=1,\n",
    "                analyzer='word', \n",
    "                stop_words='english',\n",
    "                tokenizer=TOKENIZER,             \n",
    "                max_features=5000)\n",
    "    \n",
    "    \n",
    "    #charlevel features new\n",
    "    char_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    #stop_words='english',\n",
    "    ngram_range=(2, 6),\n",
    "    max_features=10000)\n",
    "    word_vectorizer.fit(X+X1)\n",
    "    char_vectorizer.fit(X+X1)\n",
    "    \n",
    "    with open('tfidf_word_vectorizer.pk', 'wb') as fout:\n",
    "         pickle.dump(word_vectorizer,fout)\n",
    "\n",
    "    with open('tfidf_char_vectorizer.pk', 'wb') as fout:\n",
    "        pickle.dump(char_vectorizer,fout)\n",
    "    \n",
    "    test_word_features = word_vectorizer.transform(X)\n",
    "    test_char_features = char_vectorizer.transform(X)\n",
    "    X = list(hstack([test_char_features, test_word_features]).toarray())\n",
    "    #y = MultiLabelBinarizer(classes = (1,2,3,4,5,6,7,8,9,10)).fit_transform(y)\n",
    "    return X, y\n",
    "\n",
    "### tfidf feature generation was used here where stopwords and punctuations are not removed \n",
    "def gen_data_new_tfidf2(data):\n",
    "    comments = get_data(data)\n",
    "    X, y = [], []\n",
    "    for comment in comments:\n",
    "        y.append(comment['label'])\n",
    "        X.append(comment['text'])\n",
    "\n",
    "\n",
    "    #Word Level Features\n",
    "    word_vectorizer = TfidfVectorizer(sublinear_tf=True, ngram_range=(1,3),\n",
    "                min_df=1, \n",
    "                strip_accents='unicode',\n",
    "                #smooth_idf=1,\n",
    "                analyzer='word', \n",
    "                #stop_words='english',\n",
    "                tokenizer=glove_tokenize_norem,             \n",
    "                max_features=5000)\n",
    "    \n",
    "    \n",
    "    #charlevel features new\n",
    "    char_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    #stop_words='english',\n",
    "    ngram_range=(2, 6),\n",
    "    max_features=10000)\n",
    "    \n",
    "    word_vectorizer.fit(X)\n",
    "    char_vectorizer.fit(X)\n",
    "    \n",
    "    with open('tfidf_word_vectorize_noclean.pk', 'wb') as fout:\n",
    "         pickle.dump(word_vectorizer,fout)\n",
    "\n",
    "    with open('tfidf_char_vectorizer_noclean.pk', 'wb') as fout:\n",
    "         pickle.dump(char_vectorizer,fout)\n",
    "        \n",
    "    test_word_features = word_vectorizer.transform(X)\n",
    "    test_char_features = char_vectorizer.transform(X)\n",
    "    X = list(hstack([test_char_features, test_word_features]).toarray())\n",
    "    #y = MultiLabelBinarizer(classes = (1,2,3,4,5,6,7,8,9,10)).fit_transform(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "## combination of not cleaned google encodings and tfidf features where stopwords and punctuations are not removed \n",
    "def combine_tf_google_rem(data):\n",
    "    X,_=gen_data_google(data)\n",
    "    X1,y=gen_data_new_tfidf(data)\n",
    "#     X1,y=gen_data_old_tfidf()\n",
    "    X=np.concatenate((np.array(X), np.array(X1)), axis=1)\n",
    "    return X,y\n",
    "\n",
    "## combination of cleaned google encodings and tfidf features where stopwords and punctuations are ssremoved \n",
    "def combine_tf_google_norem(data):\n",
    "    X,_=gen_data_google2(data)\n",
    "    X1,y=gen_data_new_tfidf2(data)\n",
    "    X=np.concatenate((np.array(X), np.array(X1)), axis=1)\n",
    "    return X,y\n",
    "\n",
    "def combine_tf_rem_google_norem(data):\n",
    "    X,_=gen_data_google2(data)\n",
    "    X1,y=gen_data_new_tfidf(data)\n",
    "    X=np.concatenate((np.array(X), np.array(X1)), axis=1)\n",
    "    return X,y\n",
    "\n",
    "def combine_tf_norem_google_rem(data):\n",
    "    X,_=gen_data_google(data)\n",
    "    X1,y=gen_data_new_tfidf2(data)\n",
    "    X=np.concatenate((np.array(X), np.array(X1)), axis=1)\n",
    "    return X,y\n",
    "\n",
    "def gen_data_embed(data):\n",
    "    comments = get_data(data)\n",
    "    X, y = [], []\n",
    "    for comment in comments:\n",
    "        words = glove_tokenize_embed(comment['text'].lower())\n",
    "        emb = np.zeros(EMBEDDING_DIM)\n",
    "        for word in words:\n",
    "            try:\n",
    "                emb += word2vec_model[word]\n",
    "            except:\n",
    "                pass\n",
    "        if len(words)!=0:\n",
    "            emb /= len(words)\n",
    "        X.append(emb)\n",
    "        y.append(comment['label'])\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def combine_tf_rem_google_norem_embed(data):\n",
    "    X,_=gen_data_google2(data)\n",
    "    X1,y=gen_data_new_tfidf(data)\n",
    "    X2,_=gen_data_embed(data)\n",
    "    X=np.concatenate((np.array(X), np.array(X1),np.array(X2)), axis=1)\n",
    "    return X,y\n",
    "\n",
    "\n",
    "\n",
    "###old tfidf\n",
    "\n",
    "def gen_data_old_tfidf(data):\n",
    "    comments = get_data(data)\n",
    "    X, y = [], []\n",
    "    for comment in comments:\n",
    "        y.append(comment['label'])\n",
    "        X.append(comment['text'])\n",
    "    with open('../tfidf_word_vectorizer.pk', 'rb') as fin:\n",
    "        word_vectorizer = pickle.load(fin)\n",
    "\n",
    "    with open('../tfidf_char_vectorizer.pk', 'rb') as fin:\n",
    "        char_vectorizer = pickle.load(fin)\n",
    "\n",
    "\n",
    "    \n",
    "    word_vectorizer.fit(X)\n",
    "    char_vectorizer.fit(X)\n",
    "    \n",
    "    test_word_features = word_vectorizer.transform(X)\n",
    "    test_char_features = char_vectorizer.transform(X)\n",
    "    X = list(hstack([test_char_features, test_word_features]).toarray())\n",
    "    #y = MultiLabelBinarizer(classes = (1,2,3,4,5,6,7,8,9,10)).fit_transform(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def select_comments_whose_embedding_exists(flag):\n",
    "    # selects the comments as in mean_glove_embedding method\n",
    "    # Processing\n",
    "    comments = get_data(flag)\n",
    "    X, Y = [], []\n",
    "    comment_return = []\n",
    "    for tweet in comments:\n",
    "        #print(tweet)\n",
    "        _emb = 0\n",
    "        words = TOKENIZER(tweet['text'].lower())\n",
    "        for w in words:\n",
    "            #print(w)\n",
    "            if w in word2vec_model and w is not None:  # Check if embeeding there in GLove model\n",
    "                _emb+=1\n",
    "        if _emb:   # Not a blank tweet\n",
    "            comment_return.append(tweet)\n",
    "    print('Comments selected:', len(comment_return))\n",
    "    return comment_return\n",
    "\n",
    "def gen_data():\n",
    "    comments = select_comments_whose_embedding_exists(0)\n",
    "    X, y = [], []\n",
    "    for comment in comments:\n",
    "        words = glove_tokenize(comment['text'].lower())\n",
    "        emb = numpy.zeros(EMBEDDING_DIM)\n",
    "        for word in words:\n",
    "            try:\n",
    "                emb += word2vec_model[word]\n",
    "            except:\n",
    "                pass\n",
    "        emb /= len(words)\n",
    "        X.append(emb)\n",
    "        y.append(comment['label'])\n",
    "\n",
    "    # print y\n",
    "    y = MultiLabelBinarizer(classes = (1,2,3,4,5,6,7,8,9,10)).fit_transform(y)\n",
    "    print\n",
    "    return X, y\n",
    "\n",
    "## combination of not cleaned google encodings and tfidf features where stopwords and punctuations are not removed \n",
    "def combine_tf_google_glove_rem():\n",
    "    X,_=gen_data_google()\n",
    "    X1,y=gen_data_new_tfidf()\n",
    "#     X1,y=gen_data_old_tfidf()\n",
    "    X=np.concatenate((np.array(X), np.array(X1)), axis=1)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCALE_POS_WEIGHT=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def get_model(m_type=None):\n",
    "    if not m_type:\n",
    "        print(\"ERROR: Please specify a model type!\")\n",
    "        return None\n",
    "    if m_type == 'decision_tree_classifier':\n",
    "        logreg = tree.DecisionTreeClassifier(class_weight='balanced')\n",
    "    elif m_type == 'gaussian':\n",
    "        logreg = GaussianNB()\n",
    "    elif m_type == 'logistic_regression':\n",
    "        logreg = LogisticRegression(class_weight='balanced',n_jobs=10, random_state=42)\n",
    "    elif m_type == 'MLPClassifier':\n",
    "#         logreg = neural_network.MLPClassifier((500))\n",
    "        logreg = neural_network.MLPClassifier(random_state=42,early_stopping=True)\n",
    "    elif m_type == 'KNeighborsClassifier':\n",
    "#         logreg = neighbors.KNeighborsClassifier(n_neighbors = 10)\n",
    "        logreg = neighbors.KNeighborsClassifier()\n",
    "    elif m_type == 'ExtraTreeClassifier':\n",
    "        logreg = tree.ExtraTreeClassifier()\n",
    "    elif m_type == 'ExtraTreeClassifier_2':\n",
    "        logreg = ensemble.ExtraTreesClassifier()\n",
    "    elif m_type == 'RandomForestClassifier':\n",
    "        logreg = ensemble.RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=12, max_depth=3)\n",
    "    elif m_type == 'SVC':\n",
    "        logreg = LinearSVC(class_weight='balanced');\n",
    "    elif m_type == 'Catboost':\n",
    "        logreg = CatBoostClassifier(use_best_model=False, random_state=42, scale_pos_weight=SCALE_POS_WEIGHT)\n",
    "#         logreg = CatBoostClassifier(scale_pos_weight=0.8, random_seed=42,);\n",
    "    elif m_type == 'XGB_classifier':\n",
    "#         logreg=XGBClassifier(silent=False,eta=0.1,objective='binary:logistic',max_depth=5,min_child_weight=0,gamma=0.2,subsample=0.8, colsample_bytree = 0.8,scale_pos_weight=1,n_estimators=500,reg_lambda=3,nthread=12)\n",
    "        logreg=XGBClassifier(silent=False,objective='binary:logistic',scale_pos_weight=0.8,reg_lambda=3,nthread=12, random_state=42)\n",
    "    elif m_type == 'binny_test':\n",
    "        clf1 = ensemble.RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=12, max_depth=6,max_features='auto')\n",
    "        clf2 = tree.DecisionTreeClassifier(random_state=42, class_weight='balanced',max_depth=6)\n",
    "        clf3 = LogisticRegression(class_weight='balanced',penalty=\"l2\",C=0.1, dual=True, random_state=42, n_jobs=3)\n",
    "        clf4 = XGBClassifier(silent=False,objective='binary:logistic',scale_pos_weight=0.8,reg_lambda=3,nthread=12, random_state=42)\n",
    "        est_list = [('lr', clf1), ('rf', clf2), ('gnb', clf3), ('xgb', clf4)]\n",
    "        logreg = ensemble.VotingClassifier(est_list,voting='soft',n_jobs=6)\n",
    "    else:\n",
    "        print(\"give correct model\")\n",
    "    print(logreg)\n",
    "    return logreg\n",
    "\n",
    "def get_feature(f_type=None,data=None):\n",
    "    if not f_type:\n",
    "        print(\"ERROR: Please specify a model type!\")\n",
    "        return None\n",
    "    if f_type == 'google_not_preprocess':\n",
    "        X,y=gen_data_google2(data)\n",
    "    elif f_type == 'word_to_vec_embed':\n",
    "        X,y=gen_data_embed(data)\n",
    "    elif f_type == 'google_preprocess':\n",
    "        X,y=gen_data_google(data)\n",
    "    elif f_type == 'tfidf_not_preprocess':\n",
    "        X,y=gen_data_new_tfidf2(data)\n",
    "    elif f_type == 'tfidf_preprocess':\n",
    "        X,y=gen_data_new_tfidf(data)\n",
    "    elif f_type == 'google_preprocess_tfidf_preprocess':\n",
    "        X,y=combine_tf_google_rem(data)\n",
    "    elif f_type == 'google_nopreprocess_tfidf_nopreprocess':\n",
    "        X,y=combine_tf_google_norem(data)\n",
    "    elif f_type == 'google_preprocess_tfidf_nopreprocess':\n",
    "        X,y=combine_tf_norem_google_rem(data)\n",
    "    elif f_type == 'google_nopreprocess_tfidf_preprocess':\n",
    "        X,y=combine_tf_rem_google_norem(data)\n",
    "    elif f_type == 'google_nopreprocess_tfidf_preprocess_embed':\n",
    "        X,y=combine_tf_rem_google_norem_embed(data)\n",
    "    else:\n",
    "        print(\"give correct feature selection\")    \n",
    "    print(f_type)\n",
    "    return X,y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from imblearn.combine import SMOTETomek \n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedKFold as skf\n",
    "\n",
    "def binny_classifier_run(X,y,model,model_name,label_map,img_name,report_name,save_model=False):\n",
    "    Classifier_Train_X = np.array(X, copy=False)\n",
    "    Classifier_Train_Y = y\n",
    "    temp=[]\n",
    "    for data in Classifier_Train_Y:\n",
    "        temp.append(label_map[data])\n",
    "    SCALE_POS_WEIGHT=temp.count(0)/temp.count(1)\n",
    "    \n",
    "    Classifier_Train_Y=np.array(temp)\n",
    "    \n",
    "    \n",
    "    model_featureSelection = SelectFromModel(ensemble.RandomForestClassifier(n_estimators=50, class_weight='balanced', \n",
    "                                                                                      n_jobs=12, max_depth=3))\n",
    "    print('Before Num features=',Classifier_Train_X.shape[1], Counter(Classifier_Train_Y))\n",
    "    Classifier_Train_X = model_featureSelection.fit_transform(Classifier_Train_X,Classifier_Train_Y)\n",
    "    print('After Num features=',Classifier_Train_X.shape[1])\n",
    "\n",
    "    \n",
    "    if(save_model==True):\n",
    "        Classifier=model\n",
    "        Classifier.fit(Classifier_Train_X, Classifier_Train_Y)\n",
    "        filename = 'taskA/'+model_name+'_task_1.joblib.pkl'\n",
    "        joblib.dump(Classifier, filename, compress=9)\n",
    "        filename1 = 'taskA/'+model_name+'_select_features_task1.joblib.pkl'\n",
    "        joblib.dump(model_featureSelection, filename1, compress=9)\n",
    "    else:\n",
    "        kf = skf(n_splits=10,shuffle=True)\n",
    "        y_total_preds=[] \n",
    "        y_total=[]\n",
    "        count=0\n",
    "\n",
    "        for train_index, test_index in kf.split(Classifier_Train_X,Classifier_Train_Y):\n",
    "            X_train, X_test = Classifier_Train_X[train_index], Classifier_Train_X[test_index]\n",
    "            y_train, y_test = Classifier_Train_Y[train_index], Classifier_Train_Y[test_index]\n",
    "            classifier=model \n",
    "            classifier.fit(X_train,y_train)\n",
    "            y_preds = classifier.predict(X_test)\n",
    "            for ele in y_test:\n",
    "                y_total.append(ele)\n",
    "            for ele in y_preds:\n",
    "                y_total_preds.append(ele)\n",
    "            y_pred_train = classifier.predict(X_train)\n",
    "            count=count+1       \n",
    "            print('accuracy_train:',accuracy_score(y_train, y_pred_train),'accuracy_test:',accuracy_score(y_test, y_preds))\n",
    "            print('TRAINING:')\n",
    "            print(classification_report( y_train, y_pred_train ))\n",
    "            print(\"TESTING:\")\n",
    "            print(classification_report( y_test, y_preds ))\n",
    "            \n",
    "        report = classification_report( y_total, y_total_preds )\n",
    "        cm=confusion_matrix(y_total, y_total_preds)\n",
    "        plt=plot_confusion_matrix(cm,normalize= True,target_names = ['non_misgynous','misgynous'],title = \"Confusion Matrix\")\n",
    "        plt.savefig('task1'+model_name+'_'+img_name)\n",
    "        print(model)\n",
    "        print(report)\n",
    "        print(accuracy_score(y_total, y_total_preds))\n",
    "        df_result=pandas_classification_report(y_total,y_total_preds)\n",
    "        df_result.to_csv('task1'+model_name+'_'+report_name,  sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_model = 'google_nopreprocess_tfidf_preprocess_embed'\n",
    "img_name = 'cm.png'\n",
    "report_name = 'report.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending\n",
      "google_nopreprocess_tfidf_preprocess_embed\n"
     ]
    }
   ],
   "source": [
    "data_name= 'pd_train_binary'\n",
    "\n",
    "if(data_name=='pd_train_binary'):\n",
    "    X,y=get_feature(f_type=feature_model,data=pd_train_binary)\n",
    "    label_map = {\n",
    "             1: 1,\n",
    "             0: 0\n",
    "                 }\n",
    "elif(data_name=='pd_train_category'):\n",
    "    X,y=get_feature(f_type=feature_model,data=pd_train_category)\n",
    "    label_map = {\n",
    "            'discredit': 0,\n",
    "            'sexual_harassment': 1,\n",
    "            'stereotype': 2,\n",
    "            'dominance': 3,\n",
    "            'derailing': 4\n",
    "        }\n",
    "elif(data_name=='pd_train_target'):\n",
    "    X,y=get_feature(f_type=feature_model,data=pd_train_target)\n",
    "    label_map = {\n",
    "             'active': 1,\n",
    "             'passive': 0\n",
    "         }\n",
    "\n",
    "else:\n",
    "    print('give correct data')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<catboost.core.CatBoostClassifier object at 0x7fda9e8bbcc0>\n",
      "Before Num features= 15712 Counter({0: 2215, 1: 1785})\n",
      "After Num features= 253\n",
      "Learning rate set to 0.024803\n",
      "0:\tlearn: 0.6807219\ttotal: 40.1ms\tremaining: 40s\n",
      "1:\tlearn: 0.6708206\ttotal: 74.5ms\tremaining: 37.2s\n",
      "2:\tlearn: 0.6602255\ttotal: 105ms\tremaining: 34.9s\n",
      "3:\tlearn: 0.6502977\ttotal: 133ms\tremaining: 33.1s\n",
      "4:\tlearn: 0.6410137\ttotal: 161ms\tremaining: 32s\n",
      "5:\tlearn: 0.6308812\ttotal: 189ms\tremaining: 31.3s\n",
      "6:\tlearn: 0.6233346\ttotal: 215ms\tremaining: 30.5s\n",
      "7:\tlearn: 0.6159610\ttotal: 246ms\tremaining: 30.5s\n",
      "8:\tlearn: 0.6082152\ttotal: 275ms\tremaining: 30.3s\n",
      "9:\tlearn: 0.6001265\ttotal: 301ms\tremaining: 29.8s\n",
      "10:\tlearn: 0.5923223\ttotal: 329ms\tremaining: 29.6s\n",
      "11:\tlearn: 0.5850889\ttotal: 357ms\tremaining: 29.4s\n",
      "12:\tlearn: 0.5783535\ttotal: 386ms\tremaining: 29.3s\n",
      "13:\tlearn: 0.5729422\ttotal: 411ms\tremaining: 29s\n",
      "14:\tlearn: 0.5668037\ttotal: 441ms\tremaining: 28.9s\n",
      "15:\tlearn: 0.5612591\ttotal: 468ms\tremaining: 28.8s\n",
      "16:\tlearn: 0.5565169\ttotal: 495ms\tremaining: 28.6s\n",
      "17:\tlearn: 0.5515766\ttotal: 525ms\tremaining: 28.6s\n",
      "18:\tlearn: 0.5460916\ttotal: 552ms\tremaining: 28.5s\n",
      "19:\tlearn: 0.5417315\ttotal: 578ms\tremaining: 28.3s\n",
      "20:\tlearn: 0.5377272\ttotal: 608ms\tremaining: 28.3s\n",
      "21:\tlearn: 0.5337195\ttotal: 634ms\tremaining: 28.2s\n",
      "22:\tlearn: 0.5290730\ttotal: 663ms\tremaining: 28.1s\n",
      "23:\tlearn: 0.5246814\ttotal: 693ms\tremaining: 28.2s\n",
      "24:\tlearn: 0.5209884\ttotal: 723ms\tremaining: 28.2s\n",
      "25:\tlearn: 0.5166273\ttotal: 752ms\tremaining: 28.2s\n",
      "26:\tlearn: 0.5127270\ttotal: 778ms\tremaining: 28s\n",
      "27:\tlearn: 0.5101866\ttotal: 805ms\tremaining: 27.9s\n",
      "28:\tlearn: 0.5066827\ttotal: 832ms\tremaining: 27.8s\n",
      "29:\tlearn: 0.5035609\ttotal: 859ms\tremaining: 27.8s\n",
      "30:\tlearn: 0.5003193\ttotal: 885ms\tremaining: 27.7s\n",
      "31:\tlearn: 0.4975645\ttotal: 915ms\tremaining: 27.7s\n",
      "32:\tlearn: 0.4952747\ttotal: 942ms\tremaining: 27.6s\n",
      "33:\tlearn: 0.4928640\ttotal: 970ms\tremaining: 27.5s\n",
      "34:\tlearn: 0.4904487\ttotal: 996ms\tremaining: 27.5s\n",
      "35:\tlearn: 0.4883610\ttotal: 1.02s\tremaining: 27.3s\n",
      "36:\tlearn: 0.4863635\ttotal: 1.05s\tremaining: 27.3s\n",
      "37:\tlearn: 0.4840956\ttotal: 1.08s\tremaining: 27.2s\n",
      "38:\tlearn: 0.4818102\ttotal: 1.1s\tremaining: 27.2s\n",
      "39:\tlearn: 0.4796265\ttotal: 1.13s\tremaining: 27.1s\n",
      "40:\tlearn: 0.4774548\ttotal: 1.16s\tremaining: 27.1s\n",
      "41:\tlearn: 0.4753932\ttotal: 1.19s\tremaining: 27.1s\n",
      "42:\tlearn: 0.4735210\ttotal: 1.21s\tremaining: 27s\n",
      "43:\tlearn: 0.4719746\ttotal: 1.24s\tremaining: 27s\n",
      "44:\tlearn: 0.4697161\ttotal: 1.27s\tremaining: 26.9s\n",
      "45:\tlearn: 0.4677229\ttotal: 1.29s\tremaining: 26.9s\n",
      "46:\tlearn: 0.4659607\ttotal: 1.32s\tremaining: 26.8s\n",
      "47:\tlearn: 0.4640316\ttotal: 1.35s\tremaining: 26.8s\n",
      "48:\tlearn: 0.4626049\ttotal: 1.38s\tremaining: 26.7s\n",
      "49:\tlearn: 0.4612671\ttotal: 1.4s\tremaining: 26.7s\n",
      "50:\tlearn: 0.4596130\ttotal: 1.43s\tremaining: 26.6s\n",
      "51:\tlearn: 0.4579500\ttotal: 1.46s\tremaining: 26.6s\n",
      "52:\tlearn: 0.4565262\ttotal: 1.49s\tremaining: 26.5s\n",
      "53:\tlearn: 0.4546160\ttotal: 1.51s\tremaining: 26.5s\n",
      "54:\tlearn: 0.4531925\ttotal: 1.54s\tremaining: 26.4s\n",
      "55:\tlearn: 0.4516488\ttotal: 1.57s\tremaining: 26.4s\n",
      "56:\tlearn: 0.4501881\ttotal: 1.6s\tremaining: 26.4s\n",
      "57:\tlearn: 0.4491248\ttotal: 1.62s\tremaining: 26.3s\n",
      "58:\tlearn: 0.4479417\ttotal: 1.65s\tremaining: 26.3s\n",
      "59:\tlearn: 0.4465600\ttotal: 1.67s\tremaining: 26.2s\n",
      "60:\tlearn: 0.4454172\ttotal: 1.7s\tremaining: 26.2s\n",
      "61:\tlearn: 0.4442030\ttotal: 1.73s\tremaining: 26.1s\n",
      "62:\tlearn: 0.4430715\ttotal: 1.75s\tremaining: 26s\n",
      "63:\tlearn: 0.4416784\ttotal: 1.78s\tremaining: 26s\n",
      "64:\tlearn: 0.4403797\ttotal: 1.81s\tremaining: 26s\n",
      "65:\tlearn: 0.4392080\ttotal: 1.83s\tremaining: 26s\n",
      "66:\tlearn: 0.4380344\ttotal: 1.86s\tremaining: 25.9s\n",
      "67:\tlearn: 0.4369386\ttotal: 1.89s\tremaining: 25.9s\n",
      "68:\tlearn: 0.4355627\ttotal: 1.92s\tremaining: 25.9s\n",
      "69:\tlearn: 0.4345414\ttotal: 1.94s\tremaining: 25.8s\n",
      "70:\tlearn: 0.4331209\ttotal: 1.97s\tremaining: 25.8s\n",
      "71:\tlearn: 0.4323643\ttotal: 2s\tremaining: 25.7s\n",
      "72:\tlearn: 0.4314750\ttotal: 2.02s\tremaining: 25.7s\n",
      "73:\tlearn: 0.4304603\ttotal: 2.05s\tremaining: 25.7s\n",
      "74:\tlearn: 0.4294065\ttotal: 2.08s\tremaining: 25.7s\n",
      "75:\tlearn: 0.4286527\ttotal: 2.11s\tremaining: 25.6s\n",
      "76:\tlearn: 0.4279367\ttotal: 2.13s\tremaining: 25.6s\n",
      "77:\tlearn: 0.4268427\ttotal: 2.16s\tremaining: 25.5s\n",
      "78:\tlearn: 0.4260715\ttotal: 2.19s\tremaining: 25.5s\n",
      "79:\tlearn: 0.4254648\ttotal: 2.21s\tremaining: 25.4s\n",
      "80:\tlearn: 0.4243899\ttotal: 2.24s\tremaining: 25.4s\n",
      "81:\tlearn: 0.4235446\ttotal: 2.27s\tremaining: 25.4s\n",
      "82:\tlearn: 0.4224975\ttotal: 2.29s\tremaining: 25.3s\n",
      "83:\tlearn: 0.4218021\ttotal: 2.31s\tremaining: 25.3s\n",
      "84:\tlearn: 0.4208180\ttotal: 2.34s\tremaining: 25.2s\n",
      "85:\tlearn: 0.4196660\ttotal: 2.37s\tremaining: 25.1s\n",
      "86:\tlearn: 0.4187952\ttotal: 2.39s\tremaining: 25.1s\n",
      "87:\tlearn: 0.4180349\ttotal: 2.42s\tremaining: 25.1s\n",
      "88:\tlearn: 0.4169598\ttotal: 2.45s\tremaining: 25.1s\n",
      "89:\tlearn: 0.4164242\ttotal: 2.48s\tremaining: 25s\n",
      "90:\tlearn: 0.4156024\ttotal: 2.5s\tremaining: 25s\n",
      "91:\tlearn: 0.4152138\ttotal: 2.53s\tremaining: 24.9s\n",
      "92:\tlearn: 0.4146152\ttotal: 2.55s\tremaining: 24.9s\n",
      "93:\tlearn: 0.4140733\ttotal: 2.58s\tremaining: 24.9s\n",
      "94:\tlearn: 0.4132607\ttotal: 2.61s\tremaining: 24.8s\n",
      "95:\tlearn: 0.4126591\ttotal: 2.63s\tremaining: 24.8s\n",
      "96:\tlearn: 0.4119558\ttotal: 2.66s\tremaining: 24.8s\n",
      "97:\tlearn: 0.4113147\ttotal: 2.69s\tremaining: 24.8s\n",
      "98:\tlearn: 0.4106923\ttotal: 2.72s\tremaining: 24.7s\n",
      "99:\tlearn: 0.4098446\ttotal: 2.75s\tremaining: 24.7s\n",
      "100:\tlearn: 0.4091886\ttotal: 2.77s\tremaining: 24.7s\n",
      "101:\tlearn: 0.4086223\ttotal: 2.8s\tremaining: 24.6s\n",
      "102:\tlearn: 0.4077999\ttotal: 2.82s\tremaining: 24.6s\n",
      "103:\tlearn: 0.4069391\ttotal: 2.85s\tremaining: 24.5s\n",
      "104:\tlearn: 0.4061288\ttotal: 2.88s\tremaining: 24.5s\n",
      "105:\tlearn: 0.4054522\ttotal: 2.9s\tremaining: 24.5s\n",
      "106:\tlearn: 0.4048736\ttotal: 2.93s\tremaining: 24.4s\n",
      "107:\tlearn: 0.4040700\ttotal: 2.96s\tremaining: 24.4s\n",
      "108:\tlearn: 0.4033992\ttotal: 2.98s\tremaining: 24.4s\n",
      "109:\tlearn: 0.4027040\ttotal: 3.01s\tremaining: 24.4s\n",
      "110:\tlearn: 0.4021236\ttotal: 3.04s\tremaining: 24.3s\n",
      "111:\tlearn: 0.4014774\ttotal: 3.06s\tremaining: 24.3s\n",
      "112:\tlearn: 0.4011908\ttotal: 3.09s\tremaining: 24.3s\n",
      "113:\tlearn: 0.4003405\ttotal: 3.12s\tremaining: 24.2s\n",
      "114:\tlearn: 0.4000156\ttotal: 3.14s\tremaining: 24.2s\n",
      "115:\tlearn: 0.3992300\ttotal: 3.17s\tremaining: 24.2s\n",
      "116:\tlearn: 0.3988660\ttotal: 3.19s\tremaining: 24.1s\n",
      "117:\tlearn: 0.3983943\ttotal: 3.22s\tremaining: 24.1s\n",
      "118:\tlearn: 0.3978602\ttotal: 3.25s\tremaining: 24s\n",
      "119:\tlearn: 0.3971498\ttotal: 3.27s\tremaining: 24s\n",
      "120:\tlearn: 0.3965162\ttotal: 3.3s\tremaining: 24s\n",
      "121:\tlearn: 0.3959216\ttotal: 3.33s\tremaining: 23.9s\n",
      "122:\tlearn: 0.3954922\ttotal: 3.35s\tremaining: 23.9s\n",
      "123:\tlearn: 0.3949143\ttotal: 3.38s\tremaining: 23.9s\n",
      "124:\tlearn: 0.3944270\ttotal: 3.4s\tremaining: 23.8s\n",
      "125:\tlearn: 0.3938151\ttotal: 3.43s\tremaining: 23.8s\n",
      "126:\tlearn: 0.3931234\ttotal: 3.46s\tremaining: 23.8s\n",
      "127:\tlearn: 0.3926181\ttotal: 3.48s\tremaining: 23.7s\n",
      "128:\tlearn: 0.3920724\ttotal: 3.51s\tremaining: 23.7s\n",
      "129:\tlearn: 0.3913904\ttotal: 3.54s\tremaining: 23.7s\n",
      "130:\tlearn: 0.3909201\ttotal: 3.56s\tremaining: 23.7s\n",
      "131:\tlearn: 0.3903142\ttotal: 3.59s\tremaining: 23.6s\n",
      "132:\tlearn: 0.3897460\ttotal: 3.62s\tremaining: 23.6s\n",
      "133:\tlearn: 0.3892133\ttotal: 3.64s\tremaining: 23.6s\n",
      "134:\tlearn: 0.3888200\ttotal: 3.67s\tremaining: 23.5s\n",
      "135:\tlearn: 0.3885117\ttotal: 3.7s\tremaining: 23.5s\n",
      "136:\tlearn: 0.3879448\ttotal: 3.72s\tremaining: 23.5s\n",
      "137:\tlearn: 0.3872992\ttotal: 3.75s\tremaining: 23.4s\n",
      "138:\tlearn: 0.3865828\ttotal: 3.78s\tremaining: 23.4s\n",
      "139:\tlearn: 0.3860909\ttotal: 3.81s\tremaining: 23.4s\n",
      "140:\tlearn: 0.3855307\ttotal: 3.83s\tremaining: 23.4s\n",
      "141:\tlearn: 0.3851830\ttotal: 3.86s\tremaining: 23.3s\n",
      "142:\tlearn: 0.3847897\ttotal: 3.88s\tremaining: 23.3s\n",
      "143:\tlearn: 0.3843058\ttotal: 3.91s\tremaining: 23.3s\n",
      "144:\tlearn: 0.3839728\ttotal: 3.94s\tremaining: 23.2s\n",
      "145:\tlearn: 0.3833126\ttotal: 3.97s\tremaining: 23.2s\n",
      "146:\tlearn: 0.3828014\ttotal: 3.99s\tremaining: 23.2s\n",
      "147:\tlearn: 0.3823306\ttotal: 4.02s\tremaining: 23.1s\n",
      "148:\tlearn: 0.3816347\ttotal: 4.05s\tremaining: 23.1s\n",
      "149:\tlearn: 0.3811125\ttotal: 4.08s\tremaining: 23.1s\n",
      "150:\tlearn: 0.3805980\ttotal: 4.1s\tremaining: 23.1s\n",
      "151:\tlearn: 0.3803567\ttotal: 4.13s\tremaining: 23s\n",
      "152:\tlearn: 0.3800019\ttotal: 4.15s\tremaining: 23s\n",
      "153:\tlearn: 0.3796217\ttotal: 4.18s\tremaining: 23s\n",
      "154:\tlearn: 0.3791395\ttotal: 4.2s\tremaining: 22.9s\n",
      "155:\tlearn: 0.3787077\ttotal: 4.23s\tremaining: 22.9s\n",
      "156:\tlearn: 0.3781808\ttotal: 4.25s\tremaining: 22.8s\n",
      "157:\tlearn: 0.3777045\ttotal: 4.28s\tremaining: 22.8s\n",
      "158:\tlearn: 0.3772480\ttotal: 4.31s\tremaining: 22.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159:\tlearn: 0.3767837\ttotal: 4.33s\tremaining: 22.8s\n",
      "160:\tlearn: 0.3763199\ttotal: 4.36s\tremaining: 22.7s\n",
      "161:\tlearn: 0.3759642\ttotal: 4.39s\tremaining: 22.7s\n",
      "162:\tlearn: 0.3755695\ttotal: 4.41s\tremaining: 22.7s\n",
      "163:\tlearn: 0.3750871\ttotal: 4.44s\tremaining: 22.6s\n",
      "164:\tlearn: 0.3746753\ttotal: 4.47s\tremaining: 22.6s\n",
      "165:\tlearn: 0.3742987\ttotal: 4.5s\tremaining: 22.6s\n",
      "166:\tlearn: 0.3738685\ttotal: 4.52s\tremaining: 22.6s\n",
      "167:\tlearn: 0.3732836\ttotal: 4.55s\tremaining: 22.6s\n",
      "168:\tlearn: 0.3727640\ttotal: 4.58s\tremaining: 22.5s\n",
      "169:\tlearn: 0.3724209\ttotal: 4.61s\tremaining: 22.5s\n",
      "170:\tlearn: 0.3717749\ttotal: 4.63s\tremaining: 22.5s\n",
      "171:\tlearn: 0.3712772\ttotal: 4.66s\tremaining: 22.4s\n",
      "172:\tlearn: 0.3709776\ttotal: 4.68s\tremaining: 22.4s\n",
      "173:\tlearn: 0.3706704\ttotal: 4.71s\tremaining: 22.4s\n",
      "174:\tlearn: 0.3702439\ttotal: 4.74s\tremaining: 22.3s\n",
      "175:\tlearn: 0.3699020\ttotal: 4.76s\tremaining: 22.3s\n",
      "176:\tlearn: 0.3695510\ttotal: 4.79s\tremaining: 22.3s\n",
      "177:\tlearn: 0.3690202\ttotal: 4.82s\tremaining: 22.2s\n",
      "178:\tlearn: 0.3686993\ttotal: 4.84s\tremaining: 22.2s\n",
      "179:\tlearn: 0.3683394\ttotal: 4.87s\tremaining: 22.2s\n",
      "180:\tlearn: 0.3679661\ttotal: 4.89s\tremaining: 22.2s\n",
      "181:\tlearn: 0.3676890\ttotal: 4.92s\tremaining: 22.1s\n",
      "182:\tlearn: 0.3672262\ttotal: 4.95s\tremaining: 22.1s\n",
      "183:\tlearn: 0.3668643\ttotal: 4.97s\tremaining: 22.1s\n",
      "184:\tlearn: 0.3666609\ttotal: 5s\tremaining: 22s\n",
      "185:\tlearn: 0.3661097\ttotal: 5.03s\tremaining: 22s\n",
      "186:\tlearn: 0.3657349\ttotal: 5.05s\tremaining: 22s\n",
      "187:\tlearn: 0.3652992\ttotal: 5.08s\tremaining: 21.9s\n",
      "188:\tlearn: 0.3649438\ttotal: 5.1s\tremaining: 21.9s\n",
      "189:\tlearn: 0.3644328\ttotal: 5.13s\tremaining: 21.9s\n",
      "190:\tlearn: 0.3640864\ttotal: 5.15s\tremaining: 21.8s\n",
      "191:\tlearn: 0.3636211\ttotal: 5.18s\tremaining: 21.8s\n",
      "192:\tlearn: 0.3633013\ttotal: 5.2s\tremaining: 21.8s\n",
      "193:\tlearn: 0.3628842\ttotal: 5.23s\tremaining: 21.7s\n",
      "194:\tlearn: 0.3625180\ttotal: 5.26s\tremaining: 21.7s\n",
      "195:\tlearn: 0.3621128\ttotal: 5.28s\tremaining: 21.7s\n",
      "196:\tlearn: 0.3617589\ttotal: 5.31s\tremaining: 21.6s\n",
      "197:\tlearn: 0.3613014\ttotal: 5.33s\tremaining: 21.6s\n",
      "198:\tlearn: 0.3611550\ttotal: 5.36s\tremaining: 21.6s\n",
      "199:\tlearn: 0.3607584\ttotal: 5.39s\tremaining: 21.5s\n",
      "200:\tlearn: 0.3603813\ttotal: 5.41s\tremaining: 21.5s\n",
      "201:\tlearn: 0.3600267\ttotal: 5.44s\tremaining: 21.5s\n",
      "202:\tlearn: 0.3597589\ttotal: 5.47s\tremaining: 21.5s\n",
      "203:\tlearn: 0.3592537\ttotal: 5.49s\tremaining: 21.4s\n",
      "204:\tlearn: 0.3589687\ttotal: 5.51s\tremaining: 21.4s\n",
      "205:\tlearn: 0.3586076\ttotal: 5.54s\tremaining: 21.4s\n",
      "206:\tlearn: 0.3583498\ttotal: 5.56s\tremaining: 21.3s\n",
      "207:\tlearn: 0.3580387\ttotal: 5.59s\tremaining: 21.3s\n",
      "208:\tlearn: 0.3575591\ttotal: 5.62s\tremaining: 21.3s\n",
      "209:\tlearn: 0.3570077\ttotal: 5.65s\tremaining: 21.3s\n",
      "210:\tlearn: 0.3567674\ttotal: 5.67s\tremaining: 21.2s\n",
      "211:\tlearn: 0.3564449\ttotal: 5.7s\tremaining: 21.2s\n",
      "212:\tlearn: 0.3561873\ttotal: 5.72s\tremaining: 21.1s\n",
      "213:\tlearn: 0.3556998\ttotal: 5.75s\tremaining: 21.1s\n",
      "214:\tlearn: 0.3552536\ttotal: 5.77s\tremaining: 21.1s\n",
      "215:\tlearn: 0.3549525\ttotal: 5.8s\tremaining: 21.1s\n",
      "216:\tlearn: 0.3545955\ttotal: 5.83s\tremaining: 21s\n",
      "217:\tlearn: 0.3540043\ttotal: 5.85s\tremaining: 21s\n",
      "218:\tlearn: 0.3535740\ttotal: 5.88s\tremaining: 21s\n",
      "219:\tlearn: 0.3533548\ttotal: 5.9s\tremaining: 20.9s\n",
      "220:\tlearn: 0.3530795\ttotal: 5.93s\tremaining: 20.9s\n",
      "221:\tlearn: 0.3528681\ttotal: 5.95s\tremaining: 20.9s\n",
      "222:\tlearn: 0.3525381\ttotal: 5.98s\tremaining: 20.8s\n",
      "223:\tlearn: 0.3522294\ttotal: 6s\tremaining: 20.8s\n",
      "224:\tlearn: 0.3519854\ttotal: 6.03s\tremaining: 20.8s\n",
      "225:\tlearn: 0.3516987\ttotal: 6.06s\tremaining: 20.8s\n",
      "226:\tlearn: 0.3513508\ttotal: 6.08s\tremaining: 20.7s\n",
      "227:\tlearn: 0.3509729\ttotal: 6.11s\tremaining: 20.7s\n",
      "228:\tlearn: 0.3505947\ttotal: 6.14s\tremaining: 20.7s\n",
      "229:\tlearn: 0.3500907\ttotal: 6.16s\tremaining: 20.6s\n",
      "230:\tlearn: 0.3498097\ttotal: 6.19s\tremaining: 20.6s\n",
      "231:\tlearn: 0.3494445\ttotal: 6.21s\tremaining: 20.6s\n",
      "232:\tlearn: 0.3491411\ttotal: 6.24s\tremaining: 20.5s\n",
      "233:\tlearn: 0.3489189\ttotal: 6.26s\tremaining: 20.5s\n",
      "234:\tlearn: 0.3485383\ttotal: 6.29s\tremaining: 20.5s\n",
      "235:\tlearn: 0.3482329\ttotal: 6.32s\tremaining: 20.4s\n",
      "236:\tlearn: 0.3479680\ttotal: 6.34s\tremaining: 20.4s\n",
      "237:\tlearn: 0.3477606\ttotal: 6.36s\tremaining: 20.4s\n",
      "238:\tlearn: 0.3473636\ttotal: 6.39s\tremaining: 20.3s\n",
      "239:\tlearn: 0.3471715\ttotal: 6.41s\tremaining: 20.3s\n",
      "240:\tlearn: 0.3468421\ttotal: 6.44s\tremaining: 20.3s\n",
      "241:\tlearn: 0.3463993\ttotal: 6.46s\tremaining: 20.2s\n",
      "242:\tlearn: 0.3461847\ttotal: 6.49s\tremaining: 20.2s\n",
      "243:\tlearn: 0.3458329\ttotal: 6.51s\tremaining: 20.2s\n",
      "244:\tlearn: 0.3455455\ttotal: 6.54s\tremaining: 20.1s\n",
      "245:\tlearn: 0.3451685\ttotal: 6.56s\tremaining: 20.1s\n",
      "246:\tlearn: 0.3446822\ttotal: 6.59s\tremaining: 20.1s\n",
      "247:\tlearn: 0.3444287\ttotal: 6.61s\tremaining: 20.1s\n",
      "248:\tlearn: 0.3441402\ttotal: 6.64s\tremaining: 20s\n",
      "249:\tlearn: 0.3439048\ttotal: 6.67s\tremaining: 20s\n",
      "250:\tlearn: 0.3434964\ttotal: 6.69s\tremaining: 20s\n",
      "251:\tlearn: 0.3430999\ttotal: 6.72s\tremaining: 19.9s\n",
      "252:\tlearn: 0.3429489\ttotal: 6.74s\tremaining: 19.9s\n",
      "253:\tlearn: 0.3427345\ttotal: 6.77s\tremaining: 19.9s\n",
      "254:\tlearn: 0.3423185\ttotal: 6.8s\tremaining: 19.9s\n",
      "255:\tlearn: 0.3419368\ttotal: 6.82s\tremaining: 19.8s\n",
      "256:\tlearn: 0.3417472\ttotal: 6.85s\tremaining: 19.8s\n",
      "257:\tlearn: 0.3413634\ttotal: 6.88s\tremaining: 19.8s\n",
      "258:\tlearn: 0.3409215\ttotal: 6.9s\tremaining: 19.8s\n",
      "259:\tlearn: 0.3405693\ttotal: 6.93s\tremaining: 19.7s\n",
      "260:\tlearn: 0.3400428\ttotal: 6.96s\tremaining: 19.7s\n",
      "261:\tlearn: 0.3395423\ttotal: 6.99s\tremaining: 19.7s\n",
      "262:\tlearn: 0.3392081\ttotal: 7.02s\tremaining: 19.7s\n",
      "263:\tlearn: 0.3388204\ttotal: 7.04s\tremaining: 19.6s\n",
      "264:\tlearn: 0.3385595\ttotal: 7.07s\tremaining: 19.6s\n",
      "265:\tlearn: 0.3383585\ttotal: 7.1s\tremaining: 19.6s\n",
      "266:\tlearn: 0.3380482\ttotal: 7.12s\tremaining: 19.6s\n",
      "267:\tlearn: 0.3376757\ttotal: 7.15s\tremaining: 19.5s\n",
      "268:\tlearn: 0.3373802\ttotal: 7.17s\tremaining: 19.5s\n",
      "269:\tlearn: 0.3369892\ttotal: 7.2s\tremaining: 19.5s\n",
      "270:\tlearn: 0.3363855\ttotal: 7.23s\tremaining: 19.4s\n",
      "271:\tlearn: 0.3361134\ttotal: 7.25s\tremaining: 19.4s\n",
      "272:\tlearn: 0.3357501\ttotal: 7.28s\tremaining: 19.4s\n",
      "273:\tlearn: 0.3355599\ttotal: 7.31s\tremaining: 19.4s\n",
      "274:\tlearn: 0.3352336\ttotal: 7.33s\tremaining: 19.3s\n",
      "275:\tlearn: 0.3349663\ttotal: 7.36s\tremaining: 19.3s\n",
      "276:\tlearn: 0.3347319\ttotal: 7.38s\tremaining: 19.3s\n",
      "277:\tlearn: 0.3344783\ttotal: 7.41s\tremaining: 19.3s\n",
      "278:\tlearn: 0.3340382\ttotal: 7.44s\tremaining: 19.2s\n",
      "279:\tlearn: 0.3334391\ttotal: 7.46s\tremaining: 19.2s\n",
      "280:\tlearn: 0.3333062\ttotal: 7.49s\tremaining: 19.2s\n",
      "281:\tlearn: 0.3330229\ttotal: 7.51s\tremaining: 19.1s\n",
      "282:\tlearn: 0.3327077\ttotal: 7.54s\tremaining: 19.1s\n",
      "283:\tlearn: 0.3324390\ttotal: 7.57s\tremaining: 19.1s\n",
      "284:\tlearn: 0.3321518\ttotal: 7.59s\tremaining: 19s\n",
      "285:\tlearn: 0.3318597\ttotal: 7.62s\tremaining: 19s\n",
      "286:\tlearn: 0.3316014\ttotal: 7.64s\tremaining: 19s\n",
      "287:\tlearn: 0.3314379\ttotal: 7.67s\tremaining: 19s\n",
      "288:\tlearn: 0.3310759\ttotal: 7.69s\tremaining: 18.9s\n",
      "289:\tlearn: 0.3308377\ttotal: 7.71s\tremaining: 18.9s\n",
      "290:\tlearn: 0.3306094\ttotal: 7.74s\tremaining: 18.9s\n",
      "291:\tlearn: 0.3302600\ttotal: 7.77s\tremaining: 18.8s\n",
      "292:\tlearn: 0.3298634\ttotal: 7.79s\tremaining: 18.8s\n",
      "293:\tlearn: 0.3295639\ttotal: 7.82s\tremaining: 18.8s\n",
      "294:\tlearn: 0.3290580\ttotal: 7.85s\tremaining: 18.8s\n",
      "295:\tlearn: 0.3287665\ttotal: 7.87s\tremaining: 18.7s\n",
      "296:\tlearn: 0.3284845\ttotal: 7.9s\tremaining: 18.7s\n",
      "297:\tlearn: 0.3280702\ttotal: 7.92s\tremaining: 18.7s\n",
      "298:\tlearn: 0.3276825\ttotal: 7.95s\tremaining: 18.6s\n",
      "299:\tlearn: 0.3272523\ttotal: 7.98s\tremaining: 18.6s\n",
      "300:\tlearn: 0.3270174\ttotal: 8s\tremaining: 18.6s\n",
      "301:\tlearn: 0.3267263\ttotal: 8.03s\tremaining: 18.6s\n",
      "302:\tlearn: 0.3264862\ttotal: 8.06s\tremaining: 18.5s\n",
      "303:\tlearn: 0.3262333\ttotal: 8.08s\tremaining: 18.5s\n",
      "304:\tlearn: 0.3256972\ttotal: 8.11s\tremaining: 18.5s\n",
      "305:\tlearn: 0.3254178\ttotal: 8.14s\tremaining: 18.5s\n",
      "306:\tlearn: 0.3250886\ttotal: 8.16s\tremaining: 18.4s\n",
      "307:\tlearn: 0.3248738\ttotal: 8.19s\tremaining: 18.4s\n",
      "308:\tlearn: 0.3244208\ttotal: 8.22s\tremaining: 18.4s\n",
      "309:\tlearn: 0.3240088\ttotal: 8.24s\tremaining: 18.3s\n",
      "310:\tlearn: 0.3237127\ttotal: 8.27s\tremaining: 18.3s\n",
      "311:\tlearn: 0.3234506\ttotal: 8.29s\tremaining: 18.3s\n",
      "312:\tlearn: 0.3231249\ttotal: 8.32s\tremaining: 18.3s\n",
      "313:\tlearn: 0.3226861\ttotal: 8.35s\tremaining: 18.2s\n",
      "314:\tlearn: 0.3224716\ttotal: 8.38s\tremaining: 18.2s\n",
      "315:\tlearn: 0.3220541\ttotal: 8.4s\tremaining: 18.2s\n",
      "316:\tlearn: 0.3219621\ttotal: 8.43s\tremaining: 18.2s\n",
      "317:\tlearn: 0.3215579\ttotal: 8.45s\tremaining: 18.1s\n",
      "318:\tlearn: 0.3212201\ttotal: 8.48s\tremaining: 18.1s\n",
      "319:\tlearn: 0.3209408\ttotal: 8.5s\tremaining: 18.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320:\tlearn: 0.3205564\ttotal: 8.53s\tremaining: 18s\n",
      "321:\tlearn: 0.3202377\ttotal: 8.56s\tremaining: 18s\n",
      "322:\tlearn: 0.3199703\ttotal: 8.58s\tremaining: 18s\n",
      "323:\tlearn: 0.3197922\ttotal: 8.61s\tremaining: 18s\n",
      "324:\tlearn: 0.3194197\ttotal: 8.63s\tremaining: 17.9s\n",
      "325:\tlearn: 0.3191960\ttotal: 8.65s\tremaining: 17.9s\n",
      "326:\tlearn: 0.3186100\ttotal: 8.68s\tremaining: 17.9s\n",
      "327:\tlearn: 0.3183780\ttotal: 8.71s\tremaining: 17.8s\n",
      "328:\tlearn: 0.3180751\ttotal: 8.74s\tremaining: 17.8s\n",
      "329:\tlearn: 0.3177007\ttotal: 8.76s\tremaining: 17.8s\n",
      "330:\tlearn: 0.3173519\ttotal: 8.79s\tremaining: 17.8s\n",
      "331:\tlearn: 0.3169965\ttotal: 8.81s\tremaining: 17.7s\n",
      "332:\tlearn: 0.3167695\ttotal: 8.84s\tremaining: 17.7s\n",
      "333:\tlearn: 0.3165371\ttotal: 8.86s\tremaining: 17.7s\n",
      "334:\tlearn: 0.3163419\ttotal: 8.89s\tremaining: 17.6s\n",
      "335:\tlearn: 0.3160390\ttotal: 8.91s\tremaining: 17.6s\n",
      "336:\tlearn: 0.3156659\ttotal: 8.94s\tremaining: 17.6s\n",
      "337:\tlearn: 0.3151807\ttotal: 8.97s\tremaining: 17.6s\n",
      "338:\tlearn: 0.3149029\ttotal: 9s\tremaining: 17.5s\n",
      "339:\tlearn: 0.3146657\ttotal: 9.02s\tremaining: 17.5s\n",
      "340:\tlearn: 0.3143680\ttotal: 9.05s\tremaining: 17.5s\n",
      "341:\tlearn: 0.3140400\ttotal: 9.07s\tremaining: 17.5s\n",
      "342:\tlearn: 0.3137151\ttotal: 9.1s\tremaining: 17.4s\n",
      "343:\tlearn: 0.3133611\ttotal: 9.13s\tremaining: 17.4s\n",
      "344:\tlearn: 0.3130099\ttotal: 9.16s\tremaining: 17.4s\n",
      "345:\tlearn: 0.3124883\ttotal: 9.18s\tremaining: 17.4s\n",
      "346:\tlearn: 0.3121444\ttotal: 9.21s\tremaining: 17.3s\n",
      "347:\tlearn: 0.3119009\ttotal: 9.23s\tremaining: 17.3s\n",
      "348:\tlearn: 0.3116132\ttotal: 9.26s\tremaining: 17.3s\n",
      "349:\tlearn: 0.3112140\ttotal: 9.29s\tremaining: 17.2s\n",
      "350:\tlearn: 0.3109694\ttotal: 9.31s\tremaining: 17.2s\n",
      "351:\tlearn: 0.3107356\ttotal: 9.33s\tremaining: 17.2s\n",
      "352:\tlearn: 0.3104232\ttotal: 9.36s\tremaining: 17.2s\n",
      "353:\tlearn: 0.3099089\ttotal: 9.39s\tremaining: 17.1s\n",
      "354:\tlearn: 0.3094143\ttotal: 9.42s\tremaining: 17.1s\n",
      "355:\tlearn: 0.3090241\ttotal: 9.44s\tremaining: 17.1s\n",
      "356:\tlearn: 0.3085936\ttotal: 9.47s\tremaining: 17.1s\n",
      "357:\tlearn: 0.3081363\ttotal: 9.49s\tremaining: 17s\n",
      "358:\tlearn: 0.3077433\ttotal: 9.52s\tremaining: 17s\n",
      "359:\tlearn: 0.3074600\ttotal: 9.54s\tremaining: 17s\n",
      "360:\tlearn: 0.3070553\ttotal: 9.57s\tremaining: 16.9s\n",
      "361:\tlearn: 0.3067787\ttotal: 9.6s\tremaining: 16.9s\n",
      "362:\tlearn: 0.3063406\ttotal: 9.62s\tremaining: 16.9s\n",
      "363:\tlearn: 0.3059952\ttotal: 9.65s\tremaining: 16.9s\n",
      "364:\tlearn: 0.3056460\ttotal: 9.68s\tremaining: 16.8s\n",
      "365:\tlearn: 0.3053083\ttotal: 9.71s\tremaining: 16.8s\n",
      "366:\tlearn: 0.3050306\ttotal: 9.73s\tremaining: 16.8s\n",
      "367:\tlearn: 0.3047470\ttotal: 9.75s\tremaining: 16.7s\n",
      "368:\tlearn: 0.3043596\ttotal: 9.78s\tremaining: 16.7s\n",
      "369:\tlearn: 0.3039746\ttotal: 9.81s\tremaining: 16.7s\n",
      "370:\tlearn: 0.3035889\ttotal: 9.83s\tremaining: 16.7s\n",
      "371:\tlearn: 0.3032685\ttotal: 9.86s\tremaining: 16.6s\n",
      "372:\tlearn: 0.3030216\ttotal: 9.88s\tremaining: 16.6s\n",
      "373:\tlearn: 0.3025578\ttotal: 9.91s\tremaining: 16.6s\n",
      "374:\tlearn: 0.3021283\ttotal: 9.93s\tremaining: 16.6s\n",
      "375:\tlearn: 0.3018380\ttotal: 9.96s\tremaining: 16.5s\n",
      "376:\tlearn: 0.3016306\ttotal: 9.98s\tremaining: 16.5s\n",
      "377:\tlearn: 0.3012146\ttotal: 10s\tremaining: 16.5s\n",
      "378:\tlearn: 0.3008867\ttotal: 10s\tremaining: 16.4s\n",
      "379:\tlearn: 0.3006166\ttotal: 10.1s\tremaining: 16.4s\n",
      "380:\tlearn: 0.3001396\ttotal: 10.1s\tremaining: 16.4s\n",
      "381:\tlearn: 0.2998087\ttotal: 10.1s\tremaining: 16.4s\n",
      "382:\tlearn: 0.2994261\ttotal: 10.1s\tremaining: 16.3s\n",
      "383:\tlearn: 0.2990855\ttotal: 10.2s\tremaining: 16.3s\n",
      "384:\tlearn: 0.2986997\ttotal: 10.2s\tremaining: 16.3s\n",
      "385:\tlearn: 0.2985107\ttotal: 10.2s\tremaining: 16.3s\n",
      "386:\tlearn: 0.2979498\ttotal: 10.2s\tremaining: 16.2s\n",
      "387:\tlearn: 0.2977515\ttotal: 10.3s\tremaining: 16.2s\n",
      "388:\tlearn: 0.2973505\ttotal: 10.3s\tremaining: 16.2s\n",
      "389:\tlearn: 0.2969944\ttotal: 10.3s\tremaining: 16.1s\n",
      "390:\tlearn: 0.2964722\ttotal: 10.4s\tremaining: 16.1s\n",
      "391:\tlearn: 0.2960560\ttotal: 10.4s\tremaining: 16.1s\n",
      "392:\tlearn: 0.2956684\ttotal: 10.4s\tremaining: 16.1s\n",
      "393:\tlearn: 0.2954450\ttotal: 10.4s\tremaining: 16s\n",
      "394:\tlearn: 0.2950657\ttotal: 10.5s\tremaining: 16s\n",
      "395:\tlearn: 0.2946004\ttotal: 10.5s\tremaining: 16s\n",
      "396:\tlearn: 0.2943106\ttotal: 10.5s\tremaining: 16s\n",
      "397:\tlearn: 0.2940158\ttotal: 10.5s\tremaining: 15.9s\n",
      "398:\tlearn: 0.2937760\ttotal: 10.6s\tremaining: 15.9s\n",
      "399:\tlearn: 0.2935163\ttotal: 10.6s\tremaining: 15.9s\n",
      "400:\tlearn: 0.2931907\ttotal: 10.6s\tremaining: 15.9s\n",
      "401:\tlearn: 0.2928328\ttotal: 10.6s\tremaining: 15.8s\n",
      "402:\tlearn: 0.2926919\ttotal: 10.7s\tremaining: 15.8s\n",
      "403:\tlearn: 0.2923483\ttotal: 10.7s\tremaining: 15.8s\n",
      "404:\tlearn: 0.2920306\ttotal: 10.7s\tremaining: 15.7s\n",
      "405:\tlearn: 0.2917567\ttotal: 10.7s\tremaining: 15.7s\n",
      "406:\tlearn: 0.2913848\ttotal: 10.8s\tremaining: 15.7s\n",
      "407:\tlearn: 0.2910847\ttotal: 10.8s\tremaining: 15.7s\n",
      "408:\tlearn: 0.2906659\ttotal: 10.8s\tremaining: 15.6s\n",
      "409:\tlearn: 0.2901590\ttotal: 10.9s\tremaining: 15.6s\n",
      "410:\tlearn: 0.2899655\ttotal: 10.9s\tremaining: 15.6s\n",
      "411:\tlearn: 0.2897344\ttotal: 10.9s\tremaining: 15.6s\n",
      "412:\tlearn: 0.2894171\ttotal: 10.9s\tremaining: 15.5s\n",
      "413:\tlearn: 0.2891293\ttotal: 10.9s\tremaining: 15.5s\n",
      "414:\tlearn: 0.2886628\ttotal: 11s\tremaining: 15.5s\n",
      "415:\tlearn: 0.2883431\ttotal: 11s\tremaining: 15.4s\n",
      "416:\tlearn: 0.2879540\ttotal: 11s\tremaining: 15.4s\n",
      "417:\tlearn: 0.2877344\ttotal: 11.1s\tremaining: 15.4s\n",
      "418:\tlearn: 0.2873334\ttotal: 11.1s\tremaining: 15.4s\n",
      "419:\tlearn: 0.2871314\ttotal: 11.1s\tremaining: 15.3s\n",
      "420:\tlearn: 0.2869434\ttotal: 11.1s\tremaining: 15.3s\n",
      "421:\tlearn: 0.2865178\ttotal: 11.2s\tremaining: 15.3s\n",
      "422:\tlearn: 0.2861136\ttotal: 11.2s\tremaining: 15.3s\n",
      "423:\tlearn: 0.2858125\ttotal: 11.2s\tremaining: 15.2s\n",
      "424:\tlearn: 0.2856242\ttotal: 11.2s\tremaining: 15.2s\n",
      "425:\tlearn: 0.2852834\ttotal: 11.3s\tremaining: 15.2s\n",
      "426:\tlearn: 0.2849776\ttotal: 11.3s\tremaining: 15.1s\n",
      "427:\tlearn: 0.2847861\ttotal: 11.3s\tremaining: 15.1s\n",
      "428:\tlearn: 0.2845080\ttotal: 11.3s\tremaining: 15.1s\n",
      "429:\tlearn: 0.2841159\ttotal: 11.4s\tremaining: 15.1s\n",
      "430:\tlearn: 0.2838141\ttotal: 11.4s\tremaining: 15s\n",
      "431:\tlearn: 0.2834497\ttotal: 11.4s\tremaining: 15s\n",
      "432:\tlearn: 0.2831373\ttotal: 11.4s\tremaining: 15s\n",
      "433:\tlearn: 0.2827782\ttotal: 11.5s\tremaining: 15s\n",
      "434:\tlearn: 0.2824987\ttotal: 11.5s\tremaining: 14.9s\n",
      "435:\tlearn: 0.2820798\ttotal: 11.5s\tremaining: 14.9s\n",
      "436:\tlearn: 0.2817480\ttotal: 11.6s\tremaining: 14.9s\n",
      "437:\tlearn: 0.2816058\ttotal: 11.6s\tremaining: 14.9s\n",
      "438:\tlearn: 0.2813399\ttotal: 11.6s\tremaining: 14.8s\n",
      "439:\tlearn: 0.2810613\ttotal: 11.6s\tremaining: 14.8s\n",
      "440:\tlearn: 0.2807007\ttotal: 11.7s\tremaining: 14.8s\n",
      "441:\tlearn: 0.2804064\ttotal: 11.7s\tremaining: 14.7s\n",
      "442:\tlearn: 0.2800377\ttotal: 11.7s\tremaining: 14.7s\n",
      "443:\tlearn: 0.2797108\ttotal: 11.7s\tremaining: 14.7s\n",
      "444:\tlearn: 0.2793497\ttotal: 11.8s\tremaining: 14.7s\n",
      "445:\tlearn: 0.2791114\ttotal: 11.8s\tremaining: 14.6s\n",
      "446:\tlearn: 0.2787535\ttotal: 11.8s\tremaining: 14.6s\n",
      "447:\tlearn: 0.2783785\ttotal: 11.8s\tremaining: 14.6s\n",
      "448:\tlearn: 0.2780614\ttotal: 11.9s\tremaining: 14.6s\n",
      "449:\tlearn: 0.2779424\ttotal: 11.9s\tremaining: 14.5s\n",
      "450:\tlearn: 0.2777268\ttotal: 11.9s\tremaining: 14.5s\n",
      "451:\tlearn: 0.2774846\ttotal: 11.9s\tremaining: 14.5s\n",
      "452:\tlearn: 0.2772115\ttotal: 12s\tremaining: 14.4s\n",
      "453:\tlearn: 0.2769438\ttotal: 12s\tremaining: 14.4s\n",
      "454:\tlearn: 0.2765682\ttotal: 12s\tremaining: 14.4s\n",
      "455:\tlearn: 0.2762589\ttotal: 12s\tremaining: 14.4s\n",
      "456:\tlearn: 0.2758756\ttotal: 12.1s\tremaining: 14.3s\n",
      "457:\tlearn: 0.2754444\ttotal: 12.1s\tremaining: 14.3s\n",
      "458:\tlearn: 0.2749478\ttotal: 12.1s\tremaining: 14.3s\n",
      "459:\tlearn: 0.2747989\ttotal: 12.2s\tremaining: 14.3s\n",
      "460:\tlearn: 0.2745245\ttotal: 12.2s\tremaining: 14.2s\n",
      "461:\tlearn: 0.2741253\ttotal: 12.2s\tremaining: 14.2s\n",
      "462:\tlearn: 0.2737272\ttotal: 12.2s\tremaining: 14.2s\n",
      "463:\tlearn: 0.2734046\ttotal: 12.3s\tremaining: 14.2s\n",
      "464:\tlearn: 0.2732287\ttotal: 12.3s\tremaining: 14.1s\n",
      "465:\tlearn: 0.2727984\ttotal: 12.3s\tremaining: 14.1s\n",
      "466:\tlearn: 0.2724645\ttotal: 12.3s\tremaining: 14.1s\n",
      "467:\tlearn: 0.2722055\ttotal: 12.4s\tremaining: 14.1s\n",
      "468:\tlearn: 0.2718296\ttotal: 12.4s\tremaining: 14s\n",
      "469:\tlearn: 0.2716086\ttotal: 12.4s\tremaining: 14s\n",
      "470:\tlearn: 0.2713867\ttotal: 12.4s\tremaining: 14s\n",
      "471:\tlearn: 0.2710165\ttotal: 12.5s\tremaining: 13.9s\n",
      "472:\tlearn: 0.2707022\ttotal: 12.5s\tremaining: 13.9s\n",
      "473:\tlearn: 0.2703971\ttotal: 12.5s\tremaining: 13.9s\n",
      "474:\tlearn: 0.2700529\ttotal: 12.5s\tremaining: 13.9s\n",
      "475:\tlearn: 0.2697557\ttotal: 12.6s\tremaining: 13.8s\n",
      "476:\tlearn: 0.2695144\ttotal: 12.6s\tremaining: 13.8s\n",
      "477:\tlearn: 0.2691951\ttotal: 12.6s\tremaining: 13.8s\n",
      "478:\tlearn: 0.2687055\ttotal: 12.7s\tremaining: 13.8s\n",
      "479:\tlearn: 0.2683881\ttotal: 12.7s\tremaining: 13.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480:\tlearn: 0.2680291\ttotal: 12.7s\tremaining: 13.7s\n",
      "481:\tlearn: 0.2678184\ttotal: 12.7s\tremaining: 13.7s\n",
      "482:\tlearn: 0.2675411\ttotal: 12.8s\tremaining: 13.7s\n",
      "483:\tlearn: 0.2671193\ttotal: 12.8s\tremaining: 13.6s\n",
      "484:\tlearn: 0.2668452\ttotal: 12.8s\tremaining: 13.6s\n",
      "485:\tlearn: 0.2666058\ttotal: 12.8s\tremaining: 13.6s\n",
      "486:\tlearn: 0.2661925\ttotal: 12.9s\tremaining: 13.6s\n",
      "487:\tlearn: 0.2657726\ttotal: 12.9s\tremaining: 13.5s\n",
      "488:\tlearn: 0.2655118\ttotal: 12.9s\tremaining: 13.5s\n",
      "489:\tlearn: 0.2653282\ttotal: 12.9s\tremaining: 13.5s\n",
      "490:\tlearn: 0.2649655\ttotal: 13s\tremaining: 13.5s\n",
      "491:\tlearn: 0.2646690\ttotal: 13s\tremaining: 13.4s\n",
      "492:\tlearn: 0.2643596\ttotal: 13s\tremaining: 13.4s\n",
      "493:\tlearn: 0.2640415\ttotal: 13.1s\tremaining: 13.4s\n",
      "494:\tlearn: 0.2637755\ttotal: 13.1s\tremaining: 13.3s\n",
      "495:\tlearn: 0.2634494\ttotal: 13.1s\tremaining: 13.3s\n",
      "496:\tlearn: 0.2630479\ttotal: 13.1s\tremaining: 13.3s\n",
      "497:\tlearn: 0.2627917\ttotal: 13.2s\tremaining: 13.3s\n",
      "498:\tlearn: 0.2624624\ttotal: 13.2s\tremaining: 13.2s\n",
      "499:\tlearn: 0.2622828\ttotal: 13.2s\tremaining: 13.2s\n",
      "500:\tlearn: 0.2619501\ttotal: 13.2s\tremaining: 13.2s\n",
      "501:\tlearn: 0.2617705\ttotal: 13.3s\tremaining: 13.2s\n",
      "502:\tlearn: 0.2613405\ttotal: 13.3s\tremaining: 13.1s\n",
      "503:\tlearn: 0.2610990\ttotal: 13.3s\tremaining: 13.1s\n",
      "504:\tlearn: 0.2609029\ttotal: 13.3s\tremaining: 13.1s\n",
      "505:\tlearn: 0.2606273\ttotal: 13.4s\tremaining: 13s\n",
      "506:\tlearn: 0.2603208\ttotal: 13.4s\tremaining: 13s\n",
      "507:\tlearn: 0.2599563\ttotal: 13.4s\tremaining: 13s\n",
      "508:\tlearn: 0.2598565\ttotal: 13.4s\tremaining: 13s\n",
      "509:\tlearn: 0.2595287\ttotal: 13.5s\tremaining: 12.9s\n",
      "510:\tlearn: 0.2592232\ttotal: 13.5s\tremaining: 12.9s\n",
      "511:\tlearn: 0.2587183\ttotal: 13.5s\tremaining: 12.9s\n",
      "512:\tlearn: 0.2585226\ttotal: 13.5s\tremaining: 12.9s\n",
      "513:\tlearn: 0.2583492\ttotal: 13.6s\tremaining: 12.8s\n",
      "514:\tlearn: 0.2580445\ttotal: 13.6s\tremaining: 12.8s\n",
      "515:\tlearn: 0.2576696\ttotal: 13.6s\tremaining: 12.8s\n",
      "516:\tlearn: 0.2573271\ttotal: 13.7s\tremaining: 12.8s\n",
      "517:\tlearn: 0.2569771\ttotal: 13.7s\tremaining: 12.7s\n",
      "518:\tlearn: 0.2567351\ttotal: 13.7s\tremaining: 12.7s\n",
      "519:\tlearn: 0.2564057\ttotal: 13.7s\tremaining: 12.7s\n",
      "520:\tlearn: 0.2561039\ttotal: 13.8s\tremaining: 12.6s\n",
      "521:\tlearn: 0.2558865\ttotal: 13.8s\tremaining: 12.6s\n",
      "522:\tlearn: 0.2555525\ttotal: 13.8s\tremaining: 12.6s\n",
      "523:\tlearn: 0.2552335\ttotal: 13.8s\tremaining: 12.6s\n",
      "524:\tlearn: 0.2549154\ttotal: 13.9s\tremaining: 12.5s\n",
      "525:\tlearn: 0.2545868\ttotal: 13.9s\tremaining: 12.5s\n",
      "526:\tlearn: 0.2542569\ttotal: 13.9s\tremaining: 12.5s\n",
      "527:\tlearn: 0.2538332\ttotal: 13.9s\tremaining: 12.5s\n",
      "528:\tlearn: 0.2536971\ttotal: 14s\tremaining: 12.4s\n",
      "529:\tlearn: 0.2533082\ttotal: 14s\tremaining: 12.4s\n",
      "530:\tlearn: 0.2529644\ttotal: 14s\tremaining: 12.4s\n",
      "531:\tlearn: 0.2527651\ttotal: 14.1s\tremaining: 12.4s\n",
      "532:\tlearn: 0.2524386\ttotal: 14.1s\tremaining: 12.3s\n",
      "533:\tlearn: 0.2521669\ttotal: 14.1s\tremaining: 12.3s\n",
      "534:\tlearn: 0.2519452\ttotal: 14.1s\tremaining: 12.3s\n",
      "535:\tlearn: 0.2517949\ttotal: 14.2s\tremaining: 12.3s\n",
      "536:\tlearn: 0.2516389\ttotal: 14.2s\tremaining: 12.2s\n",
      "537:\tlearn: 0.2512818\ttotal: 14.2s\tremaining: 12.2s\n",
      "538:\tlearn: 0.2509132\ttotal: 14.2s\tremaining: 12.2s\n",
      "539:\tlearn: 0.2505383\ttotal: 14.3s\tremaining: 12.1s\n",
      "540:\tlearn: 0.2501457\ttotal: 14.3s\tremaining: 12.1s\n",
      "541:\tlearn: 0.2499573\ttotal: 14.3s\tremaining: 12.1s\n",
      "542:\tlearn: 0.2496502\ttotal: 14.3s\tremaining: 12.1s\n",
      "543:\tlearn: 0.2494803\ttotal: 14.4s\tremaining: 12s\n",
      "544:\tlearn: 0.2492675\ttotal: 14.4s\tremaining: 12s\n",
      "545:\tlearn: 0.2490265\ttotal: 14.4s\tremaining: 12s\n",
      "546:\tlearn: 0.2487226\ttotal: 14.4s\tremaining: 12s\n",
      "547:\tlearn: 0.2484249\ttotal: 14.5s\tremaining: 11.9s\n",
      "548:\tlearn: 0.2481295\ttotal: 14.5s\tremaining: 11.9s\n",
      "549:\tlearn: 0.2478614\ttotal: 14.5s\tremaining: 11.9s\n",
      "550:\tlearn: 0.2475486\ttotal: 14.5s\tremaining: 11.8s\n",
      "551:\tlearn: 0.2472110\ttotal: 14.6s\tremaining: 11.8s\n",
      "552:\tlearn: 0.2467794\ttotal: 14.6s\tremaining: 11.8s\n",
      "553:\tlearn: 0.2465642\ttotal: 14.6s\tremaining: 11.8s\n",
      "554:\tlearn: 0.2464560\ttotal: 14.6s\tremaining: 11.7s\n",
      "555:\tlearn: 0.2462920\ttotal: 14.7s\tremaining: 11.7s\n",
      "556:\tlearn: 0.2460410\ttotal: 14.7s\tremaining: 11.7s\n",
      "557:\tlearn: 0.2458039\ttotal: 14.7s\tremaining: 11.7s\n",
      "558:\tlearn: 0.2454734\ttotal: 14.7s\tremaining: 11.6s\n",
      "559:\tlearn: 0.2452494\ttotal: 14.8s\tremaining: 11.6s\n",
      "560:\tlearn: 0.2449849\ttotal: 14.8s\tremaining: 11.6s\n",
      "561:\tlearn: 0.2446295\ttotal: 14.8s\tremaining: 11.6s\n",
      "562:\tlearn: 0.2444215\ttotal: 14.9s\tremaining: 11.5s\n",
      "563:\tlearn: 0.2442205\ttotal: 14.9s\tremaining: 11.5s\n",
      "564:\tlearn: 0.2439001\ttotal: 14.9s\tremaining: 11.5s\n",
      "565:\tlearn: 0.2436314\ttotal: 14.9s\tremaining: 11.4s\n",
      "566:\tlearn: 0.2433038\ttotal: 15s\tremaining: 11.4s\n",
      "567:\tlearn: 0.2429288\ttotal: 15s\tremaining: 11.4s\n",
      "568:\tlearn: 0.2425608\ttotal: 15s\tremaining: 11.4s\n",
      "569:\tlearn: 0.2422579\ttotal: 15s\tremaining: 11.3s\n",
      "570:\tlearn: 0.2419299\ttotal: 15.1s\tremaining: 11.3s\n",
      "571:\tlearn: 0.2417013\ttotal: 15.1s\tremaining: 11.3s\n",
      "572:\tlearn: 0.2413562\ttotal: 15.1s\tremaining: 11.3s\n",
      "573:\tlearn: 0.2410716\ttotal: 15.1s\tremaining: 11.2s\n",
      "574:\tlearn: 0.2408904\ttotal: 15.2s\tremaining: 11.2s\n",
      "575:\tlearn: 0.2406885\ttotal: 15.2s\tremaining: 11.2s\n",
      "576:\tlearn: 0.2403538\ttotal: 15.2s\tremaining: 11.2s\n",
      "577:\tlearn: 0.2399806\ttotal: 15.2s\tremaining: 11.1s\n",
      "578:\tlearn: 0.2397683\ttotal: 15.3s\tremaining: 11.1s\n",
      "579:\tlearn: 0.2396019\ttotal: 15.3s\tremaining: 11.1s\n",
      "580:\tlearn: 0.2394191\ttotal: 15.3s\tremaining: 11s\n",
      "581:\tlearn: 0.2392135\ttotal: 15.3s\tremaining: 11s\n",
      "582:\tlearn: 0.2390141\ttotal: 15.4s\tremaining: 11s\n",
      "583:\tlearn: 0.2388071\ttotal: 15.4s\tremaining: 11s\n",
      "584:\tlearn: 0.2386127\ttotal: 15.4s\tremaining: 10.9s\n",
      "585:\tlearn: 0.2382545\ttotal: 15.4s\tremaining: 10.9s\n",
      "586:\tlearn: 0.2379942\ttotal: 15.5s\tremaining: 10.9s\n",
      "587:\tlearn: 0.2375664\ttotal: 15.5s\tremaining: 10.9s\n",
      "588:\tlearn: 0.2372633\ttotal: 15.5s\tremaining: 10.8s\n",
      "589:\tlearn: 0.2369683\ttotal: 15.6s\tremaining: 10.8s\n",
      "590:\tlearn: 0.2367375\ttotal: 15.6s\tremaining: 10.8s\n",
      "591:\tlearn: 0.2364062\ttotal: 15.6s\tremaining: 10.8s\n",
      "592:\tlearn: 0.2360463\ttotal: 15.6s\tremaining: 10.7s\n",
      "593:\tlearn: 0.2357932\ttotal: 15.7s\tremaining: 10.7s\n",
      "594:\tlearn: 0.2354837\ttotal: 15.7s\tremaining: 10.7s\n",
      "595:\tlearn: 0.2351309\ttotal: 15.7s\tremaining: 10.7s\n",
      "596:\tlearn: 0.2348686\ttotal: 15.7s\tremaining: 10.6s\n",
      "597:\tlearn: 0.2346502\ttotal: 15.8s\tremaining: 10.6s\n",
      "598:\tlearn: 0.2343657\ttotal: 15.8s\tremaining: 10.6s\n",
      "599:\tlearn: 0.2340702\ttotal: 15.8s\tremaining: 10.6s\n",
      "600:\tlearn: 0.2338031\ttotal: 15.9s\tremaining: 10.5s\n",
      "601:\tlearn: 0.2335051\ttotal: 15.9s\tremaining: 10.5s\n",
      "602:\tlearn: 0.2332624\ttotal: 15.9s\tremaining: 10.5s\n",
      "603:\tlearn: 0.2329646\ttotal: 15.9s\tremaining: 10.4s\n",
      "604:\tlearn: 0.2326575\ttotal: 16s\tremaining: 10.4s\n",
      "605:\tlearn: 0.2325389\ttotal: 16s\tremaining: 10.4s\n",
      "606:\tlearn: 0.2323597\ttotal: 16s\tremaining: 10.4s\n",
      "607:\tlearn: 0.2321140\ttotal: 16s\tremaining: 10.3s\n",
      "608:\tlearn: 0.2318272\ttotal: 16.1s\tremaining: 10.3s\n",
      "609:\tlearn: 0.2315033\ttotal: 16.1s\tremaining: 10.3s\n",
      "610:\tlearn: 0.2312776\ttotal: 16.1s\tremaining: 10.3s\n",
      "611:\tlearn: 0.2310912\ttotal: 16.1s\tremaining: 10.2s\n",
      "612:\tlearn: 0.2309033\ttotal: 16.2s\tremaining: 10.2s\n",
      "613:\tlearn: 0.2305819\ttotal: 16.2s\tremaining: 10.2s\n",
      "614:\tlearn: 0.2303872\ttotal: 16.2s\tremaining: 10.2s\n",
      "615:\tlearn: 0.2301870\ttotal: 16.2s\tremaining: 10.1s\n",
      "616:\tlearn: 0.2298988\ttotal: 16.3s\tremaining: 10.1s\n",
      "617:\tlearn: 0.2296673\ttotal: 16.3s\tremaining: 10.1s\n",
      "618:\tlearn: 0.2293340\ttotal: 16.3s\tremaining: 10.1s\n",
      "619:\tlearn: 0.2291223\ttotal: 16.4s\tremaining: 10s\n",
      "620:\tlearn: 0.2289191\ttotal: 16.4s\tremaining: 10s\n",
      "621:\tlearn: 0.2287178\ttotal: 16.4s\tremaining: 9.97s\n",
      "622:\tlearn: 0.2285133\ttotal: 16.4s\tremaining: 9.94s\n",
      "623:\tlearn: 0.2282624\ttotal: 16.5s\tremaining: 9.91s\n",
      "624:\tlearn: 0.2280264\ttotal: 16.5s\tremaining: 9.89s\n",
      "625:\tlearn: 0.2276394\ttotal: 16.5s\tremaining: 9.86s\n",
      "626:\tlearn: 0.2272920\ttotal: 16.5s\tremaining: 9.84s\n",
      "627:\tlearn: 0.2271760\ttotal: 16.6s\tremaining: 9.81s\n",
      "628:\tlearn: 0.2269946\ttotal: 16.6s\tremaining: 9.78s\n",
      "629:\tlearn: 0.2267543\ttotal: 16.6s\tremaining: 9.76s\n",
      "630:\tlearn: 0.2263994\ttotal: 16.6s\tremaining: 9.73s\n",
      "631:\tlearn: 0.2261418\ttotal: 16.7s\tremaining: 9.7s\n",
      "632:\tlearn: 0.2257576\ttotal: 16.7s\tremaining: 9.68s\n",
      "633:\tlearn: 0.2255370\ttotal: 16.7s\tremaining: 9.65s\n",
      "634:\tlearn: 0.2251978\ttotal: 16.7s\tremaining: 9.63s\n",
      "635:\tlearn: 0.2248501\ttotal: 16.8s\tremaining: 9.6s\n",
      "636:\tlearn: 0.2247554\ttotal: 16.8s\tremaining: 9.57s\n",
      "637:\tlearn: 0.2245121\ttotal: 16.8s\tremaining: 9.54s\n",
      "638:\tlearn: 0.2242065\ttotal: 16.8s\tremaining: 9.52s\n",
      "639:\tlearn: 0.2240575\ttotal: 16.9s\tremaining: 9.49s\n",
      "640:\tlearn: 0.2239364\ttotal: 16.9s\tremaining: 9.46s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641:\tlearn: 0.2237479\ttotal: 16.9s\tremaining: 9.44s\n",
      "642:\tlearn: 0.2233537\ttotal: 16.9s\tremaining: 9.41s\n",
      "643:\tlearn: 0.2229622\ttotal: 17s\tremaining: 9.39s\n",
      "644:\tlearn: 0.2226125\ttotal: 17s\tremaining: 9.36s\n",
      "645:\tlearn: 0.2222921\ttotal: 17s\tremaining: 9.34s\n",
      "646:\tlearn: 0.2221682\ttotal: 17.1s\tremaining: 9.31s\n",
      "647:\tlearn: 0.2218614\ttotal: 17.1s\tremaining: 9.28s\n",
      "648:\tlearn: 0.2215247\ttotal: 17.1s\tremaining: 9.26s\n",
      "649:\tlearn: 0.2213935\ttotal: 17.1s\tremaining: 9.23s\n",
      "650:\tlearn: 0.2212096\ttotal: 17.2s\tremaining: 9.21s\n",
      "651:\tlearn: 0.2210771\ttotal: 17.2s\tremaining: 9.18s\n",
      "652:\tlearn: 0.2208112\ttotal: 17.2s\tremaining: 9.15s\n",
      "653:\tlearn: 0.2204886\ttotal: 17.2s\tremaining: 9.13s\n",
      "654:\tlearn: 0.2202713\ttotal: 17.3s\tremaining: 9.1s\n",
      "655:\tlearn: 0.2200946\ttotal: 17.3s\tremaining: 9.07s\n",
      "656:\tlearn: 0.2197678\ttotal: 17.3s\tremaining: 9.04s\n",
      "657:\tlearn: 0.2195565\ttotal: 17.4s\tremaining: 9.02s\n",
      "658:\tlearn: 0.2194268\ttotal: 17.4s\tremaining: 8.99s\n",
      "659:\tlearn: 0.2191647\ttotal: 17.4s\tremaining: 8.96s\n",
      "660:\tlearn: 0.2189623\ttotal: 17.4s\tremaining: 8.94s\n",
      "661:\tlearn: 0.2187864\ttotal: 17.5s\tremaining: 8.91s\n",
      "662:\tlearn: 0.2184978\ttotal: 17.5s\tremaining: 8.88s\n",
      "663:\tlearn: 0.2182925\ttotal: 17.5s\tremaining: 8.86s\n",
      "664:\tlearn: 0.2179523\ttotal: 17.5s\tremaining: 8.83s\n",
      "665:\tlearn: 0.2178654\ttotal: 17.6s\tremaining: 8.8s\n",
      "666:\tlearn: 0.2177248\ttotal: 17.6s\tremaining: 8.78s\n",
      "667:\tlearn: 0.2176044\ttotal: 17.6s\tremaining: 8.75s\n",
      "668:\tlearn: 0.2173292\ttotal: 17.6s\tremaining: 8.72s\n",
      "669:\tlearn: 0.2170724\ttotal: 17.7s\tremaining: 8.7s\n",
      "670:\tlearn: 0.2168322\ttotal: 17.7s\tremaining: 8.67s\n",
      "671:\tlearn: 0.2166162\ttotal: 17.7s\tremaining: 8.65s\n",
      "672:\tlearn: 0.2164195\ttotal: 17.7s\tremaining: 8.62s\n",
      "673:\tlearn: 0.2160565\ttotal: 17.8s\tremaining: 8.6s\n",
      "674:\tlearn: 0.2158271\ttotal: 17.8s\tremaining: 8.57s\n",
      "675:\tlearn: 0.2156757\ttotal: 17.8s\tremaining: 8.54s\n",
      "676:\tlearn: 0.2154922\ttotal: 17.8s\tremaining: 8.51s\n",
      "677:\tlearn: 0.2152861\ttotal: 17.9s\tremaining: 8.49s\n",
      "678:\tlearn: 0.2150829\ttotal: 17.9s\tremaining: 8.46s\n",
      "679:\tlearn: 0.2148580\ttotal: 17.9s\tremaining: 8.43s\n",
      "680:\tlearn: 0.2146965\ttotal: 17.9s\tremaining: 8.4s\n",
      "681:\tlearn: 0.2144434\ttotal: 18s\tremaining: 8.38s\n",
      "682:\tlearn: 0.2141169\ttotal: 18s\tremaining: 8.35s\n",
      "683:\tlearn: 0.2139899\ttotal: 18s\tremaining: 8.32s\n",
      "684:\tlearn: 0.2138084\ttotal: 18s\tremaining: 8.3s\n",
      "685:\tlearn: 0.2136975\ttotal: 18.1s\tremaining: 8.27s\n",
      "686:\tlearn: 0.2134302\ttotal: 18.1s\tremaining: 8.25s\n",
      "687:\tlearn: 0.2131612\ttotal: 18.1s\tremaining: 8.22s\n",
      "688:\tlearn: 0.2128990\ttotal: 18.2s\tremaining: 8.19s\n",
      "689:\tlearn: 0.2127585\ttotal: 18.2s\tremaining: 8.17s\n",
      "690:\tlearn: 0.2126593\ttotal: 18.2s\tremaining: 8.14s\n",
      "691:\tlearn: 0.2124905\ttotal: 18.2s\tremaining: 8.11s\n",
      "692:\tlearn: 0.2123812\ttotal: 18.3s\tremaining: 8.09s\n",
      "693:\tlearn: 0.2122584\ttotal: 18.3s\tremaining: 8.06s\n",
      "694:\tlearn: 0.2120507\ttotal: 18.3s\tremaining: 8.03s\n",
      "695:\tlearn: 0.2118406\ttotal: 18.3s\tremaining: 8.01s\n",
      "696:\tlearn: 0.2115719\ttotal: 18.4s\tremaining: 7.98s\n",
      "697:\tlearn: 0.2114924\ttotal: 18.4s\tremaining: 7.95s\n",
      "698:\tlearn: 0.2113618\ttotal: 18.4s\tremaining: 7.93s\n",
      "699:\tlearn: 0.2111354\ttotal: 18.4s\tremaining: 7.9s\n",
      "700:\tlearn: 0.2109269\ttotal: 18.5s\tremaining: 7.87s\n",
      "701:\tlearn: 0.2107661\ttotal: 18.5s\tremaining: 7.85s\n",
      "702:\tlearn: 0.2105545\ttotal: 18.5s\tremaining: 7.82s\n",
      "703:\tlearn: 0.2104611\ttotal: 18.5s\tremaining: 7.79s\n",
      "704:\tlearn: 0.2101754\ttotal: 18.6s\tremaining: 7.77s\n",
      "705:\tlearn: 0.2099402\ttotal: 18.6s\tremaining: 7.74s\n",
      "706:\tlearn: 0.2098017\ttotal: 18.6s\tremaining: 7.71s\n",
      "707:\tlearn: 0.2096062\ttotal: 18.6s\tremaining: 7.69s\n",
      "708:\tlearn: 0.2094090\ttotal: 18.7s\tremaining: 7.66s\n",
      "709:\tlearn: 0.2092178\ttotal: 18.7s\tremaining: 7.63s\n",
      "710:\tlearn: 0.2089676\ttotal: 18.7s\tremaining: 7.61s\n",
      "711:\tlearn: 0.2088434\ttotal: 18.7s\tremaining: 7.58s\n",
      "712:\tlearn: 0.2087038\ttotal: 18.8s\tremaining: 7.55s\n",
      "713:\tlearn: 0.2085423\ttotal: 18.8s\tremaining: 7.53s\n",
      "714:\tlearn: 0.2083973\ttotal: 18.8s\tremaining: 7.5s\n",
      "715:\tlearn: 0.2082609\ttotal: 18.8s\tremaining: 7.47s\n",
      "716:\tlearn: 0.2081405\ttotal: 18.9s\tremaining: 7.45s\n",
      "717:\tlearn: 0.2079075\ttotal: 18.9s\tremaining: 7.42s\n",
      "718:\tlearn: 0.2077103\ttotal: 18.9s\tremaining: 7.39s\n",
      "719:\tlearn: 0.2074954\ttotal: 18.9s\tremaining: 7.37s\n",
      "720:\tlearn: 0.2073115\ttotal: 19s\tremaining: 7.34s\n",
      "721:\tlearn: 0.2071353\ttotal: 19s\tremaining: 7.32s\n",
      "722:\tlearn: 0.2069439\ttotal: 19s\tremaining: 7.29s\n",
      "723:\tlearn: 0.2068119\ttotal: 19.1s\tremaining: 7.26s\n",
      "724:\tlearn: 0.2064983\ttotal: 19.1s\tremaining: 7.24s\n",
      "725:\tlearn: 0.2063382\ttotal: 19.1s\tremaining: 7.21s\n",
      "726:\tlearn: 0.2060528\ttotal: 19.1s\tremaining: 7.18s\n",
      "727:\tlearn: 0.2058515\ttotal: 19.2s\tremaining: 7.16s\n",
      "728:\tlearn: 0.2056982\ttotal: 19.2s\tremaining: 7.13s\n",
      "729:\tlearn: 0.2053750\ttotal: 19.2s\tremaining: 7.11s\n",
      "730:\tlearn: 0.2051836\ttotal: 19.2s\tremaining: 7.08s\n",
      "731:\tlearn: 0.2050058\ttotal: 19.3s\tremaining: 7.05s\n",
      "732:\tlearn: 0.2048103\ttotal: 19.3s\tremaining: 7.03s\n",
      "733:\tlearn: 0.2046169\ttotal: 19.3s\tremaining: 7s\n",
      "734:\tlearn: 0.2044281\ttotal: 19.3s\tremaining: 6.97s\n",
      "735:\tlearn: 0.2042586\ttotal: 19.4s\tremaining: 6.95s\n",
      "736:\tlearn: 0.2040728\ttotal: 19.4s\tremaining: 6.92s\n",
      "737:\tlearn: 0.2038081\ttotal: 19.4s\tremaining: 6.89s\n",
      "738:\tlearn: 0.2036286\ttotal: 19.4s\tremaining: 6.87s\n",
      "739:\tlearn: 0.2034542\ttotal: 19.5s\tremaining: 6.84s\n",
      "740:\tlearn: 0.2032972\ttotal: 19.5s\tremaining: 6.81s\n",
      "741:\tlearn: 0.2030605\ttotal: 19.5s\tremaining: 6.79s\n",
      "742:\tlearn: 0.2028206\ttotal: 19.5s\tremaining: 6.76s\n",
      "743:\tlearn: 0.2025818\ttotal: 19.6s\tremaining: 6.74s\n",
      "744:\tlearn: 0.2023403\ttotal: 19.6s\tremaining: 6.71s\n",
      "745:\tlearn: 0.2022318\ttotal: 19.6s\tremaining: 6.68s\n",
      "746:\tlearn: 0.2021297\ttotal: 19.7s\tremaining: 6.66s\n",
      "747:\tlearn: 0.2018510\ttotal: 19.7s\tremaining: 6.63s\n",
      "748:\tlearn: 0.2016080\ttotal: 19.7s\tremaining: 6.6s\n",
      "749:\tlearn: 0.2012979\ttotal: 19.7s\tremaining: 6.58s\n",
      "750:\tlearn: 0.2010591\ttotal: 19.8s\tremaining: 6.55s\n",
      "751:\tlearn: 0.2008598\ttotal: 19.8s\tremaining: 6.53s\n",
      "752:\tlearn: 0.2007385\ttotal: 19.8s\tremaining: 6.5s\n",
      "753:\tlearn: 0.2005254\ttotal: 19.8s\tremaining: 6.47s\n",
      "754:\tlearn: 0.2002368\ttotal: 19.9s\tremaining: 6.45s\n",
      "755:\tlearn: 0.1999738\ttotal: 19.9s\tremaining: 6.42s\n",
      "756:\tlearn: 0.1997083\ttotal: 19.9s\tremaining: 6.39s\n",
      "757:\tlearn: 0.1995644\ttotal: 19.9s\tremaining: 6.37s\n",
      "758:\tlearn: 0.1993378\ttotal: 20s\tremaining: 6.34s\n",
      "759:\tlearn: 0.1990680\ttotal: 20s\tremaining: 6.32s\n",
      "760:\tlearn: 0.1989182\ttotal: 20s\tremaining: 6.29s\n",
      "761:\tlearn: 0.1987654\ttotal: 20.1s\tremaining: 6.26s\n",
      "762:\tlearn: 0.1985386\ttotal: 20.1s\tremaining: 6.24s\n",
      "763:\tlearn: 0.1983364\ttotal: 20.1s\tremaining: 6.21s\n",
      "764:\tlearn: 0.1980315\ttotal: 20.1s\tremaining: 6.18s\n",
      "765:\tlearn: 0.1978521\ttotal: 20.2s\tremaining: 6.16s\n",
      "766:\tlearn: 0.1975850\ttotal: 20.2s\tremaining: 6.13s\n",
      "767:\tlearn: 0.1974136\ttotal: 20.2s\tremaining: 6.11s\n",
      "768:\tlearn: 0.1973576\ttotal: 20.2s\tremaining: 6.08s\n",
      "769:\tlearn: 0.1971976\ttotal: 20.3s\tremaining: 6.05s\n",
      "770:\tlearn: 0.1968628\ttotal: 20.3s\tremaining: 6.03s\n",
      "771:\tlearn: 0.1967177\ttotal: 20.3s\tremaining: 6s\n",
      "772:\tlearn: 0.1964923\ttotal: 20.3s\tremaining: 5.97s\n",
      "773:\tlearn: 0.1963196\ttotal: 20.4s\tremaining: 5.95s\n",
      "774:\tlearn: 0.1961400\ttotal: 20.4s\tremaining: 5.92s\n",
      "775:\tlearn: 0.1959422\ttotal: 20.4s\tremaining: 5.9s\n",
      "776:\tlearn: 0.1957103\ttotal: 20.5s\tremaining: 5.87s\n",
      "777:\tlearn: 0.1956038\ttotal: 20.5s\tremaining: 5.84s\n",
      "778:\tlearn: 0.1954157\ttotal: 20.5s\tremaining: 5.82s\n",
      "779:\tlearn: 0.1952694\ttotal: 20.5s\tremaining: 5.79s\n",
      "780:\tlearn: 0.1950838\ttotal: 20.6s\tremaining: 5.76s\n",
      "781:\tlearn: 0.1948761\ttotal: 20.6s\tremaining: 5.74s\n",
      "782:\tlearn: 0.1946991\ttotal: 20.6s\tremaining: 5.71s\n",
      "783:\tlearn: 0.1945485\ttotal: 20.6s\tremaining: 5.68s\n",
      "784:\tlearn: 0.1944918\ttotal: 20.7s\tremaining: 5.66s\n",
      "785:\tlearn: 0.1942951\ttotal: 20.7s\tremaining: 5.63s\n",
      "786:\tlearn: 0.1940208\ttotal: 20.7s\tremaining: 5.61s\n",
      "787:\tlearn: 0.1938262\ttotal: 20.7s\tremaining: 5.58s\n",
      "788:\tlearn: 0.1937353\ttotal: 20.8s\tremaining: 5.55s\n",
      "789:\tlearn: 0.1936173\ttotal: 20.8s\tremaining: 5.52s\n",
      "790:\tlearn: 0.1934168\ttotal: 20.8s\tremaining: 5.5s\n",
      "791:\tlearn: 0.1932440\ttotal: 20.8s\tremaining: 5.47s\n",
      "792:\tlearn: 0.1931369\ttotal: 20.9s\tremaining: 5.44s\n",
      "793:\tlearn: 0.1929495\ttotal: 20.9s\tremaining: 5.42s\n",
      "794:\tlearn: 0.1926944\ttotal: 20.9s\tremaining: 5.39s\n",
      "795:\tlearn: 0.1925578\ttotal: 20.9s\tremaining: 5.37s\n",
      "796:\tlearn: 0.1923596\ttotal: 21s\tremaining: 5.34s\n",
      "797:\tlearn: 0.1921504\ttotal: 21s\tremaining: 5.31s\n",
      "798:\tlearn: 0.1919406\ttotal: 21s\tremaining: 5.29s\n",
      "799:\tlearn: 0.1916042\ttotal: 21s\tremaining: 5.26s\n",
      "800:\tlearn: 0.1915013\ttotal: 21.1s\tremaining: 5.23s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801:\tlearn: 0.1912670\ttotal: 21.1s\tremaining: 5.21s\n",
      "802:\tlearn: 0.1911401\ttotal: 21.1s\tremaining: 5.18s\n",
      "803:\tlearn: 0.1910664\ttotal: 21.1s\tremaining: 5.16s\n",
      "804:\tlearn: 0.1908967\ttotal: 21.2s\tremaining: 5.13s\n",
      "805:\tlearn: 0.1907474\ttotal: 21.2s\tremaining: 5.1s\n",
      "806:\tlearn: 0.1905127\ttotal: 21.2s\tremaining: 5.08s\n",
      "807:\tlearn: 0.1903176\ttotal: 21.2s\tremaining: 5.05s\n",
      "808:\tlearn: 0.1901560\ttotal: 21.3s\tremaining: 5.02s\n",
      "809:\tlearn: 0.1899934\ttotal: 21.3s\tremaining: 5s\n",
      "810:\tlearn: 0.1898962\ttotal: 21.3s\tremaining: 4.97s\n",
      "811:\tlearn: 0.1897334\ttotal: 21.4s\tremaining: 4.94s\n",
      "812:\tlearn: 0.1896339\ttotal: 21.4s\tremaining: 4.92s\n",
      "813:\tlearn: 0.1895462\ttotal: 21.4s\tremaining: 4.89s\n",
      "814:\tlearn: 0.1894288\ttotal: 21.4s\tremaining: 4.86s\n",
      "815:\tlearn: 0.1892379\ttotal: 21.4s\tremaining: 4.84s\n",
      "816:\tlearn: 0.1891248\ttotal: 21.5s\tremaining: 4.81s\n",
      "817:\tlearn: 0.1889104\ttotal: 21.5s\tremaining: 4.78s\n",
      "818:\tlearn: 0.1887588\ttotal: 21.5s\tremaining: 4.76s\n",
      "819:\tlearn: 0.1886774\ttotal: 21.6s\tremaining: 4.73s\n",
      "820:\tlearn: 0.1885183\ttotal: 21.6s\tremaining: 4.7s\n",
      "821:\tlearn: 0.1882973\ttotal: 21.6s\tremaining: 4.68s\n",
      "822:\tlearn: 0.1880819\ttotal: 21.6s\tremaining: 4.65s\n",
      "823:\tlearn: 0.1878686\ttotal: 21.7s\tremaining: 4.63s\n",
      "824:\tlearn: 0.1876621\ttotal: 21.7s\tremaining: 4.6s\n",
      "825:\tlearn: 0.1875266\ttotal: 21.7s\tremaining: 4.57s\n",
      "826:\tlearn: 0.1873687\ttotal: 21.7s\tremaining: 4.55s\n",
      "827:\tlearn: 0.1872849\ttotal: 21.8s\tremaining: 4.52s\n",
      "828:\tlearn: 0.1871583\ttotal: 21.8s\tremaining: 4.49s\n",
      "829:\tlearn: 0.1868637\ttotal: 21.8s\tremaining: 4.47s\n",
      "830:\tlearn: 0.1866303\ttotal: 21.8s\tremaining: 4.44s\n",
      "831:\tlearn: 0.1864173\ttotal: 21.9s\tremaining: 4.42s\n",
      "832:\tlearn: 0.1862928\ttotal: 21.9s\tremaining: 4.39s\n",
      "833:\tlearn: 0.1860732\ttotal: 21.9s\tremaining: 4.36s\n",
      "834:\tlearn: 0.1858102\ttotal: 21.9s\tremaining: 4.34s\n",
      "835:\tlearn: 0.1855524\ttotal: 22s\tremaining: 4.31s\n",
      "836:\tlearn: 0.1854369\ttotal: 22s\tremaining: 4.28s\n",
      "837:\tlearn: 0.1852832\ttotal: 22s\tremaining: 4.26s\n",
      "838:\tlearn: 0.1851844\ttotal: 22s\tremaining: 4.23s\n",
      "839:\tlearn: 0.1849434\ttotal: 22.1s\tremaining: 4.2s\n",
      "840:\tlearn: 0.1847728\ttotal: 22.1s\tremaining: 4.18s\n",
      "841:\tlearn: 0.1845189\ttotal: 22.1s\tremaining: 4.15s\n",
      "842:\tlearn: 0.1842296\ttotal: 22.2s\tremaining: 4.13s\n",
      "843:\tlearn: 0.1840648\ttotal: 22.2s\tremaining: 4.1s\n",
      "844:\tlearn: 0.1839368\ttotal: 22.2s\tremaining: 4.07s\n",
      "845:\tlearn: 0.1837877\ttotal: 22.2s\tremaining: 4.05s\n",
      "846:\tlearn: 0.1835068\ttotal: 22.3s\tremaining: 4.02s\n",
      "847:\tlearn: 0.1832985\ttotal: 22.3s\tremaining: 3.99s\n",
      "848:\tlearn: 0.1831427\ttotal: 22.3s\tremaining: 3.97s\n",
      "849:\tlearn: 0.1829941\ttotal: 22.3s\tremaining: 3.94s\n",
      "850:\tlearn: 0.1829259\ttotal: 22.4s\tremaining: 3.92s\n",
      "851:\tlearn: 0.1828289\ttotal: 22.4s\tremaining: 3.89s\n",
      "852:\tlearn: 0.1827255\ttotal: 22.4s\tremaining: 3.86s\n",
      "853:\tlearn: 0.1825275\ttotal: 22.4s\tremaining: 3.84s\n",
      "854:\tlearn: 0.1823022\ttotal: 22.5s\tremaining: 3.81s\n",
      "855:\tlearn: 0.1821240\ttotal: 22.5s\tremaining: 3.78s\n",
      "856:\tlearn: 0.1819786\ttotal: 22.5s\tremaining: 3.76s\n",
      "857:\tlearn: 0.1817246\ttotal: 22.5s\tremaining: 3.73s\n",
      "858:\tlearn: 0.1815592\ttotal: 22.6s\tremaining: 3.71s\n",
      "859:\tlearn: 0.1814151\ttotal: 22.6s\tremaining: 3.68s\n",
      "860:\tlearn: 0.1813034\ttotal: 22.6s\tremaining: 3.65s\n",
      "861:\tlearn: 0.1811675\ttotal: 22.6s\tremaining: 3.63s\n",
      "862:\tlearn: 0.1810950\ttotal: 22.7s\tremaining: 3.6s\n",
      "863:\tlearn: 0.1810036\ttotal: 22.7s\tremaining: 3.57s\n",
      "864:\tlearn: 0.1808340\ttotal: 22.7s\tremaining: 3.55s\n",
      "865:\tlearn: 0.1806133\ttotal: 22.8s\tremaining: 3.52s\n",
      "866:\tlearn: 0.1805584\ttotal: 22.8s\tremaining: 3.49s\n",
      "867:\tlearn: 0.1804419\ttotal: 22.8s\tremaining: 3.47s\n",
      "868:\tlearn: 0.1803041\ttotal: 22.8s\tremaining: 3.44s\n",
      "869:\tlearn: 0.1801058\ttotal: 22.8s\tremaining: 3.41s\n",
      "870:\tlearn: 0.1800056\ttotal: 22.9s\tremaining: 3.39s\n",
      "871:\tlearn: 0.1799620\ttotal: 22.9s\tremaining: 3.36s\n",
      "872:\tlearn: 0.1797796\ttotal: 22.9s\tremaining: 3.33s\n",
      "873:\tlearn: 0.1795761\ttotal: 22.9s\tremaining: 3.31s\n",
      "874:\tlearn: 0.1793674\ttotal: 23s\tremaining: 3.28s\n",
      "875:\tlearn: 0.1791934\ttotal: 23s\tremaining: 3.25s\n",
      "876:\tlearn: 0.1789743\ttotal: 23s\tremaining: 3.23s\n",
      "877:\tlearn: 0.1788636\ttotal: 23.1s\tremaining: 3.2s\n",
      "878:\tlearn: 0.1786604\ttotal: 23.1s\tremaining: 3.18s\n",
      "879:\tlearn: 0.1783428\ttotal: 23.1s\tremaining: 3.15s\n",
      "880:\tlearn: 0.1782386\ttotal: 23.1s\tremaining: 3.12s\n",
      "881:\tlearn: 0.1780571\ttotal: 23.2s\tremaining: 3.1s\n",
      "882:\tlearn: 0.1778686\ttotal: 23.2s\tremaining: 3.07s\n",
      "883:\tlearn: 0.1777375\ttotal: 23.2s\tremaining: 3.04s\n",
      "884:\tlearn: 0.1775917\ttotal: 23.2s\tremaining: 3.02s\n",
      "885:\tlearn: 0.1774415\ttotal: 23.3s\tremaining: 2.99s\n",
      "886:\tlearn: 0.1773163\ttotal: 23.3s\tremaining: 2.97s\n",
      "887:\tlearn: 0.1771971\ttotal: 23.3s\tremaining: 2.94s\n",
      "888:\tlearn: 0.1771054\ttotal: 23.3s\tremaining: 2.91s\n",
      "889:\tlearn: 0.1768512\ttotal: 23.4s\tremaining: 2.89s\n",
      "890:\tlearn: 0.1767561\ttotal: 23.4s\tremaining: 2.86s\n",
      "891:\tlearn: 0.1766090\ttotal: 23.4s\tremaining: 2.83s\n",
      "892:\tlearn: 0.1764491\ttotal: 23.4s\tremaining: 2.81s\n",
      "893:\tlearn: 0.1761993\ttotal: 23.5s\tremaining: 2.78s\n",
      "894:\tlearn: 0.1760403\ttotal: 23.5s\tremaining: 2.75s\n",
      "895:\tlearn: 0.1759868\ttotal: 23.5s\tremaining: 2.73s\n",
      "896:\tlearn: 0.1758297\ttotal: 23.5s\tremaining: 2.7s\n",
      "897:\tlearn: 0.1756311\ttotal: 23.6s\tremaining: 2.68s\n",
      "898:\tlearn: 0.1755039\ttotal: 23.6s\tremaining: 2.65s\n",
      "899:\tlearn: 0.1753872\ttotal: 23.6s\tremaining: 2.62s\n",
      "900:\tlearn: 0.1752248\ttotal: 23.6s\tremaining: 2.6s\n",
      "901:\tlearn: 0.1750964\ttotal: 23.7s\tremaining: 2.57s\n",
      "902:\tlearn: 0.1750160\ttotal: 23.7s\tremaining: 2.54s\n",
      "903:\tlearn: 0.1748081\ttotal: 23.7s\tremaining: 2.52s\n",
      "904:\tlearn: 0.1746072\ttotal: 23.7s\tremaining: 2.49s\n",
      "905:\tlearn: 0.1744383\ttotal: 23.8s\tremaining: 2.47s\n",
      "906:\tlearn: 0.1743623\ttotal: 23.8s\tremaining: 2.44s\n",
      "907:\tlearn: 0.1741886\ttotal: 23.8s\tremaining: 2.41s\n",
      "908:\tlearn: 0.1740506\ttotal: 23.9s\tremaining: 2.39s\n",
      "909:\tlearn: 0.1739390\ttotal: 23.9s\tremaining: 2.36s\n",
      "910:\tlearn: 0.1738166\ttotal: 23.9s\tremaining: 2.33s\n",
      "911:\tlearn: 0.1736686\ttotal: 23.9s\tremaining: 2.31s\n",
      "912:\tlearn: 0.1735764\ttotal: 24s\tremaining: 2.28s\n",
      "913:\tlearn: 0.1734844\ttotal: 24s\tremaining: 2.26s\n",
      "914:\tlearn: 0.1733590\ttotal: 24s\tremaining: 2.23s\n",
      "915:\tlearn: 0.1731198\ttotal: 24s\tremaining: 2.2s\n",
      "916:\tlearn: 0.1729612\ttotal: 24.1s\tremaining: 2.18s\n",
      "917:\tlearn: 0.1728402\ttotal: 24.1s\tremaining: 2.15s\n",
      "918:\tlearn: 0.1726097\ttotal: 24.1s\tremaining: 2.13s\n",
      "919:\tlearn: 0.1725000\ttotal: 24.1s\tremaining: 2.1s\n",
      "920:\tlearn: 0.1723498\ttotal: 24.2s\tremaining: 2.07s\n",
      "921:\tlearn: 0.1721950\ttotal: 24.2s\tremaining: 2.05s\n",
      "922:\tlearn: 0.1719982\ttotal: 24.2s\tremaining: 2.02s\n",
      "923:\tlearn: 0.1718181\ttotal: 24.2s\tremaining: 1.99s\n",
      "924:\tlearn: 0.1716882\ttotal: 24.3s\tremaining: 1.97s\n",
      "925:\tlearn: 0.1714587\ttotal: 24.3s\tremaining: 1.94s\n",
      "926:\tlearn: 0.1710954\ttotal: 24.3s\tremaining: 1.91s\n",
      "927:\tlearn: 0.1709712\ttotal: 24.3s\tremaining: 1.89s\n",
      "928:\tlearn: 0.1707658\ttotal: 24.4s\tremaining: 1.86s\n",
      "929:\tlearn: 0.1707232\ttotal: 24.4s\tremaining: 1.84s\n",
      "930:\tlearn: 0.1705343\ttotal: 24.4s\tremaining: 1.81s\n",
      "931:\tlearn: 0.1703542\ttotal: 24.5s\tremaining: 1.78s\n",
      "932:\tlearn: 0.1702510\ttotal: 24.5s\tremaining: 1.76s\n",
      "933:\tlearn: 0.1700563\ttotal: 24.5s\tremaining: 1.73s\n",
      "934:\tlearn: 0.1699899\ttotal: 24.5s\tremaining: 1.71s\n",
      "935:\tlearn: 0.1697236\ttotal: 24.6s\tremaining: 1.68s\n",
      "936:\tlearn: 0.1695631\ttotal: 24.6s\tremaining: 1.65s\n",
      "937:\tlearn: 0.1694046\ttotal: 24.6s\tremaining: 1.63s\n",
      "938:\tlearn: 0.1692087\ttotal: 24.6s\tremaining: 1.6s\n",
      "939:\tlearn: 0.1690702\ttotal: 24.7s\tremaining: 1.57s\n",
      "940:\tlearn: 0.1689330\ttotal: 24.7s\tremaining: 1.55s\n",
      "941:\tlearn: 0.1688547\ttotal: 24.7s\tremaining: 1.52s\n",
      "942:\tlearn: 0.1686313\ttotal: 24.7s\tremaining: 1.5s\n",
      "943:\tlearn: 0.1684864\ttotal: 24.8s\tremaining: 1.47s\n",
      "944:\tlearn: 0.1683041\ttotal: 24.8s\tremaining: 1.44s\n",
      "945:\tlearn: 0.1681771\ttotal: 24.8s\tremaining: 1.42s\n",
      "946:\tlearn: 0.1679660\ttotal: 24.8s\tremaining: 1.39s\n",
      "947:\tlearn: 0.1678632\ttotal: 24.9s\tremaining: 1.36s\n",
      "948:\tlearn: 0.1675754\ttotal: 24.9s\tremaining: 1.34s\n",
      "949:\tlearn: 0.1673698\ttotal: 24.9s\tremaining: 1.31s\n",
      "950:\tlearn: 0.1672190\ttotal: 25s\tremaining: 1.28s\n",
      "951:\tlearn: 0.1670665\ttotal: 25s\tremaining: 1.26s\n",
      "952:\tlearn: 0.1669466\ttotal: 25s\tremaining: 1.23s\n",
      "953:\tlearn: 0.1668291\ttotal: 25s\tremaining: 1.21s\n",
      "954:\tlearn: 0.1667589\ttotal: 25.1s\tremaining: 1.18s\n",
      "955:\tlearn: 0.1666150\ttotal: 25.1s\tremaining: 1.15s\n",
      "956:\tlearn: 0.1664894\ttotal: 25.1s\tremaining: 1.13s\n",
      "957:\tlearn: 0.1663503\ttotal: 25.1s\tremaining: 1.1s\n",
      "958:\tlearn: 0.1662184\ttotal: 25.2s\tremaining: 1.07s\n",
      "959:\tlearn: 0.1661799\ttotal: 25.2s\tremaining: 1.05s\n",
      "960:\tlearn: 0.1660138\ttotal: 25.2s\tremaining: 1.02s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "961:\tlearn: 0.1658717\ttotal: 25.2s\tremaining: 997ms\n",
      "962:\tlearn: 0.1655993\ttotal: 25.3s\tremaining: 971ms\n",
      "963:\tlearn: 0.1655081\ttotal: 25.3s\tremaining: 944ms\n",
      "964:\tlearn: 0.1653591\ttotal: 25.3s\tremaining: 918ms\n",
      "965:\tlearn: 0.1651841\ttotal: 25.3s\tremaining: 892ms\n",
      "966:\tlearn: 0.1650771\ttotal: 25.4s\tremaining: 865ms\n",
      "967:\tlearn: 0.1649805\ttotal: 25.4s\tremaining: 839ms\n",
      "968:\tlearn: 0.1648257\ttotal: 25.4s\tremaining: 813ms\n",
      "969:\tlearn: 0.1646451\ttotal: 25.4s\tremaining: 787ms\n",
      "970:\tlearn: 0.1643603\ttotal: 25.5s\tremaining: 761ms\n",
      "971:\tlearn: 0.1642201\ttotal: 25.5s\tremaining: 734ms\n",
      "972:\tlearn: 0.1640730\ttotal: 25.5s\tremaining: 708ms\n",
      "973:\tlearn: 0.1638722\ttotal: 25.5s\tremaining: 682ms\n",
      "974:\tlearn: 0.1636677\ttotal: 25.6s\tremaining: 656ms\n",
      "975:\tlearn: 0.1635385\ttotal: 25.6s\tremaining: 630ms\n",
      "976:\tlearn: 0.1633817\ttotal: 25.6s\tremaining: 603ms\n",
      "977:\tlearn: 0.1631303\ttotal: 25.7s\tremaining: 577ms\n",
      "978:\tlearn: 0.1630030\ttotal: 25.7s\tremaining: 551ms\n",
      "979:\tlearn: 0.1628099\ttotal: 25.7s\tremaining: 525ms\n",
      "980:\tlearn: 0.1627129\ttotal: 25.7s\tremaining: 498ms\n",
      "981:\tlearn: 0.1625895\ttotal: 25.8s\tremaining: 472ms\n",
      "982:\tlearn: 0.1623984\ttotal: 25.8s\tremaining: 446ms\n",
      "983:\tlearn: 0.1622141\ttotal: 25.8s\tremaining: 420ms\n",
      "984:\tlearn: 0.1620221\ttotal: 25.8s\tremaining: 393ms\n",
      "985:\tlearn: 0.1618637\ttotal: 25.9s\tremaining: 367ms\n",
      "986:\tlearn: 0.1617172\ttotal: 25.9s\tremaining: 341ms\n",
      "987:\tlearn: 0.1614525\ttotal: 25.9s\tremaining: 315ms\n",
      "988:\tlearn: 0.1612895\ttotal: 25.9s\tremaining: 289ms\n",
      "989:\tlearn: 0.1612133\ttotal: 26s\tremaining: 262ms\n",
      "990:\tlearn: 0.1610186\ttotal: 26s\tremaining: 236ms\n",
      "991:\tlearn: 0.1608942\ttotal: 26s\tremaining: 210ms\n",
      "992:\tlearn: 0.1608135\ttotal: 26s\tremaining: 184ms\n",
      "993:\tlearn: 0.1606801\ttotal: 26.1s\tremaining: 157ms\n",
      "994:\tlearn: 0.1604970\ttotal: 26.1s\tremaining: 131ms\n",
      "995:\tlearn: 0.1603848\ttotal: 26.1s\tremaining: 105ms\n",
      "996:\tlearn: 0.1603006\ttotal: 26.1s\tremaining: 78.7ms\n",
      "997:\tlearn: 0.1601617\ttotal: 26.2s\tremaining: 52.5ms\n",
      "998:\tlearn: 0.1600321\ttotal: 26.2s\tremaining: 26.2ms\n",
      "999:\tlearn: 0.1599057\ttotal: 26.2s\tremaining: 0us\n",
      "ending\n",
      "google_nopreprocess_tfidf_preprocess_embed\n",
      "Before Num features= 15712 Counter({1: 27, 0: 23})\n",
      "After Num features= 253\n",
      "BINNY DATA:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.78      0.73        23\n",
      "          1       0.79      0.70      0.75        27\n",
      "\n",
      "avg / total       0.75      0.74      0.74        50\n",
      "\n",
      "accuracy_test_BINNY: 0.74\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=12, objective='binary:logistic', random_state=42,\n",
      "       reg_alpha=0, reg_lambda=3, scale_pos_weight=0.8, seed=None,\n",
      "       silent=False, subsample=1)\n",
      "Before Num features= 15712 Counter({0: 2215, 1: 1785})\n",
      "After Num features= 250\n",
      "ending\n",
      "google_nopreprocess_tfidf_preprocess_embed\n",
      "Before Num features= 15712 Counter({1: 27, 0: 23})\n",
      "After Num features= 250\n",
      "BINNY DATA:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.78      0.65        23\n",
      "          1       0.72      0.48      0.58        27\n",
      "\n",
      "avg / total       0.65      0.62      0.61        50\n",
      "\n",
      "accuracy_test_BINNY: 0.62\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=10, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "Before Num features= 15712 Counter({0: 2215, 1: 1785})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binny/anaconda3/envs/punyajoy-nogpu/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Num features= 257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binny/anaconda3/envs/punyajoy-nogpu/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1232: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending\n",
      "google_nopreprocess_tfidf_preprocess_embed\n",
      "Before Num features= 15712 Counter({1: 27, 0: 23})\n",
      "After Num features= 257\n",
      "BINNY DATA:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.70      0.65        23\n",
      "          1       0.71      0.63      0.67        27\n",
      "\n",
      "avg / total       0.67      0.66      0.66        50\n",
      "\n",
      "accuracy_test_BINNY: 0.66\n"
     ]
    }
   ],
   "source": [
    "#list_of_model = ['decision_tree_classifier', 'gaussian', 'logistic_regression', 'MLPClassifier', 'RandomForestClassifier',\n",
    "#                 'SVC', 'Catboost', 'XGB_classifier']\n",
    "list_of_model = ['Catboost','XGB_classifier','logistic_regression']\n",
    "\n",
    "for each_model in list_of_model:\n",
    "    model=get_model(m_type=each_model)\n",
    "    binny_classifier_run(X,y,model,each_model,label_map,img_name,report_name,save_model=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
