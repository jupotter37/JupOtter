{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This is an example of how to train a basic image classification model with Keras and Tensorflow, using TileDB as storage for images.\n",
    "First of all let's import everything we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tiledb\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Activation, MaxPooling2D, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "First create the needed directories and define some globla variables like image size, batch size and paths"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Image size for rescaling. Feel free to increase image size in order to check how fast TileDB array writes and reads are.\n",
    "IMAGE_SIZE = (64, 64)\n",
    "\n",
    "# Batch size for training an image classification model.\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Where our data live.\n",
    "DATA_PATH = \"data/\"\n",
    "\n",
    "# Where our images live\n",
    "IMAGE_PATH = \"data/flower_photos\"\n",
    "\n",
    "# Where our tileDB arrays live.\n",
    "TILEDB_PATH = \"data/flower_photos_tiledb\"\n",
    "\n",
    "# Where trained models live\n",
    "MODEL_PATH = \"data/trained_models\"\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    os.mkdir(DATA_PATH)\n",
    "\n",
    "if not os.path.exists(IMAGE_PATH):\n",
    "    os.mkdir(IMAGE_PATH)\n",
    "\n",
    "if not os.path.exists(TILEDB_PATH):\n",
    "    os.mkdir(TILEDB_PATH)\n",
    "\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.mkdir(MODEL_PATH)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We have to download the flower image dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] downloading image data...\n",
      "[STATUS] downloading image data finished...\n"
     ]
    }
   ],
   "source": [
    "print(\"[STATUS] downloading image data...\")\n",
    "data_dir = tf.keras.utils.get_file(\n",
    "    'flower_photos',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "    untar=True)\n",
    "os.system(\"mv ~/.keras/datasets/flower_photos ./data\")\n",
    "print(\"[STATUS] downloading image data finished...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We move on by getting class names from image data directory. We then perform basic one hot encoding for image labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get labels/classes\n",
    "labels = [name for name in os.listdir(IMAGE_PATH) if os.path.isdir(os.path.join(IMAGE_PATH, name))]\n",
    "\n",
    "# Encode labels\n",
    "labels_dict = {labels[i]: i for i in range(0, len(labels))}\n",
    "number_of_classes = len(labels)\n",
    "one_hot_encodings = np.eye(number_of_classes, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next step is to load images, perform a basic preprocessing step and store them as TileDB arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] image loading and basic preprocessing...\n",
      "[STATUS] processed folder: roses\n",
      "[STATUS] processed folder: sunflowers\n",
      "[STATUS] processed folder: daisy\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) /private/var/folders/nz/vv4_9tw56nv9k3tkvyszvwg80000gn/T/pip-req-build-v0h6zy15/opencv/modules/imgproc/src/resize.cpp:3929: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31merror\u001B[0m                                     Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-9b04ce6812c6>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     15\u001B[0m         \u001B[0;31m# read the image and resize it to a fixed-size\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[0mimage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 17\u001B[0;31m         \u001B[0mimage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mIMAGE_SIZE\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m         \u001B[0;31m# Here is where you may add any kind of image preprocessing you need.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31merror\u001B[0m: OpenCV(4.4.0) /private/var/folders/nz/vv4_9tw56nv9k3tkvyszvwg80000gn/T/pip-req-build-v0h6zy15/opencv/modules/imgproc/src/resize.cpp:3929: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "# Empty lists to hold images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "print(\"[STATUS] image loading and basic preprocessing...\")\n",
    "\n",
    "# loop over the training data sub-folders\n",
    "for current_label in labels_dict:\n",
    "\n",
    "    class_image_paths = glob.glob(IMAGE_PATH + \"/\" + current_label + \"/*.jpg\")\n",
    "\n",
    "    # loop over the images per class\n",
    "    for image_path in class_image_paths:\n",
    "\n",
    "        # read the image and resize it to a fixed-size\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, IMAGE_SIZE)\n",
    "\n",
    "        # Here is where you may add any kind of image preprocessing you need.\n",
    "\n",
    "        # update the list of images\n",
    "        images.append(image.astype(np.float32))\n",
    "\n",
    "        # update the list of labels\n",
    "        labels.append(one_hot_encodings[labels_dict[current_label]])\n",
    "\n",
    "    print(\"[STATUS] processed folder: {}\".format(current_label))\n",
    "\n",
    "# Create two numpy arrays with all images and all labels respectively.\n",
    "images = np.stack(images, axis=0) / 255.0 # Scale RGB values between 0.0 - 1.0\n",
    "labels = np.stack(labels, axis=0)\n",
    "\n",
    "print(\"[STATUS] completed image resizing...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will now split our dataset in train and validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Shuffle image and label data in the same manner\n",
    "randomize = np.arange(images.shape[0])\n",
    "np.random.shuffle(randomize)\n",
    "images = images[randomize]\n",
    "labels = labels[randomize]\n",
    "\n",
    "train_max_indx = int(labels.shape[0] * 0.8)\n",
    "\n",
    "train_images = images[:train_max_indx]\n",
    "train_labels = labels[:train_max_indx]\n",
    "\n",
    "validate_images = images[train_max_indx:]\n",
    "validate_labels = labels[train_max_indx:]\n",
    "\n",
    "# get the overall image dataset shapes\n",
    "print(\"[STATUS] train images array shape {}\".format(train_images.shape))\n",
    "print(\"[STATUS] validate images array shape {}\".format(validate_images.shape))\n",
    "\n",
    "# get the overall label dataset shapes\n",
    "print(\"[STATUS] train labels array shape {}\".format(train_labels.shape))\n",
    "print(\"[STATUS] validate labels array shape {}\".format(validate_labels.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now is the time to store image data and labels to TileDB arrays. We have to define the schema, dimensions and tile extend.\n",
    "We will use 3 dimensions for images, i.e, 1st dimension will be the image id, while the 2nd and 3rd dimensions correspond to each\n",
    "image's x-axis and y-axis. RGB values will be stored as attributes in each TileDB array cell. Because of the fact that during\n",
    "training a model we will load image batches equal to the BATCH_SIZE, tile extend of the image_id dimension should be equal\n",
    "with the BATCH_SIZE. The tile extend of the other two dimensions should be equal with the image x and y size respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define dimensions, Schema and write TileDB array for image data\n",
    "train_image_id = tiledb.Dim(name=\"image_id\", domain=(0, train_images.shape[0] - 1), tile=BATCH_SIZE, dtype=np.int32)\n",
    "validate_image_id = tiledb.Dim(name=\"image_id\", domain=(0, validate_images.shape[0] - 1), tile=BATCH_SIZE, dtype=np.int32)\n",
    "\n",
    "# The following dimensions are common\n",
    "x_axis = tiledb.Dim(name=\"x_axis\", domain=(0, train_images.shape[1] - 1), tile=train_images.shape[1], dtype=np.int32)\n",
    "y_axis = tiledb.Dim(name=\"y_axis\", domain=(0, train_images.shape[2] - 1), tile=train_images.shape[2], dtype=np.int32)\n",
    "\n",
    "# Two different schemas for train and validate\n",
    "train_images_schema = tiledb.ArraySchema(domain=tiledb.Domain(train_image_id, x_axis, y_axis),\n",
    "                                         sparse=False,\n",
    "                                         attrs=[tiledb.Attr(name=\"rgb\", dtype=[(\"\", np.float32),\n",
    "                                                                               (\"\", np.float32),\n",
    "                                                                               (\"\", np.float32)])])\n",
    "\n",
    "validate_images_schema = tiledb.ArraySchema(domain=tiledb.Domain(validate_image_id, x_axis, y_axis),\n",
    "                                            sparse=False,\n",
    "                                            attrs=[tiledb.Attr(name=\"rgb\", dtype=[(\"\", np.float32),\n",
    "                                                                                  (\"\", np.float32),\n",
    "                                                                                  (\"\", np.float32)])])\n",
    "\n",
    "tiledb.Array.create(TILEDB_PATH + \"/train_image_array\", train_images_schema)\n",
    "tiledb.Array.create(TILEDB_PATH + \"/validate_image_array\", validate_images_schema)\n",
    "\n",
    "train_image_view = train_images.view([(\"\", np.float32), (\"\", np.float32), (\"\", np.float32)])\n",
    "validate_image_view = validate_images.view([(\"\", np.float32), (\"\", np.float32), (\"\", np.float32)])\n",
    "\n",
    "with tiledb.open(TILEDB_PATH + \"/train_image_array\", 'w') as train_images_tiledb:\n",
    "    train_images_tiledb[:] = train_image_view\n",
    "\n",
    "with tiledb.open(TILEDB_PATH + \"/validate_image_array\", 'w') as validate_images_tiledb:\n",
    "    validate_images_tiledb[:] = validate_image_view\n",
    "\n",
    "print(\"[STATUS] images TileDB arrays are ready.\")\n",
    "\n",
    "# Similarly for label arrays.\n",
    "train_label_id = tiledb.Dim(name=\"label_id\", domain=(0, train_labels.shape[0] - 1), tile=BATCH_SIZE, dtype=np.int32)\n",
    "validate_label_id = tiledb.Dim(name=\"label_id\", domain=(0, validate_labels.shape[0] - 1), tile=BATCH_SIZE, dtype=np.int32)\n",
    "\n",
    "train_labels_schema = tiledb.ArraySchema(domain=tiledb.Domain(train_label_id),\n",
    "                                         sparse=False,\n",
    "                                         attrs=[tiledb.Attr(name=\"label\",\n",
    "                                                            dtype=[(\"\", np.float32),\n",
    "                                                                   (\"\", np.float32),\n",
    "                                                                   (\"\", np.float32),\n",
    "                                                                   (\"\", np.float32),\n",
    "                                                                   (\"\", np.float32)])])\n",
    "\n",
    "validate_labels_schema = tiledb.ArraySchema(domain=tiledb.Domain(validate_label_id),\n",
    "                                            sparse=False,\n",
    "                                            attrs=[tiledb.Attr(name=\"label\",\n",
    "                                                               dtype=[(\"\", np.float32),\n",
    "                                                                      (\"\", np.float32),\n",
    "                                                                      (\"\", np.float32),\n",
    "                                                                      (\"\", np.float32),\n",
    "                                                                      (\"\", np.float32)])])\n",
    "\n",
    "\n",
    "tiledb.Array.create(TILEDB_PATH + \"/train_label_array\", train_labels_schema)\n",
    "tiledb.Array.create(TILEDB_PATH + \"/validate_label_array\", validate_labels_schema)\n",
    "\n",
    "train_labels_view = train_labels.view([(\"\", np.float32), (\"\", np.float32), (\"\", np.float32), (\"\", np.float32), (\"\", np.float32)])\n",
    "validate_labels_view = validate_labels.view([(\"\", np.float32), (\"\", np.float32), (\"\", np.float32), (\"\", np.float32), (\"\", np.float32)])\n",
    "\n",
    "\n",
    "with tiledb.open(TILEDB_PATH + \"/train_label_array\", 'w') as train_labels_tiledb:\n",
    "    train_labels_tiledb[:] = train_labels_view\n",
    "\n",
    "with tiledb.open(TILEDB_PATH + \"/validate_label_array\", 'w') as validate_labels_tiledb:\n",
    "    validate_labels_tiledb[:] = validate_labels_view\n",
    "\n",
    "print(\"[STATUS] labels TileDB arrays are ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will need a data generator than will feed training and validation data into the model while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generator(tiledb_images_obj, tiledb_labels_obj, shape, batch_size=32):\n",
    "    \"\"\"\n",
    "    Yields the next training batch.\n",
    "    \"\"\"\n",
    "\n",
    "    while True:  # Loop forever so the generator never terminates\n",
    "\n",
    "        # Get index to start each batch\n",
    "        for offset in range(0, shape, batch_size):\n",
    "\n",
    "            # Get the samples you'll use in this batch. We have to convert structured numpy arrays to\n",
    "            # numpy arrays.\n",
    "\n",
    "            # Avoid reshaping error in last batch\n",
    "            if offset + batch_size > shape:\n",
    "                batch_size = shape - offset\n",
    "\n",
    "            x_train = tiledb_images_obj[offset:offset + batch_size]['rgb'].\\\n",
    "                view(np.float32).reshape(batch_size, IMAGE_SIZE[0], IMAGE_SIZE[1], 3)\n",
    "\n",
    "            y_train = tiledb_labels_obj[offset:offset + batch_size]['label'].\\\n",
    "                view(np.float32).reshape(batch_size, number_of_classes)\n",
    "\n",
    "            # The generator-y part: yield the next training batch\n",
    "            yield x_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will create generators for train and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Open TileDB image and label arrays.\n",
    "train_images_tiledb = tiledb.open(TILEDB_PATH + \"/train_image_array\")\n",
    "train_labels_tiledb = tiledb.open(TILEDB_PATH + \"/train_label_array\")\n",
    "\n",
    "validate_images_tiledb = tiledb.open(TILEDB_PATH + \"/validate_image_array\")\n",
    "validate_labels_tiledb = tiledb.open(TILEDB_PATH + \"/validate_label_array\")\n",
    "\n",
    "# Create generators\n",
    "train_generator = generator(tiledb_images_obj=train_images_tiledb,\n",
    "                            tiledb_labels_obj=train_labels_tiledb,\n",
    "                            shape=train_images.shape[0],\n",
    "                            batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "validate_generator = generator(tiledb_images_obj=validate_images_tiledb,\n",
    "                               tiledb_labels_obj=validate_labels_tiledb,\n",
    "                               shape=validate_images.shape[0],\n",
    "                               batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will now define a function that creates an image classification model (taken from https://www.kaggle.com/alxmamaev/flowers-recognition) using Keras with Tensorflow backend.\n",
    "Because of the fact that we don't perform any image preprocessing or data augmentation for image classification problems,\n",
    "the model is not expected to achieve great accuracy. Great accuracy is out of the scope of this notebook, which just presents how we can employ\n",
    "TileDB as storage for images in order to train a model with Tensorflow and Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape, num_of_classes):\n",
    "\n",
    "    input_shape = input_shape\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape, name='conv2d_1'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), name='maxpool2d_1'))\n",
    "    model.add(Conv2D(32, (3, 3), name='conv2d_2'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), name='maxpool2d_2'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_of_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed by creating a model with the corresponding checkpoint and early stopping callbacks and train it by passing\n",
    "train and validation generators as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = create_model(input_shape=images[0].shape, num_of_classes=number_of_classes)\n",
    "\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    MODEL_PATH + \"/flower_model.h5\", save_best_only=True\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_images.shape[0] // BATCH_SIZE,\n",
    "        epochs=5,\n",
    "        validation_data=validate_generator,\n",
    "        validation_steps=validate_images.shape[0] // BATCH_SIZE,\n",
    "        callbacks=[checkpoint_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}