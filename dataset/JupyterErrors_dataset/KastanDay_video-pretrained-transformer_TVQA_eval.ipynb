{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to run eval\n",
    "\n",
    "```\n",
    "\"a0\": \"Because Sheldon is being rude.\", \n",
    "\"a1\": \"Because he doesn't like Sheldon.\", \n",
    "\"a2\": \"Because they are having an argument.\", \n",
    "\"a3\": \"Because Howard wanted to have a private meal with Raj.\", \n",
    "\"a4\": \"Because Sheldon won't loan him money for food.\", \n",
    "\"answer_idx\": 2, \n",
    "\"q\": \"Why is Howard frustrated when he is talking to Sheldon?\", \n",
    "\"qid\": 122039, \n",
    "\"show_name\": \"The Big Bang Theory\", \n",
    "\"ts\": \"20.16-25.12\", \n",
    "\"vid_name\": \"s03e02_seg02_clip_10\"\n",
    "\n",
    "\n",
    "\"Question: {q} Is it '{ans_candidate}'? [MASK].\"\n",
    "\n",
    "\n",
    "Iterate thru, run embeddings. Then run construct question, then run model, find the highest probability YES answer. Return that answer_idx. Find accuacy.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122039"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load json from file\n",
    "train_filepath=\"/mnt/teton/vpt/data/benchmark_datasets/TVQA/TVQA/data/tvqa_qa_release/tvqa_train.jsonl\"\n",
    "with open(train_filepath, 'r') as f:\n",
    "    train_qa_json = [json.loads(line) for line in f]\n",
    "len(train_qa_json)  # 122,039\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a0': 'Cafeteria',\n",
       " 'a1': 'Hallway',\n",
       " 'a2': 'Car',\n",
       " 'a3': 'Patients room',\n",
       " 'a4': 'Outside',\n",
       " 'answer_idx': 4,\n",
       " 'q': 'Where is Meredith when George approaches her?',\n",
       " 'qid': 0,\n",
       " 'show_name': \"Grey's Anatomy\",\n",
       " 'ts': '76.01-84.2',\n",
       " 'vid_name': 'grey_s03e20_seg02_clip_14'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_qa_json[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'76.01'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_qa_json[0]['ts'].split('-')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def qa_to_prompt(qa:Dict, captions:str):\n",
    "    # prompts = []\n",
    "    # for ans_candidate in [qa['a0'], qa['a1'], qa['a2'], qa['a3'], qa['a4']]:\n",
    "    #     prompts.append([f\"Question: {qa['q']} Is it '{ans_candidate}'?\"])\n",
    "    return [[f\"Some context: {captions}. Question: {qa['q']} Is it '{ans_candidate}'?\"] for ans_candidate in [qa['a0'], qa['a1'], qa['a2'], qa['a3'], qa['a4']]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"Some context: some captions. Question: Where is Meredith when George approaches her? Is it 'Cafeteria'?\"],\n",
       " [\"Some context: some captions. Question: Where is Meredith when George approaches her? Is it 'Hallway'?\"],\n",
       " [\"Some context: some captions. Question: Where is Meredith when George approaches her? Is it 'Car'?\"],\n",
       " [\"Some context: some captions. Question: Where is Meredith when George approaches her? Is it 'Patients room'?\"],\n",
       " [\"Some context: some captions. Question: Where is Meredith when George approaches her? Is it 'Outside'?\"]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_to_prompt(train_qa_json[0], \"some captions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: include captions in the prompt."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21793"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load json from file\n",
    "subtitles_filepath=\"/mnt/teton/vpt/data/benchmark_datasets/TVQA/TVQA/data/tvqa_preprocessed_subtitles.jsonl\"\n",
    "with open(subtitles_filepath, 'r') as f:\n",
    "    subtitles = [json.loads(line) for line in f]\n",
    "len(subtitles)  # 21,793"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Meredith! Tell me where she is. - I can't! If she wanted you to know... - She does. She...\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subtitles[0]\n",
    "\n",
    "def get_subtitle_from_clip(vid_name:str, start_time:float, end_time:float):\n",
    "  subtitle = ''\n",
    "  for sub in subtitles:\n",
    "      if sub['vid_name'] == vid_name:\n",
    "          # print()\n",
    "          for text in sub['sub']:\n",
    "              if text['start'] >= float(start_time - 1) and text['end'] <= float(end_time + 1):\n",
    "                subtitle += text['text'] + ' '\n",
    "                # print(text['text'])\n",
    "                # print(text['start'], text['end'])\n",
    "                # print()\n",
    "  return subtitle.strip()\n",
    "\n",
    "get_subtitle_from_clip('grey_s03e20_seg02_clip_14', 76.01, 84.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Some context: Meredith! Tell me where she is. - I can't! If she wanted you to know... - She does. She.... Question: Where is Meredith when George approaches her? Is it 'Cafeteria'?\",\n",
       " \"Some context: Meredith! Tell me where she is. - I can't! If she wanted you to know... - She does. She.... Question: Where is Meredith when George approaches her? Is it 'Hallway'?\",\n",
       " \"Some context: Meredith! Tell me where she is. - I can't! If she wanted you to know... - She does. She.... Question: Where is Meredith when George approaches her? Is it 'Car'?\",\n",
       " \"Some context: Meredith! Tell me where she is. - I can't! If she wanted you to know... - She does. She.... Question: Where is Meredith when George approaches her? Is it 'Patients room'?\",\n",
       " \"Some context: Meredith! Tell me where she is. - I can't! If she wanted you to know... - She does. She.... Question: Where is Meredith when George approaches her? Is it 'Outside'?\"]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "v = [\n",
    "    \"Some context: Meredith! Tell me where she is. - I can't! If she wanted you to know... - She does. She.... Question: Where is Meredith when George approaches her? Is it 'Cafeteria'?\",\n",
    "    \"Some context: Meredith! Tell me where she is. - I can't! If she wanted you to know... - She does. She.... Question: Where is Meredith when George approaches her? Is it 'Hallway'?\",\n",
    "    \"Some context: Meredith! Tell me where she is. - I can't! If she wanted you to know... - She does. She.... Question: Where is Meredith when George approaches her? Is it 'Car'?\",\n",
    "    \"Some context: Meredith! Tell me where she is. - I can't! If she wanted you to know... - She does. She.... Question: Where is Meredith when George approaches her? Is it 'Patients room'?\",\n",
    "    \"Some context: Meredith! Tell me where she is. - I can't! If she wanted you to know... - She does. She.... Question: Where is Meredith when George approaches her? Is it 'Outside'?\"\n",
    "]\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, list found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(v[:]))\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, list found"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(v[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so now we have the text. Need to embed it. Then embed images. then we're ready to rock."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get logits for the generated answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c700ee253e9044bd8301f79e531f7c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d23186c4534e7f9508b085366c8ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"spiece.model\";:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256846877c554bd9adc2ea7c8bf90e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e66aeb4b33846aca0ac8e9e1dea2990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9a2ed8087d4928aec03965ec8c0e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71604201eb434e09b01d3a388a4102fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b740e6d8302418b91563540d1b50113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model_name = 'google/flan-t5-small'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some context: Meredith! Tell me where she is. - I can't! If she wanted you to know... - She does. She.... Question: Where is Meredith when George approaches her? Is it 'Cafeteria'?\n",
      "yes_score = tensor(-1.9372)\n",
      "no_score = tensor(1.0013)\n",
      "['<pad> no</s>']\n",
      "Some context: Meredith! Tell me where she is. - I can't! If she wanted you to know... - She does. She.... Question: Where is Meredith when George approaches her? Is it 'Hallway'?\n",
      "yes_score = tensor(-1.9553)\n",
      "no_score = tensor(0.8167)\n",
      "['<pad> no</s>']\n",
      "Some context: Meredith! Tell me where she is. - I can't! If she wanted you to know... - She does. She.... Question: Where is Meredith when George approaches her? Is it 'Car'?\n",
      "yes_score = tensor(-2.8168)\n",
      "no_score = tensor(0.5007)\n",
      "['<pad> no</s>']\n",
      "Some context: Meredith! Tell me where she is. - I can't! If she wanted you to know... - She does. She.... Question: Where is Meredith when George approaches her? Is it 'Patients room'?\n",
      "yes_score = tensor(-1.0733)\n",
      "no_score = tensor(1.5197)\n",
      "['<pad> no</s>']\n",
      "Some context: Meredith! Tell me where she is. - I can't! If she wanted you to know... - She does. She.... Question: Where is Meredith when George approaches her? Is it 'Outside'?\n",
      "yes_score = tensor(-2.7644)\n",
      "no_score = tensor(-1.2458)\n",
      "['<pad> no</s>']\n",
      "Arg of 'yes' answer\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Some context: Meredith! Tell me where she is. - I can't! If she wanted you to know... - She does. She.... Question: Where is Meredith when George approaches her? Is it 'Cafeteria'?\"\n",
    "import numpy as np\n",
    "all_yes_scores = []\n",
    "for prompt in v:\n",
    "  print(prompt)\n",
    "  inputs = tokenizer(prompt, return_tensors=\"pt\")  # Batch size 1\n",
    "  outputs = model.generate(**inputs, return_dict_in_generate=True, output_scores=True, early_stopping=True, max_new_tokens=2)\n",
    "  # print(outputs)\n",
    "  all_yes_scores.append(outputs.scores[0][0][4273])\n",
    "  print('yes_score =', outputs.scores[0][0][4273])\n",
    "  print('no_score =', outputs.scores[0][0][150])\n",
    "  print(tokenizer.batch_decode(outputs.sequences, skip_special_tokens=False))\n",
    "  \n",
    "print(\"Arg of 'yes' answer\")\n",
    "print(np.array(all_yes_scores).argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-52.7880,  -5.7398, -11.3355,  ..., -52.8435, -52.7438, -52.6754]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch set max print size to 1000\n",
    "\n",
    "outputs.scores[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  150,  1067,    27,  ..., 32065, 32114, 21515]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "ord = torch.argsort(outputs.scores[0], descending=True)\n",
    "ord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GreedySearchEncoderDecoderOutput(sequences=tensor([[  0, 150,   1]]), scores=(tensor([[-52.7880,  -5.7398, -11.3355,  ..., -52.8435, -52.7438, -52.6754]]), tensor([[-71.3249,  -0.3261, -18.2158,  ..., -71.4193, -71.3626, -71.4082]])), encoder_attentions=None, encoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, decoder_hidden_states=None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no', 'outside', 'I', '', 'yes']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(ord[0][:5], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 150, 1067,   27,    3, 4273])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.7644)\n",
      "tensor(-2.0362)\n",
      "tensor(-1.2458)\n"
     ]
    }
   ],
   "source": [
    "# no:  150\n",
    "# yes: 4273\n",
    "\n",
    "print(outputs.scores[0][0][4273]) # yes\n",
    "# print(outputs.scores[0][0][1067])  # outside\n",
    "print(outputs.scores[0][0][150])  # no\n",
    "\n",
    "# closer to 0 is better (smaller absolute value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vpt_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
