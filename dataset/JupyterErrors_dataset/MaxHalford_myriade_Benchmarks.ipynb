{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">901</span>,<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m901\u001b[0m,\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "X, y = datasets.load_digits(n_class=5, return_X_y=True)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.84%\n"
     ]
    }
   ],
   "source": [
    "import myriade\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn import pipeline\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "model = pipeline.make_pipeline(\n",
    "    preprocessing.StandardScaler(),\n",
    "    myriade.multiclass.OptimalHierarchyClassifier(\n",
    "        classifier=linear_model.LogisticRegression()\n",
    "    )\n",
    ")\n",
    "\n",
    "model = model.fit(X_train, y_train)\n",
    "print(f\"{model.score(X_test, y_test):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial: 0.95333\n",
      "KNN: 0.95333\n",
      "OvR: 0.92667\n",
      "OvO: 0.96667\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "from sklearn import linear_model\n",
    "from sklearn import pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import multiclass\n",
    "from sklearn import neighbors\n",
    "\n",
    "binary_clf = pipeline.make_pipeline(\n",
    "    preprocessing.StandardScaler(),\n",
    "    linear_model.LogisticRegression()\n",
    ")\n",
    "\n",
    "models = {\n",
    "    'Multinomial': pipeline.make_pipeline(\n",
    "        preprocessing.StandardScaler(),\n",
    "        linear_model.LogisticRegression(multi_class='multinomial', solver='sag')\n",
    "    ),\n",
    "    'KNN': pipeline.make_pipeline(\n",
    "        preprocessing.StandardScaler(),\n",
    "        model_selection.GridSearchCV(\n",
    "            neighbors.KNeighborsClassifier(),\n",
    "            param_grid={'n_neighbors': [3, 6, 9, 12]}\n",
    "        )\n",
    "    ),\n",
    "    'OvR': multiclass.OneVsRestClassifier(binary_clf),\n",
    "    'OvO': multiclass.OneVsOneClassifier(binary_clf),\n",
    "    #'ECOC': model_selection.GridSearchCV(\n",
    "    #    multiclass.OutputCodeClassifier(binary_clf, random_state=42),\n",
    "    #    param_grid={'code_size': [i / 10 for i in range(1, 16, 2)]}  # 10% to 150%\n",
    "    #)\n",
    "}\n",
    "\n",
    "cross_val = functools.partial(\n",
    "    model_selection.cross_val_score,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    scoring='accuracy',\n",
    "    cv=model_selection.KFold(5, shuffle=True, random_state=42)\n",
    ")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f'{name}: {cross_val(model).mean():.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-vs-rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9533333333333334"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import myriad\n",
    "\n",
    "binary_clf = pipeline.make_pipeline(\n",
    "    preprocessing.StandardScaler(),\n",
    "    linear_model.LogisticRegression(solver='liblinear')\n",
    ")\n",
    "\n",
    "lt = myriad.LabelTreeClassifier(binary_clf)\n",
    "cross_val(lt).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 49.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import myriad\n",
    "import tqdm\n",
    "\n",
    "best_tree = None\n",
    "best_score = -math.inf\n",
    "\n",
    "for tree in tqdm.tqdm(myriad.iter_trees(labels=set(y))):\n",
    "    hc = myriad.LabelTreeClassifier(binary_clf, prior_tree=tree)\n",
    "    score = cross_val(hc).mean()\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_tree = tree\n",
    "\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'p' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-65a5687ba10f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyriad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabelTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_tree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mhc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/myriad/myriad/myriad.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/myriad/myriad/myriad.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(tree, X, y_out, p_parent)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_parent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'p' referenced before assignment"
     ]
    }
   ],
   "source": [
    "hc = myriad.LabelTreeClassifier(binary_clf, prior_tree=tree)\n",
    "hc.fit(X, y)\n",
    "hc.predict_proba(X).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0,): AnyNode(label=0),\n",
       " (1,): AnyNode(label=1),\n",
       " (2,): AnyNode(label=2),\n",
       " (3,): AnyNode(label=3),\n",
       " (4,): AnyNode(label=4),\n",
       " (5,): AnyNode(label=5),\n",
       " (6,): AnyNode(label=6),\n",
       " (7,): AnyNode(label=7),\n",
       " (8,): AnyNode(label=8),\n",
       " (9,): AnyNode(label=9)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = {(i,): anytree.AnyNode(label=i) for i in range(10)}\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "\n",
    "def sort_tuple(*args):\n",
    "    return tuple(sorted(args))\n",
    "\n",
    "\n",
    "class CM(collections.defaultdict):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(int)\n",
    "        \n",
    "    def __setitem__(self, key, val):\n",
    "        skey = sort_tuple(*key)\n",
    "        return super().__setitem__(skey, val)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        skey = sort_tuple(*key)\n",
    "        return super().__getitem__(skey)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "mistakes = CM()\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i == j:\n",
    "            continue\n",
    "        mistakes[(i,), (j,)] += cm[i, j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3,), (9,), (3, 9))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left, right = max(mistakes, key=mistakes.get)\n",
    "del mistakes[left, right]\n",
    "new_key = sort_tuple(*left, *right)\n",
    "left, right, new_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnyNode(labels=[3, 9])\n",
      "├── AnyNode(label=3)\n",
      "└── AnyNode(label=9)\n"
     ]
    }
   ],
   "source": [
    "nodes[new_key] = make_branch(nodes.pop(left), nodes.pop(right))\n",
    "print(anytree.RenderTree(nodes[new_key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0,): AnyNode(label=0),\n",
       " (1,): AnyNode(label=1),\n",
       " (2,): AnyNode(label=2),\n",
       " (4,): AnyNode(label=4),\n",
       " (5,): AnyNode(label=5),\n",
       " (6,): AnyNode(label=6),\n",
       " (7,): AnyNode(label=7),\n",
       " (8,): AnyNode(label=8),\n",
       " (3, 9): AnyNode(labels=[3, 9])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_pop(d, k, default=0):\n",
    "    try:\n",
    "        return d.pop(k)\n",
    "    except KeyError:\n",
    "        return default\n",
    "\n",
    "for node in list(nodes.keys())[:-1]:\n",
    "    mistakes[sort_tuple(node, new_key)] = (\n",
    "        safe_pop(mistakes, sort_tuple(node, left)) +\n",
    "        safe_pop(mistakes, sort_tuple(node, right))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_smart_tree(labels, cm):\n",
    "    \n",
    "    nodes = {(label,): anytree.AnyNode(label=label) for label in labels}\n",
    "    mistakes = CM()\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            mistakes[(labels[i],), (labels[j],)] += cm[i, j]\n",
    "\n",
    "    while len(nodes) > 1:\n",
    "\n",
    "        left, right = max(mistakes, key=mistakes.get)\n",
    "        del mistakes[left, right]\n",
    "        new_key = sort_tuple(*left, *right)\n",
    "\n",
    "        nodes[new_key] = make_branch(nodes.pop(left), nodes.pop(right))\n",
    "\n",
    "        def safe_pop(d, k, default=0):\n",
    "            try:\n",
    "                return d.pop(k)\n",
    "            except KeyError:\n",
    "                return default\n",
    "\n",
    "        for node in list(nodes.keys())[:-1]:\n",
    "            mistakes[sort_tuple(node, new_key)] = (\n",
    "                safe_pop(mistakes, sort_tuple(node, left)) +\n",
    "                safe_pop(mistakes, sort_tuple(node, right))\n",
    "            )\n",
    "            \n",
    "    return list(nodes.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnyNode(labels=[0, 1, 3, 9, 8, 6, 4, 7, 5, 2])\n",
      "├── AnyNode(labels=[0, 1, 3, 9, 8, 6, 4, 7, 5])\n",
      "│   ├── AnyNode(labels=[0, 1, 3, 9, 8, 6, 4, 7])\n",
      "│   │   ├── AnyNode(labels=[0, 1, 3, 9, 8, 6])\n",
      "│   │   │   ├── AnyNode(labels=[0, 1, 3, 9, 8])\n",
      "│   │   │   │   ├── AnyNode(label=0)\n",
      "│   │   │   │   └── AnyNode(labels=[1, 3, 9, 8])\n",
      "│   │   │   │       ├── AnyNode(labels=[1, 3, 9])\n",
      "│   │   │   │       │   ├── AnyNode(label=1)\n",
      "│   │   │   │       │   └── AnyNode(labels=[3, 9])\n",
      "│   │   │   │       │       ├── AnyNode(label=3)\n",
      "│   │   │   │       │       └── AnyNode(label=9)\n",
      "│   │   │   │       └── AnyNode(label=8)\n",
      "│   │   │   └── AnyNode(label=6)\n",
      "│   │   └── AnyNode(labels=[4, 7])\n",
      "│   │       ├── AnyNode(label=4)\n",
      "│   │       └── AnyNode(label=7)\n",
      "│   └── AnyNode(label=5)\n",
      "└── AnyNode(label=2)\n"
     ]
    }
   ],
   "source": [
    "tree = build_smart_tree(np.unique(y), metrics.confusion_matrix(y_test, y_pred))\n",
    "print(anytree.RenderTree(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9577777777777777"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(X_train, y_train, tree, binary_model)\n",
    "y_pred = predict(X_test, tree)\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import base\n",
    "from sklearn import utils\n",
    "\n",
    "class HierarchyClassifier(base.BaseEstimator, base.ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, classifier):\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        # Build and train a flat tree\n",
    "        flat_tree = make_flat_tree(labels=self.classes_)\n",
    "        train(X, y, flat_tree, self.classifier)\n",
    "\n",
    "        # Make predictions and establish the confusion matrix\n",
    "        y_pred = predict(X, flat_tree)\n",
    "        cm = metrics.confusion_matrix(y, y_pred, labels=self.classes_)\n",
    "\n",
    "        # Build smarter tree\n",
    "        self.tree_ = build_smart_tree(self.classes_, cm)\n",
    "        train(X, y, self.tree_, self.classifier)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return predict(X, self.tree_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9711111111111111"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc = HierarchyClassifier(binary_model)\n",
    "hc.fit(X_train, y_train)\n",
    "y_pred = hc.predict(X_test)\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnyNode(labels=[0, 1, 3, 8, 9, 6, 4, 7, 5, 2], model=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression', LogisticRegression())]))\n",
      "├── AnyNode(labels=[0, 1, 3, 8, 9, 6, 4, 7, 5], model=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression', LogisticRegression())]))\n",
      "│   ├── AnyNode(labels=[0, 1, 3, 8, 9, 6, 4, 7], model=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression', LogisticRegression())]))\n",
      "│   │   ├── AnyNode(labels=[0, 1, 3, 8, 9, 6], model=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression', LogisticRegression())]))\n",
      "│   │   │   ├── AnyNode(labels=[0, 1, 3, 8, 9], model=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression', LogisticRegression())]))\n",
      "│   │   │   │   ├── AnyNode(label=0)\n",
      "│   │   │   │   └── AnyNode(labels=[1, 3, 8, 9], model=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression', LogisticRegression())]))\n",
      "│   │   │   │       ├── AnyNode(labels=[1, 3, 8], model=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression', LogisticRegression())]))\n",
      "│   │   │   │       │   ├── AnyNode(label=1)\n",
      "│   │   │   │       │   └── AnyNode(labels=[3, 8], model=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression', LogisticRegression())]))\n",
      "│   │   │   │       │       ├── AnyNode(label=3)\n",
      "│   │   │   │       │       └── AnyNode(label=8)\n",
      "│   │   │   │       └── AnyNode(label=9)\n",
      "│   │   │   └── AnyNode(label=6)\n",
      "│   │   └── AnyNode(labels=[4, 7], model=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression', LogisticRegression())]))\n",
      "│   │       ├── AnyNode(label=4)\n",
      "│   │       └── AnyNode(label=7)\n",
      "│   └── AnyNode(label=5)\n",
      "└── AnyNode(label=2)\n"
     ]
    }
   ],
   "source": [
    "print(anytree.RenderTree(hc.tree_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "newsgroups = datasets.fetch_20newsgroups(\n",
    "    subset='train',\n",
    "    remove=('headers', 'footers', 'quotes'),\n",
    ")\n",
    "newsgroups_vectors = vectorizer.fit_transform(newsgroups.data)\n",
    "\n",
    "tasks = {\n",
    "    'Iris': datasets.load_iris(return_X_y=True),\n",
    "    'Digits': datasets.load_digits(return_X_y=True),\n",
    "    'Newsgroups': (newsgroups_vectors, newsgroups.target)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris\n",
      "----\n",
      "n 150\n",
      "p 4\n",
      "k 3\n",
      "\n",
      "OvR 0.9736842105263158 0.01\n",
      "OvO 0.9736842105263158 0.01\n",
      "Hierarchy 0.9736842105263158 0.01\n",
      "\n",
      "Digits\n",
      "------\n",
      "n 1797\n",
      "p 64\n",
      "k 10\n",
      "\n",
      "OvR 0.9355555555555556 0.10\n",
      "OvO 0.96 0.09\n",
      "Hierarchy 0.9488888888888889 0.06\n",
      "\n",
      "Newsgroups\n",
      "----------\n",
      "n 11314\n",
      "p 101631\n",
      "k 20\n",
      "\n",
      "OvR 0.49240014139271826 0.90\n",
      "OvO 0.48462354188759277 1.52\n",
      "Hierarchy 0.4330151997172146 0.91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import multiclass\n",
    "\n",
    "binary_model = pipeline.make_pipeline(\n",
    "    preprocessing.StandardScaler(with_mean=False),\n",
    "    linear_model.SGDClassifier(random_state=42)\n",
    ")\n",
    "\n",
    "models = {\n",
    "    'OvR': lambda: multiclass.OneVsRestClassifier(binary_model),\n",
    "    'OvO': lambda: multiclass.OneVsOneClassifier(binary_model),\n",
    "    'Hierarchy': lambda: HierarchyClassifier(binary_model)\n",
    "}\n",
    "\n",
    "\n",
    "for task_name, task in tasks.items():\n",
    "    \n",
    "    print(task_name)\n",
    "    print('-' * len(task_name))\n",
    "    \n",
    "    X, y = task\n",
    "    y = preprocessing.LabelEncoder().fit_transform(y)\n",
    "    print('n', X.shape[0])\n",
    "    print('p', X.shape[1])\n",
    "    print('k', len(np.unique(y)))\n",
    "    print()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, random_state=42)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        model = model()\n",
    "        tic = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        toc = time.time()\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(model_name, metrics.accuracy_score(y_test, y_pred), f'{toc - tic:.2f}')\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import myriad\n",
    "\n",
    "X, y = myriad.datasets.load_wiki_large()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2365436x325056 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 7716184 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2620557055866235"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325056"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(l for labels in y for l in labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat_hier.txt', 'test.txt', 'train.txt']\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import tempfile\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "def get_data_home() -> pathlib.Path:\n",
    "    \"\"\"Return the location where datasets are to be stored.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    data_home = os.environ.get('MYRIAD_DATA', os.path.join('~', 'myriad_data'))\n",
    "    data_home = os.path.expanduser(data_home)\n",
    "    data_home = pathlib.Path(data_home)\n",
    "    if not data_home.exists():\n",
    "        os.makedirs(data_home)\n",
    "    return data_home\n",
    "\n",
    "data_home = get_data_home()\n",
    "\n",
    "with tarfile.open(data_home.joinpath('wiki_small.tar')) as wiki, tempfile.TemporaryDirectory() as untar:\n",
    "    print(wiki.getnames())\n",
    "    wiki.extract('train.txt', path=untar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'33692,13402,393382 1958361:1 1406434:1 1087979:1 1575596:1 1568423:1 1647082:1 1683055:2 959786:2 199557:1 1298293:1 1818509:1 1627758:1 1797547:1 1137332:1 792648:1 823758:1 1657857:1 1257203:2 1643138:1 1794479:2 1892706:1 1776443:1 1440249:1 343843:1 1875794:2 1668225:2 840280:2 1959409:2 1806640:2 1269574:1 367780:1 348667:1 1225157:1 1405316:1 1662756:1 1288684:1 1058628:2 75013:1 1274224:1 1341165:1 1124792:1 1092419:1 1370520:1 1248932:1 1055151:1 1576704:1 1669002:1 992551:1 1527338:1 742798:1 1175252:1 447960:1 1956883:1 1390251:1 14403:1 2059598:1 594957:1 818590:7 554613:1 416684:1 1520683:1 352804:1 1227548:1 405008:1 1129361:3 603084:1 1055696:11 1061488:1 358027:1 1729436:1 226053:1 326241:1 54278:1 328156:1 1313681:1 597023:1 1517117:1 1749787:3 1945075:2 1035426:1 1225319:1 1700823:1 521422:3 1900504:1 1390999:1 1959967:2 1912168:1 1219566:1 1193610:1 1117370:1 1630093:2 62619:1 1078156:2 1972926:1 1246596:1 304423:1 1910640:1 855276:2 1989445:1 1822977:1 624:3 275673:1 1345267:1 592526:1 1211852:1 352470:1 548779:1 1779069:1 4288:1 279353:1 106021:2 1909745:1 444833:2 536530:1\\n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels, features = line.rstrip().split(' ', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "with tarfile.open('wikipediaSmallv2.0.tar.gz') as wiki, tempfile.TemporaryDirectory() as untar_dir:\n",
    "    wiki.extract('train.txt', path=untar_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624:3 4288:1 14403:1 54278:1 62619:1 75013:1 106021:2 199557:1 226053:1 275673:1 279353:1 304423:1 326241:1 328156:1 343843:1 348667:1 352470:1 352804:1 358027:1 367780:1 405008:1 416684:1 444833:2 447960:1 521422:3 536530:1 548779:1 554613:1 592526:1 594957:1 597023:1 603084:1 742798:1 792648:1 818590:7 823758:1 840280:2 855276:2 959786:2 992551:1 1035426:1 1055151:1 1055696:11 1058628:2 1061488:1 1078156:2 1087979:1 1092419:1 1117370:1 1124792:1 1129361:3 1137332:1 1175252:1 1193610:1 1211852:1 1219566:1 1225157:1 1225319:1 1227548:1 1246596:1 1248932:1 1257203:2 1269574:1 1274224:1 1288684:1 1298293:1 1313681:1 1341165:1 1345267:1 1370520:1 1390251:1 1390999:1 1405316:1 1406434:1 1440249:1 1517117:1 1520683:1 1527338:1 1568423:1 1575596:1 1576704:1 1627758:1 1630093:2 1643138:1 1647082:1 1657857:1 1662756:1 1668225:2 1669002:1 1683055:2 1700823:1 1729436:1 1749787:3 1776443:1 1779069:1 1794479:2 1797547:1 1806640:2 1818509:1 1822977:1 1875794:2 1892706:1 1900504:1 1909745:1 1910640:1 1912168:1 1945075:2 1956883:1 1958361:1 1959409:2 1959967:2 1972926:1 1989445:1 2059598:1\n"
     ]
    }
   ],
   "source": [
    "def split(pair):\n",
    "    k, v = pair.split(':')\n",
    "    return int(k), v\n",
    "\n",
    "features = sorted(map(split, (pair for pair in line.rstrip().split(' ', 1)[1].split(' '))))\n",
    "print(' '.join(f'{k}:{v}' for k, v in features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'csr_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-5b4bd7762573>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'csr_matrix'"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from scipy import sparse\n",
    "\n",
    "encoder = collections.defaultdict(lambda: len(encoder))\n",
    "\n",
    "Y = sparse.dok_matrix((394_756, 36_372), dtype=bool)\n",
    "\n",
    "for i, labels in enumerate(y):\n",
    "    for label in labels:\n",
    "        j = encoder[label]\n",
    "        Y[i, j] = True \n",
    "\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x36372 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 1 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<394756x36372 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 394756 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(len(labels) for labels in y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "55fbbcf542e06cc59ad76a1e0d5dc36ee204d6d2b704491656ee6b3487310122"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
