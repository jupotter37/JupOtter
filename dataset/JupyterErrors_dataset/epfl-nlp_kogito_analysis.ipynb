{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relation_modeling_utils import load_data\n",
    "\n",
    "train_df = load_data(\"data/atomic2020_data-feb2021/train.tsv\", multi_label=True)\n",
    "val_df = load_data(\"data/atomic2020_data-feb2021/dev.tsv\", multi_label=True)\n",
    "test_df = load_data(\"data/atomic2020_data-feb2021/test.tsv\", multi_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching relations...\n",
      "Took 8.954379081726074 seconds per head\n"
     ]
    }
   ],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.processors.relation import SWEMRelationMatcher\n",
    "import time\n",
    "\n",
    "csi = CommonsenseInference()\n",
    "csi.remove_processor(\"simple_relation_matcher\")\n",
    "swem_matcher = SWEMRelationMatcher(\"swem_relation_matcher\")\n",
    "csi.add_processor(swem_matcher)\n",
    "heads = val_df.text.to_list()\n",
    "start = time.time()\n",
    "kgraph = csi.infer(heads=heads, dry_run=True)\n",
    "end = time.time()\n",
    "print(f\"Took {(end-start)/len(heads)} seconds per head\")\n",
    "# kgraph.to_jsonl(\"kgraph_modelbased_relations_swem.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching relations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b386c89279214afbbb4bb0aa6a770de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 16.970062732696533 seconds per head\n"
     ]
    }
   ],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.processors.relation import DistilBertRelationMatcher\n",
    "import time\n",
    "\n",
    "csi = CommonsenseInference()\n",
    "csi.remove_processor(\"simple_relation_matcher\")\n",
    "dbert_matcher = DistilBertRelationMatcher(\"dbert_relation_matcher\")\n",
    "csi.add_processor(dbert_matcher)\n",
    "heads = val_df.text.to_list()\n",
    "start = time.time()\n",
    "kgraph = csi.infer(heads=heads, dry_run=True)\n",
    "end = time.time()\n",
    "print(f\"Took {(end-start)/len(heads)} seconds per head\")\n",
    "# kgraph.to_jsonl(\"kgraph_modelbased_relations_dbert.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36940, 2962, 6569)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PersonX abandons ___ altogether</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PersonX abandons the ___ altogether</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PersonX abolishes ___ altogether</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PersonX abolishes ___ in the states</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PersonX abolishes the ___ altogether</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text      label\n",
       "0       PersonX abandons ___ altogether  [0, 0, 1]\n",
       "1   PersonX abandons the ___ altogether  [0, 1, 1]\n",
       "2      PersonX abolishes ___ altogether  [0, 1, 1]\n",
       "3   PersonX abolishes ___ in the states  [0, 1, 1]\n",
       "4  PersonX abolishes the ___ altogether  [0, 1, 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relation_modeling_utils import explode_labels\n",
    "train_df, val_df, test_df = explode_labels(train_df), explode_labels(val_df), explode_labels(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    22457\n",
       " 1    14483\n",
       " Name: label_0, dtype: int64,\n",
       " 0    18538\n",
       " 1    18402\n",
       " Name: label_1, dtype: int64,\n",
       " 1    21006\n",
       " 0    15934\n",
       " Name: label_2, dtype: int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label_0.value_counts(), train_df.label_1.value_counts(), train_df.label_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    2630\n",
       " 1     332\n",
       " Name: label_0, dtype: int64,\n",
       " 1    2263\n",
       " 0     699\n",
       " Name: label_1, dtype: int64,\n",
       " 1    2228\n",
       " 0     734\n",
       " Name: label_2, dtype: int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.label_0.value_counts(), val_df.label_1.value_counts(), val_df.label_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    4668\n",
       " 1    1901\n",
       " Name: label_0, dtype: int64,\n",
       " 1    4419\n",
       " 0    2150\n",
       " Name: label_1, dtype: int64,\n",
       " 0    3996\n",
       " 1    2573\n",
       " Name: label_2, dtype: int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.label_0.value_counts(), test_df.label_1.value_counts(), test_df.label_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19717</th>\n",
       "      <td>alcohol</td>\n",
       "      <td>[1, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19771</th>\n",
       "      <td>bag</td>\n",
       "      <td>[1, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19822</th>\n",
       "      <td>beer</td>\n",
       "      <td>[1, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19915</th>\n",
       "      <td>call</td>\n",
       "      <td>[1, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19930</th>\n",
       "      <td>car</td>\n",
       "      <td>[1, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26118</th>\n",
       "      <td>subject</td>\n",
       "      <td>[1, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26215</th>\n",
       "      <td>flirt</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26572</th>\n",
       "      <td>ice skate</td>\n",
       "      <td>[1, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26592</th>\n",
       "      <td>open door</td>\n",
       "      <td>[1, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26693</th>\n",
       "      <td>graduate</td>\n",
       "      <td>[1, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            text      label  label_0  label_1  label_2\n",
       "19717    alcohol  [1, 1, 0]        1        1        0\n",
       "19771        bag  [1, 1, 0]        1        1        0\n",
       "19822       beer  [1, 1, 0]        1        1        0\n",
       "19915       call  [1, 1, 0]        1        1        0\n",
       "19930        car  [1, 1, 0]        1        1        0\n",
       "...          ...        ...      ...      ...      ...\n",
       "26118    subject  [1, 1, 0]        1        1        0\n",
       "26215      flirt  [1, 1, 1]        1        1        1\n",
       "26572  ice skate  [1, 1, 0]        1        1        0\n",
       "26592  open door  [1, 1, 0]        1        1        0\n",
       "26693   graduate  [1, 1, 0]        1        1        0\n",
       "\n",
       "[183 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[(train_df.label_0 == 1) & (train_df.label_1 == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relation_modeling_utils import get_class_dist_report\n",
    "train_df_report = get_class_dist_report(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('class_0', 0): 0.6079317812669194,\n",
       " ('class_0', 'class_0', 0, 0): 0.6079317812669194,\n",
       " ('class_0', 'class_0', 0, 1): 0.0,\n",
       " ('class_0', 1): 0.3920682187330807,\n",
       " ('class_0', 'class_0', 1, 0): 0.0,\n",
       " ('class_0', 'class_0', 1, 1): 0.3920682187330807,\n",
       " ('class_0', 'class_1', 0, 0): 0.1147265836491608,\n",
       " ('class_0', 'class_1', 0, 1): 0.49320519761775855,\n",
       " ('class_0', 'class_1', 1, 0): 0.3871142393069843,\n",
       " ('class_0', 'class_1', 1, 1): 0.0049539794260963724,\n",
       " ('class_0', 'class_2', 0, 0): 0.040931239848402814,\n",
       " ('class_0', 'class_2', 0, 1): 0.5670005414185165,\n",
       " ('class_0', 'class_2', 1, 0): 0.3904168922577152,\n",
       " ('class_0', 'class_2', 1, 1): 0.0016513264753654576,\n",
       " ('class_1', 0): 0.5018408229561451,\n",
       " ('class_1', 'class_0', 0, 0): 0.1147265836491608,\n",
       " ('class_1', 'class_0', 0, 1): 0.3871142393069843,\n",
       " ('class_1', 1): 0.4981591770438549,\n",
       " ('class_1', 'class_0', 1, 0): 0.49320519761775855,\n",
       " ('class_1', 'class_0', 1, 1): 0.0049539794260963724,\n",
       " ('class_1', 'class_1', 0, 0): 0.5018408229561451,\n",
       " ('class_1', 'class_1', 0, 1): 0.0,\n",
       " ('class_1', 'class_1', 1, 0): 0.0,\n",
       " ('class_1', 'class_1', 1, 1): 0.4981591770438549,\n",
       " ('class_1', 'class_2', 0, 0): 0.38657282079047106,\n",
       " ('class_1', 'class_2', 0, 1): 0.11526800216567407,\n",
       " ('class_1', 'class_2', 1, 0): 0.04477531131564699,\n",
       " ('class_1', 'class_2', 1, 1): 0.4533838657282079,\n",
       " ('class_2', 0): 0.43134813210611805,\n",
       " ('class_2', 'class_0', 0, 0): 0.040931239848402814,\n",
       " ('class_2', 'class_0', 0, 1): 0.3904168922577152,\n",
       " ('class_2', 1): 0.568651867893882,\n",
       " ('class_2', 'class_0', 1, 0): 0.5670005414185165,\n",
       " ('class_2', 'class_0', 1, 1): 0.0016513264753654576,\n",
       " ('class_2', 'class_1', 0, 0): 0.38657282079047106,\n",
       " ('class_2', 'class_1', 0, 1): 0.04477531131564699,\n",
       " ('class_2', 'class_1', 1, 0): 0.11526800216567407,\n",
       " ('class_2', 'class_1', 1, 1): 0.4533838657282079,\n",
       " ('class_2', 'class_2', 0, 0): 0.43134813210611805,\n",
       " ('class_2', 'class_2', 0, 1): 0.0,\n",
       " ('class_2', 'class_2', 1, 0): 0.0,\n",
       " ('class_2', 'class_2', 1, 1): 0.568651867893882}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PersonX nsubj abandons VERB []\n",
      "abandons ROOT abandons VERB [PersonX, altogether]\n",
      "altogether advmod abandons VERB []\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"PersonX abandons ___ altogether\".replace(\"_\", \"\").replace(\"  \", \" \"))\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "            [child for child in token.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36940/36940 [01:38<00:00, 373.90it/s]\n",
      "100%|██████████| 2962/2962 [00:07<00:00, 371.91it/s]\n",
      "100%|██████████| 6569/6569 [00:17<00:00, 377.47it/s]\n"
     ]
    }
   ],
   "source": [
    "from relation_modeling_utils import HeuristicClassifier\n",
    "heuristic_model = HeuristicClassifier()\n",
    "train_preds = heuristic_model.predict(train_df)\n",
    "val_preds = heuristic_model.predict(val_df)\n",
    "test_preds = heuristic_model.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.832, precision=0.813, recall=0.855, f1=0.832\n"
     ]
    }
   ],
   "source": [
    "from relation_modeling_utils import report_metrics\n",
    "report_metrics(torch.tensor(train_preds, dtype=float), torch.tensor(np.asarray(train_df.label.to_list())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.792, precision=0.814, recall=0.849, f1=0.825\n"
     ]
    }
   ],
   "source": [
    "report_metrics(torch.tensor(val_preds, dtype=float), torch.tensor(np.asarray(val_df.label.to_list())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.771, precision=0.747, recall=0.843, f1=0.781\n"
     ]
    }
   ],
   "source": [
    "report_metrics(torch.tensor(test_preds, dtype=float), torch.tensor(np.asarray(test_df.label.to_list())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140049/140049 [00:00<00:00, 1285019.43it/s]\n",
      "100%|██████████| 14524/14524 [00:00<00:00, 1351062.82it/s]\n",
      "100%|██████████| 27270/27270 [00:00<00:00, 1325960.40it/s]\n"
     ]
    }
   ],
   "source": [
    "from relation_modeling_utils import create_vocab\n",
    "train_vocab, val_vocab, test_vocab = create_vocab(train_df), create_vocab(val_df), create_vocab(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15235929505400797, 0.8725581395348837)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_vocab.intersection(val_vocab)) / len(train_vocab), len(train_vocab.intersection(val_vocab)) / len(val_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.27109559002680095, 0.8000958772770853)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_vocab.intersection(test_vocab)) / len(train_vocab), len(train_vocab.intersection(test_vocab)) / len(test_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "atomic_df = pd.read_csv(\"data/atomic/v4_atomic_all_agg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = set(train_df.text.to_list())\n",
    "ood_test = [event for event in atomic_df.event if event not in train_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24312"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(atomic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4617"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ood_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_df = pd.DataFrame({'text': ood_test})\n",
    "ood_vocab = create_vocab(ood_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.17363761877690245, 0.8737229260318757)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_vocab.intersection(ood_vocab)) / len(train_vocab), len(train_vocab.intersection(ood_vocab)) / len(ood_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy_wordnet.wordnet_annotator.WordnetAnnotator at 0x7ff0c52bcdc0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy_wordnet.wordnet_annotator import WordnetAnnotator \n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe(\"spacy_wordnet\", after='tagger', config={'lang': nlp.lang})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('offer.v.01'),\n",
       " Synset('offer.v.02'),\n",
       " Synset('volunteer.v.02'),\n",
       " Synset('offer.v.04'),\n",
       " Synset('offer.v.05'),\n",
       " Synset('offer.v.06'),\n",
       " Synset('offer.v.07'),\n",
       " Synset('offer.v.08'),\n",
       " Synset('offer.v.09'),\n",
       " Synset('put_up.v.02'),\n",
       " Synset('extend.v.04'),\n",
       " Synset('propose.v.05'),\n",
       " Synset('offer.v.13')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = nlp('offered')[0]\n",
    "token._.wordnet.synsets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab.intersection(test_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "transomcs_df = pd.read_csv(\"data/TransOMCS_full.txt\", sep=\"\\t\", header=None, names=[\"head\", \"relation\", \"tail\", \"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>student</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>school</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>building</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>city</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sugar</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>coffee</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>government</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>city</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>school</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>city</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         head    relation    tail  score\n",
       "0     student  AtLocation  school    1.0\n",
       "1    building  AtLocation    city    1.0\n",
       "2       sugar  AtLocation  coffee    1.0\n",
       "3  government  AtLocation    city    1.0\n",
       "4      school  AtLocation    city    1.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transomcs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18481607"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transomcs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>student</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>school</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>building</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>city</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sugar</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>coffee</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>government</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>city</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>school</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>city</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5370463</th>\n",
       "      <td>bribe</td>\n",
       "      <td>UsedFor</td>\n",
       "      <td>lend</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5370464</th>\n",
       "      <td>jefferson</td>\n",
       "      <td>HasA</td>\n",
       "      <td>county</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5370465</th>\n",
       "      <td>man</td>\n",
       "      <td>UsedFor</td>\n",
       "      <td>give to</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5370466</th>\n",
       "      <td>sender</td>\n",
       "      <td>UsedFor</td>\n",
       "      <td>know</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5370467</th>\n",
       "      <td>lack</td>\n",
       "      <td>CapableOf</td>\n",
       "      <td>meaning</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5370468 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               head    relation     tail  score\n",
       "0           student  AtLocation   school   1.00\n",
       "1          building  AtLocation     city   1.00\n",
       "2             sugar  AtLocation   coffee   1.00\n",
       "3        government  AtLocation     city   1.00\n",
       "4            school  AtLocation     city   1.00\n",
       "...             ...         ...      ...    ...\n",
       "5370463       bribe     UsedFor     lend   0.51\n",
       "5370464   jefferson        HasA   county   0.51\n",
       "5370465         man     UsedFor  give to   0.51\n",
       "5370466      sender     UsedFor     know   0.51\n",
       "5370467        lack   CapableOf  meaning   0.51\n",
       "\n",
       "[5370468 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transomcs_df[transomcs_df['score'] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38215</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ReceivesAction</td>\n",
       "      <td>fasten</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73145</th>\n",
       "      <td>NaN</td>\n",
       "      <td>InstanceOf</td>\n",
       "      <td>warranty</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108082</th>\n",
       "      <td>work</td>\n",
       "      <td>ReceivesAction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114095</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ReceivesAction</td>\n",
       "      <td>read</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124334</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ReceivesAction</td>\n",
       "      <td>lure</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18379073</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ReceivesAction</td>\n",
       "      <td>dereference</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18379482</th>\n",
       "      <td>ping</td>\n",
       "      <td>ReceivesAction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18406398</th>\n",
       "      <td>NaN</td>\n",
       "      <td>InstanceOf</td>\n",
       "      <td>betrothal</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18438389</th>\n",
       "      <td>uptight</td>\n",
       "      <td>InstanceOf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18444109</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>954 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             head        relation         tail  score\n",
       "38215         NaN  ReceivesAction       fasten   0.99\n",
       "73145         NaN      InstanceOf     warranty   0.99\n",
       "108082       work  ReceivesAction          NaN   0.99\n",
       "114095        NaN  ReceivesAction         read   0.99\n",
       "124334        NaN  ReceivesAction         lure   0.99\n",
       "...           ...             ...          ...    ...\n",
       "18379073      NaN  ReceivesAction  dereference   0.00\n",
       "18379482     ping  ReceivesAction          NaN   0.00\n",
       "18406398      NaN      InstanceOf    betrothal   0.00\n",
       "18438389  uptight      InstanceOf          NaN   0.00\n",
       "18444109      NaN      AtLocation          NaN   0.00\n",
       "\n",
       "[954 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transomcs_df[transomcs_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "transomcs_df = transomcs_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18480653"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transomcs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "transomcs_df = transomcs_df[transomcs_df.score >= 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5534596"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transomcs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transomcs_df.duplicated(subset=['head']).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kogito.core.relation import CONCEPTNET_TO_ATOMIC_MAP, PHYSICAL_RELATIONS, EVENT_RELATIONS, SOCIAL_RELATIONS\n",
    "from collections import defaultdict\n",
    "\n",
    "def relation_to_class(relation):\n",
    "    if relation in PHYSICAL_RELATIONS:\n",
    "        return 0\n",
    "    \n",
    "    if relation in EVENT_RELATIONS:\n",
    "        return 1\n",
    "    \n",
    "    if relation in SOCIAL_RELATIONS:\n",
    "        return 2\n",
    "    \n",
    "    return None\n",
    "\n",
    "test_ood_samples = []\n",
    "unrecognized_rels = set()\n",
    "head_label_map = defaultdict(set)\n",
    "\n",
    "for row in transomcs_df.itertuples():\n",
    "    heads = row.head.split()\n",
    "    if not any([head in train_vocab for head in heads]):\n",
    "        rel_class = relation_to_class(row.relation)\n",
    "        if rel_class is None:\n",
    "            atomic_relations = CONCEPTNET_TO_ATOMIC_MAP.get(row.relation)\n",
    "            if atomic_relations:\n",
    "                if not isinstance(atomic_relations, list):\n",
    "                    atomic_relations = [atomic_relations]\n",
    "                \n",
    "                for rel in atomic_relations:\n",
    "                    rel_class = relation_to_class(rel)\n",
    "                    head_label_map[row.head].add(rel_class)\n",
    "            else:\n",
    "                unrecognized_rels.add(row.relation)\n",
    "        else:\n",
    "            head_label_map[row.head].add(rel_class)\n",
    "\n",
    "for head, labels in head_label_map.items():\n",
    "    final_label = [1 if label in labels else 0 for label in range(3)]\n",
    "    test_ood_samples.append((head, final_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41829"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ood_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CreatedBy', 'InstanceOf'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unrecognized_rels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ood_df = pd.DataFrame(test_ood_samples, columns=['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>curator</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foyer</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yolk</td>\n",
       "      <td>[1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fade</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pave</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      text      label\n",
       "0  curator  [1, 1, 1]\n",
       "1    foyer  [1, 1, 1]\n",
       "2     yolk  [1, 1, 0]\n",
       "3     fade  [1, 1, 1]\n",
       "4     pave  [1, 1, 1]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ood_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41829/41829 [01:44<00:00, 401.65it/s]\n"
     ]
    }
   ],
   "source": [
    "test_ood_preds = heuristic_model.predict(test_ood_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.658, precision=0.785, recall=0.535, f1=0.604\n"
     ]
    }
   ],
   "source": [
    "report_metrics(torch.tensor(test_ood_preds, dtype=float), torch.tensor(np.asarray(test_ood_df.label.to_list())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ood_df_report = get_class_dist_report(test_ood_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('class_0', 0): 0.012025150015539459,\n",
       " ('class_0', 'class_0', 0, 0): 0.012025150015539459,\n",
       " ('class_0', 'class_0', 0, 1): 0.0,\n",
       " ('class_0', 1): 0.9879748499844605,\n",
       " ('class_0', 'class_0', 1, 0): 0.0,\n",
       " ('class_0', 'class_0', 1, 1): 0.9879748499844605,\n",
       " ('class_0', 'class_1', 0, 0): 0.004016352291472423,\n",
       " ('class_0', 'class_1', 0, 1): 0.008008797724067035,\n",
       " ('class_0', 'class_1', 1, 0): 0.35998948098209377,\n",
       " ('class_0', 'class_1', 1, 1): 0.6279853690023668,\n",
       " ('class_0', 'class_2', 0, 0): 0.007889263429677974,\n",
       " ('class_0', 'class_2', 0, 1): 0.0041358865858614835,\n",
       " ('class_0', 'class_2', 1, 0): 0.8271534103134189,\n",
       " ('class_0', 'class_2', 1, 1): 0.16082143967104162,\n",
       " ('class_1', 0): 0.36400583327356617,\n",
       " ('class_1', 'class_0', 0, 0): 0.004016352291472423,\n",
       " ('class_1', 'class_0', 0, 1): 0.35998948098209377,\n",
       " ('class_1', 1): 0.6359941667264338,\n",
       " ('class_1', 'class_0', 1, 0): 0.008008797724067035,\n",
       " ('class_1', 'class_0', 1, 1): 0.6279853690023668,\n",
       " ('class_1', 'class_1', 0, 0): 0.36400583327356617,\n",
       " ('class_1', 'class_1', 0, 1): 0.0,\n",
       " ('class_1', 'class_1', 1, 0): 0.0,\n",
       " ('class_1', 'class_1', 1, 1): 0.6359941667264338,\n",
       " ('class_1', 'class_2', 0, 0): 0.3384494011331851,\n",
       " ('class_1', 'class_2', 0, 1): 0.025556432140381075,\n",
       " ('class_1', 'class_2', 1, 0): 0.49659327260991176,\n",
       " ('class_1', 'class_2', 1, 1): 0.13940089411652204,\n",
       " ('class_2', 0): 0.8350426737430969,\n",
       " ('class_2', 'class_0', 0, 0): 0.007889263429677974,\n",
       " ('class_2', 'class_0', 0, 1): 0.8271534103134189,\n",
       " ('class_2', 1): 0.1649573262569031,\n",
       " ('class_2', 'class_0', 1, 0): 0.0041358865858614835,\n",
       " ('class_2', 'class_0', 1, 1): 0.16082143967104162,\n",
       " ('class_2', 'class_1', 0, 0): 0.3384494011331851,\n",
       " ('class_2', 'class_1', 0, 1): 0.49659327260991176,\n",
       " ('class_2', 'class_1', 1, 0): 0.025556432140381075,\n",
       " ('class_2', 'class_1', 1, 1): 0.13940089411652204,\n",
       " ('class_2', 'class_2', 0, 0): 0.8350426737430969,\n",
       " ('class_2', 'class_2', 0, 1): 0.0,\n",
       " ('class_2', 'class_2', 1, 0): 0.0,\n",
       " ('class_2', 'class_2', 1, 1): 0.1649573262569031}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ood_df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ood_df = explode_labels(test_ood_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1    41326\n",
       " 0      503\n",
       " Name: label_0, dtype: int64,\n",
       " 1    26603\n",
       " 0    15226\n",
       " Name: label_1, dtype: int64,\n",
       " 0    34929\n",
       " 1     6900\n",
       " Name: label_2, dtype: int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ood_df.label_0.value_counts(), test_ood_df.label_1.value_counts(), test_ood_df.label_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kogito.core.processors.relation import SWEMRelationClassifier\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import spacy\n",
    "from relation_modeling_utils import HeadDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "vocab = np.load(\n",
    "    \"./data/vocab_glove_100d.npy\", allow_pickle=True\n",
    ").item()\n",
    "\n",
    "swem_classifier = SWEMRelationClassifier(pooling=\"avg\")\n",
    "swem_classifier.load_state_dict(\n",
    "    torch.load(\n",
    "        \"./models/swem_multi_label_finetune_state_dict.pth\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swem_test_data = HeadDataset(test_ood_df, vocab=vocab)\n",
    "swem_test_data = HeadDataset(test_df, vocab=vocab)\n",
    "swem_test_dataloader = DataLoader(swem_test_data, batch_size=len(swem_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    swem_X, swem_y = next(iter(swem_test_dataloader))\n",
    "    swem_preds = swem_classifier.forward(swem_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1],\n",
       "        [0, 1, 1],\n",
       "        [0, 1, 1],\n",
       "        ...,\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swem_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.860, precision=0.829, recall=0.961, f1=0.878\n"
     ]
    }
   ],
   "source": [
    "report_metrics(swem_preds, swem_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset\n",
    "import torchmetrics\n",
    "\n",
    "class DistilBertHeadDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "        self.labels = np.asarray(df['label'].to_list())\n",
    "        self.texts = [self.tokenizer(text, padding='max_length', max_length=32, truncation=True,\n",
    "                                     return_tensors=\"pt\") for text in df['text']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "class DistilBERTClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_classes=3, dropout=0.5, freeze_emb=False):\n",
    "        super().__init__()\n",
    "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, num_classes)\n",
    "\n",
    "        if freeze_emb:\n",
    "            for parameter in self.distilbert.parameters():\n",
    "                parameter.requires_grad = False\n",
    "            self.classifier = nn.Sequential(self.linear)\n",
    "        else:\n",
    "            self.classifier = nn.Sequential(self.linear)\n",
    "        self.test_accuracy = torchmetrics.Accuracy()\n",
    "        self.test_precision = torchmetrics.Precision(num_classes=3, average='weighted')\n",
    "        self.test_recall = torchmetrics.Recall(num_classes=3, average='weighted')\n",
    "        self.test_f1 = torchmetrics.F1Score(num_classes=3, average='weighted')\n",
    "    \n",
    "    def forward(self, input_ids, mask):\n",
    "        outputs = self.distilbert(input_ids=input_ids, attention_mask=mask, return_dict=False)\n",
    "        outputs = self.classifier(outputs[0][:, 0, :])\n",
    "        return outputs\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        mask = X['attention_mask']\n",
    "        input_ids = X['input_ids'].squeeze(1)\n",
    "        outputs = self.forward(input_ids, mask)\n",
    "        probs = F.sigmoid(outputs)\n",
    "        self.test_accuracy(probs, y)\n",
    "        self.test_precision(probs, y)\n",
    "        self.test_recall(probs, y)\n",
    "        self.test_f1(probs, y)\n",
    "        return probs\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        results = dict(accuracy=self.test_accuracy.compute(),\n",
    "                    precision=self.test_precision.compute(),\n",
    "                    recall=self.test_recall.compute(),\n",
    "                    F1=self.test_f1.compute())\n",
    "        self.log_dict(results)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for DistilBERTClassifier:\n\tMissing key(s) in state_dict: \"classifier.0.weight\", \"classifier.0.bias\". \n\tUnexpected key(s) in state_dict: \"classifier.1.weight\", \"classifier.1.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/root/kogito/examples/relation_modeling/analysis.ipynb Cell 46'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Biccluster032.iccluster.epfl.ch/root/kogito/examples/relation_modeling/analysis.ipynb#ch0000045vscode-remote?line=0'>1</a>\u001b[0m distilbert_classifier \u001b[39m=\u001b[39m DistilBERTClassifier\u001b[39m.\u001b[39;49mload_from_checkpoint(\u001b[39m'\u001b[39;49m\u001b[39m./models/distilbert/distilbert_model_20220404H1852.ckpt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.conda/envs/kogito/lib/python3.8/site-packages/pytorch_lightning/core/saving.py:156\u001b[0m, in \u001b[0;36mModelIO.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///root/.conda/envs/kogito/lib/python3.8/site-packages/pytorch_lightning/core/saving.py?line=152'>153</a>\u001b[0m \u001b[39m# override the hparams with values that were passed in\u001b[39;00m\n\u001b[1;32m    <a href='file:///root/.conda/envs/kogito/lib/python3.8/site-packages/pytorch_lightning/core/saving.py?line=153'>154</a>\u001b[0m checkpoint[\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mCHECKPOINT_HYPER_PARAMS_KEY]\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[0;32m--> <a href='file:///root/.conda/envs/kogito/lib/python3.8/site-packages/pytorch_lightning/core/saving.py?line=155'>156</a>\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_load_model_state(checkpoint, strict\u001b[39m=\u001b[39;49mstrict, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///root/.conda/envs/kogito/lib/python3.8/site-packages/pytorch_lightning/core/saving.py?line=156'>157</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/.conda/envs/kogito/lib/python3.8/site-packages/pytorch_lightning/core/saving.py:204\u001b[0m, in \u001b[0;36mModelIO._load_model_state\u001b[0;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[1;32m    <a href='file:///root/.conda/envs/kogito/lib/python3.8/site-packages/pytorch_lightning/core/saving.py?line=200'>201</a>\u001b[0m model\u001b[39m.\u001b[39mon_load_checkpoint(checkpoint)\n\u001b[1;32m    <a href='file:///root/.conda/envs/kogito/lib/python3.8/site-packages/pytorch_lightning/core/saving.py?line=202'>203</a>\u001b[0m \u001b[39m# load the state_dict on the model automatically\u001b[39;00m\n\u001b[0;32m--> <a href='file:///root/.conda/envs/kogito/lib/python3.8/site-packages/pytorch_lightning/core/saving.py?line=203'>204</a>\u001b[0m keys \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mload_state_dict(checkpoint[\u001b[39m\"\u001b[39;49m\u001b[39mstate_dict\u001b[39;49m\u001b[39m\"\u001b[39;49m], strict\u001b[39m=\u001b[39;49mstrict)\n\u001b[1;32m    <a href='file:///root/.conda/envs/kogito/lib/python3.8/site-packages/pytorch_lightning/core/saving.py?line=205'>206</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m strict:\n\u001b[1;32m    <a href='file:///root/.conda/envs/kogito/lib/python3.8/site-packages/pytorch_lightning/core/saving.py?line=206'>207</a>\u001b[0m     \u001b[39mif\u001b[39;00m keys\u001b[39m.\u001b[39mmissing_keys:\n",
      "File \u001b[0;32m~/.conda/envs/kogito/lib/python3.8/site-packages/torch/nn/modules/module.py:1497\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   <a href='file:///root/.conda/envs/kogito/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1491'>1492</a>\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   <a href='file:///root/.conda/envs/kogito/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1492'>1493</a>\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   <a href='file:///root/.conda/envs/kogito/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1493'>1494</a>\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   <a href='file:///root/.conda/envs/kogito/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1495'>1496</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> <a href='file:///root/.conda/envs/kogito/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1496'>1497</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   <a href='file:///root/.conda/envs/kogito/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1497'>1498</a>\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   <a href='file:///root/.conda/envs/kogito/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1498'>1499</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DistilBERTClassifier:\n\tMissing key(s) in state_dict: \"classifier.0.weight\", \"classifier.0.bias\". \n\tUnexpected key(s) in state_dict: \"classifier.1.weight\", \"classifier.1.bias\". "
     ]
    }
   ],
   "source": [
    "distilbert_classifier = DistilBERTClassifier.load_from_checkpoint('./models/distilbert/distilbert_model_20220404H1852.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbert_test_data = DistilBertHeadDataset(test_ood_df)\n",
    "dbert_test_dataloader = DataLoader(dbert_test_data, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Missing logger folder: /root/kogito/examples/relation_modeling/lightning_logs\n",
      "/root/.conda/envs/kogito/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429211c63b4844e9b2b67cab566f7850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.conda/envs/kogito/lib/python3.8/site-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': tensor(0.7189, device='cuda:0'), 'precision': tensor(0.8397, device='cuda:0'), 'recall': tensor(0.5454, device='cuda:0'), 'F1': tensor(0.5650, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'F1': 0.5650182366371155,\n",
      " 'accuracy': 0.7189190983772278,\n",
      " 'precision': 0.8396950960159302,\n",
      " 'recall': 0.5454303026199341}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.7189190983772278,\n",
       "  'precision': 0.8396950960159302,\n",
       "  'recall': 0.5454303026199341,\n",
       "  'F1': 0.5650182366371155}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=[0])\n",
    "trainer.test(distilbert_classifier, dbert_test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "\n",
    "class BertHeadDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.labels = np.asarray(df['label'].to_list())\n",
    "        self.texts = [self.tokenizer(text, padding='max_length', max_length=32, truncation=True,\n",
    "                                     return_tensors=\"pt\") for text in df['text']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "class BERTClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_classes=3, dropout=0.5, learning_rate=1e-4, freeze_emb=False):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, num_classes)\n",
    "\n",
    "        if freeze_emb:\n",
    "            for parameter in self.bert.parameters():\n",
    "                parameter.requires_grad = False\n",
    "            self.classifier = nn.Sequential(self.linear)\n",
    "        else:\n",
    "            self.classifier = nn.Sequential(self.dropout, self.linear)\n",
    "        self.test_accuracy = torchmetrics.Accuracy()\n",
    "        self.test_precision = torchmetrics.Precision(num_classes=3, average='weighted')\n",
    "        self.test_recall = torchmetrics.Recall(num_classes=3, average='weighted')\n",
    "        self.test_f1 = torchmetrics.F1Score(num_classes=3, average='weighted')\n",
    "    \n",
    "    def forward(self, input_ids, mask):\n",
    "        _, outputs = self.bert(input_ids=input_ids, attention_mask=mask, return_dict=False)\n",
    "        outputs = self.classifier(outputs)\n",
    "        return outputs\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        mask = X['attention_mask']\n",
    "        input_ids = X['input_ids'].squeeze(1)\n",
    "        outputs = self.forward(input_ids, mask)\n",
    "        probs = F.sigmoid(outputs)\n",
    "        self.test_accuracy(probs, y)\n",
    "        self.test_precision(probs, y)\n",
    "        self.test_recall(probs, y)\n",
    "        self.test_f1(probs, y)\n",
    "        return probs\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        results = dict(accuracy=self.test_accuracy.compute(),\n",
    "                    precision=self.test_precision.compute(),\n",
    "                    recall=self.test_recall.compute(),\n",
    "                    F1=self.test_f1.compute())\n",
    "        self.log_dict(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_classifier = BERTClassifier.load_from_checkpoint('./models/bert/bert_model_20220404H1850.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_test_data = BertHeadDataset(test_ood_df)\n",
    "bert_test_dataloader = DataLoader(bert_test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/root/.conda/envs/kogito/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac19da073b34f8f8ab30a10aae523e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.conda/envs/kogito/lib/python3.8/site-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'F1': 0.545831024646759,\n",
      " 'accuracy': 0.7217401266098022,\n",
      " 'precision': 0.7522579431533813,\n",
      " 'recall': 0.5436528325080872}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.7217401266098022,\n",
       "  'precision': 0.7522579431533813,\n",
       "  'recall': 0.5436528325080872,\n",
       "  'F1': 0.545831024646759}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_trainer = pl.Trainer(accelerator=\"gpu\", devices=[0])\n",
    "bert_trainer.test(bert_classifier, bert_test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c3b128559c7e8fd624042ca8b6c93b33cd59aca7b58d05c9d4cd21ec1a84d35"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('kogito')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
